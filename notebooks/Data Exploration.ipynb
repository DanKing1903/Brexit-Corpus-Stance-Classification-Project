{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = \"../data/raw/brexit_blog_corpus.xlsx\"\n",
    "df = pd.read_excel(file, usecols = \"A:K\")\n",
    "random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SND_studie</th>\n",
       "      <th>SND_dataset</th>\n",
       "      <th>SND_version</th>\n",
       "      <th>Utterance ID No</th>\n",
       "      <th>Utterance</th>\n",
       "      <th>Stance category</th>\n",
       "      <th>second stance category</th>\n",
       "      <th>third</th>\n",
       "      <th>fourth</th>\n",
       "      <th>fifth</th>\n",
       "      <th>Utterance word length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1037</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>I know what you mean.</td>\n",
       "      <td>agreement/disagreement</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1037</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>Yep, we definitely freeze out others opinions,...</td>\n",
       "      <td>agreement/disagreement</td>\n",
       "      <td>certainty</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1037</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3</td>\n",
       "      <td>So do I.</td>\n",
       "      <td>agreement/disagreement</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1037</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4</td>\n",
       "      <td>I don't disagree that the Yes campaign made mi...</td>\n",
       "      <td>agreement/disagreement</td>\n",
       "      <td>contrariety</td>\n",
       "      <td>necessity</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1037</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5</td>\n",
       "      <td>That to me is where the real conversions will ...</td>\n",
       "      <td>agreement/disagreement</td>\n",
       "      <td>prediction</td>\n",
       "      <td>source of knowledge</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   SND_studie  SND_dataset  SND_version  Utterance ID No  \\\n",
       "0        1037            1          1.0                1   \n",
       "1        1037            1          1.0                2   \n",
       "2        1037            1          1.0                3   \n",
       "3        1037            1          1.0                4   \n",
       "4        1037            1          1.0                5   \n",
       "\n",
       "                                           Utterance         Stance category  \\\n",
       "0                              I know what you mean.  agreement/disagreement   \n",
       "1  Yep, we definitely freeze out others opinions,...  agreement/disagreement   \n",
       "2                                           So do I.  agreement/disagreement   \n",
       "3  I don't disagree that the Yes campaign made mi...  agreement/disagreement   \n",
       "4  That to me is where the real conversions will ...  agreement/disagreement   \n",
       "\n",
       "  second stance category                third fourth fifth  \\\n",
       "0                    NaN                  NaN    NaN   NaN   \n",
       "1              certainty                  NaN    NaN   NaN   \n",
       "2                    NaN                  NaN    NaN   NaN   \n",
       "3            contrariety            necessity    NaN   NaN   \n",
       "4             prediction  source of knowledge    NaN   NaN   \n",
       "\n",
       "   Utterance word length  \n",
       "0                      5  \n",
       "1                     14  \n",
       "2                      3  \n",
       "3                     21  \n",
       "4                     29  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset distribution with respect to 1st label\n",
    "Dataset only has 1682 data points, therefore it is very important that out test split and training split both have distributions that are similar to the original data set. Here we can see the distribution of labels when we only consider the first label of each data point."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "contrariety               352\n",
       "source of knowledge       287\n",
       "prediction                252\n",
       "necessity                 204\n",
       "uncertainty               196\n",
       "hypotheticality           171\n",
       "certainty                  84\n",
       "agreement/disagreement     50\n",
       "tact/rudeness              44\n",
       "volition                   42\n",
       "Name: Stance category, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_percent = df['Stance category'].value_counts()\n",
    "\n",
    "df_percent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "contrariety               594\n",
       "prediction                463\n",
       "source of knowledge       442\n",
       "uncertainty               411\n",
       "necessity                 311\n",
       "hypotheticality           255\n",
       "certainty                 161\n",
       "agreement/disagreement     93\n",
       "volition                   73\n",
       "tact/rudeness              73\n",
       "concession/contrarines      2\n",
       "hypotheticallity            1\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_labels = df.iloc[:,5:10]\n",
    "stacked = all_labels.stack()\n",
    "stacked.value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2879\n"
     ]
    }
   ],
   "source": [
    "print(sum(stacked.value_counts()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['volition',\n",
       " 'prediction',\n",
       " 'tact/rudeness',\n",
       " 'necessity',\n",
       " 'hypotheticality',\n",
       " 'certainty',\n",
       " 'agreement/disagreement',\n",
       " 'contrariety',\n",
       " 'source of knowledge',\n",
       " 'uncertainty']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = set(df['Stance category'].values)\n",
    "list(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'BaseEstimator' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-50c7aceadee5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mclass\u001b[0m \u001b[0mLabelTransformer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mBaseEstimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTransformerMixin\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m     \"\"\"\n\u001b[1;32m      3\u001b[0m     \u001b[0mJoin\u001b[0m \u001b[0;36m5\u001b[0m \u001b[0mlabel\u001b[0m \u001b[0mcolumns\u001b[0m \u001b[0minto\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcorrect\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0mobserved\u001b[0m \u001b[0mlabel\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \"\"\"\n",
      "\u001b[0;31mNameError\u001b[0m: name 'BaseEstimator' is not defined"
     ]
    }
   ],
   "source": [
    "class LabelTransformer(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"\n",
    "    Join 5 label columns into list, correct 2 observed label errors \n",
    "    \n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        return None\n",
    "    \n",
    "    def fit(self, df, *_):\n",
    "        return self\n",
    "        \n",
    "    def transform(self, df, *_):\n",
    "        df = df.filter(['Stance category', 'second stance category', 'third', 'fourth', 'fifth'])\n",
    "        df.replace('concession/contrarines', np.NaN, inplace = True)\n",
    "        df.replace('hypotheticallity', 'hypotheticality', inplace = True)\n",
    "        y = df.stack().groupby(level = 0).apply(list)\n",
    "        return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
