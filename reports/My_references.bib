
@unpublished{sorowerLiteratureSurveyAlgorithms2018,
  title = {A {{Literature Survey}} on {{Algorithms}} for {{Multi}}-Label {{Learning}}},
  abstract = {Multi-label Learning is a form of supervised learning where the classification algorithm is required to learn from a set of instances, each instance can belong to multiple classes and so after be able to predict a set of class labels for a new instance. This is a generalized version of most popular multi-class problems where each instances is restricted to have only one class label. There exists a wide range of applications for multi-labelled predictions, such as text categorization, semantic image labeling, gene functionality classification etc. and the scope and interest is increasing with modern applications. This survey paper introduces the task of multi-label prediction (classification), presents the sparse literature in this area in an organized manner, discusses different evaluation metrics and performs a comparative analysis of the existing algorithms. This paper also relates multi-label problems with similar but different problems that are often reduced to multi-label problems to have access to wide range of multi-label algorithms.},
  language = {en},
  author = {Sorower, Mohammad S},
  year = {2018},
  file = {/home/dan/Zotero/storage/VGRN2Q5H/Sorower - A Literature Survey on Algorithms for Multi-label .pdf}
}

@article{simakiAnnotatingSpeakerStance2017,
  title = {Annotating {{Speaker Stance}} in {{Discourse}}: {{The Brexit Blog Corpus}}},
  issn = {1613-7027, 1613-7035},
  shorttitle = {Annotating {{Speaker Stance}} in {{Discourse}}},
  abstract = {The aim of this study is to explore the possibility of identifying speaker stance in discourse, provide an analytical resource for it and an evaluation of the level of agreement across speakers. We also explore to what extent language users agree about what kind of stances are expressed in natural language use or whether their interpretations diverge. In order to perform this task, a comprehensive cognitive-functional framework of ten stance categories was developed based on previous work on speaker stance in the literature. A corpus of opinionated texts was compiled, the Brexit Blog Corpus (BBC). An analytical protocol and interface (Active Learning and Visual Analytics) for the annotations was set up and the data were independently annotated by two annotators. The annotation procedure, the annotation agreements and the co-occurrence of more than one stance in the utterances are described and discussed. The careful, analytical annotation process has returned satisfactory inter- and intra-annotation agreement scores, resulting in a gold standard corpus, the final version of the BBC.},
  language = {en},
  journal = {Corpus Linguistics and Linguistic Theory},
  author = {Simaki, Vasiliki and Paradis, Carita and Skeppstedt, Maria and Sahlgren, Magnus and Kucher, Kostiantyn and Kerren, Andreas},
  month = jan,
  year = {2017},
  file = {/home/dan/Zotero/storage/6UVGWYA3/Simaki et al. - 2017 - Annotating Speaker Stance in Discourse The Brexit.pdf},
  note = {to be published.}
}

@article{simakiDetectionStanceRelatedCharacteristics2018,
  title = {Detection of {{Stance}}-{{Related Characteristics}} in {{Social Media Text}}},
  abstract = {In this paper, we present a study for the identification of stancerelated features in text data from social media. Based on our previous work on stance and our findings on stance patterns, we detected stance-related characteristics in a data set from Twitter and Facebook. We extracted various corpus-, quantitative- and computational-based features that proved to be significant for six stance categories (contrariety, hypotheticality, necessity, prediction, source of knowledge, and uncertainty), and we tested them in our data set. The results of a preliminary clustering method are presented and discussed as a starting point for future contributions in the field. The results of our experiments showed a strong correlation between different characteristics and stance constructions, which can lead us to a methodology for automatic stance annotation of these data.},
  language = {en},
  author = {Simaki, Vasiliki and Simakis, Panagiotis and Paradis, Carita and Kerren, Andreas},
  year = {2018},
  pages = {7},
  file = {/home/dan/Zotero/storage/L6SYQ7CL/Simaki et al. - 2018 - Detection of Stance-Related Characteristics in Soc.pdf}
}

@article{martinsStanceXploreVisualizationInteractive,
  title = {{{StanceXplore}}: {{Visualization}} for the {{Interactive Exploration}} of {{Stance}} in {{Social Media}}},
  abstract = {The use of interactive visualization techniques in Digital Humanities research can be a useful addition when traditional automated machine learning techniques face difficulties, as is often the case with the exploration of large volumes of dynamic\textemdash{}and in many cases, noisy and conflicting\textemdash{}textual data from social media. Recently, the field of stance analysis has been moving from a predominantly binary approach\textemdash{}either pro or con\textemdash{}to a multifaceted one, where each unit of text may be classified as one (or more) of multiple possible stance categories. This change adds more layers of complexity to an already hard problem, but also opens up new opportunities for obtaining richer and more relevant results from the analysis of stancetaking in social media. In this paper we propose StanceXplore, a new visualization for the interactive exploration of stance in social media. Our goal is to offer DH researchers the chance to explore stance-classified text corpora from different perspectives at the same time, using coordinated multiple views including user-defined topics, content similarity and dissimilarity, and geographical and temporal distribution. As a case study, we explore the activity of Twitter users in Sweden, analyzing their behavior in terms of topics discussed and the stances taken. Each textual unit (tweet) is labeled with one of eleven stance categories from a cognitive-functional stance framework based on recent work. We illustrate how StanceXplore can be used effectively to investigate multidimensional patterns and trends in stance-taking related to cultural events, their geographical distribution, and the confidence of the stance classifier.},
  language = {en},
  author = {Martins, R M and Simaki, V and Kucher, K and Paradis, C and Kerren, A},
  pages = {5},
  file = {/home/dan/Zotero/storage/IKGGDUNM/Martins et al. - StanceXplore Visualization for the Interactive Ex.pdf}
}

@article{simakiEvaluatingStanceannotatedSentences2018,
  title = {Evaluating Stance-Annotated Sentences from the {{Brexit Blog Corpus}}: {{A}} Quantitative Linguistic Analysis},
  volume = {42},
  issn = {1502-5462},
  shorttitle = {Evaluating Stance-Annotated Sentences from the {{Brexit Blog Corpus}}},
  doi = {10.1515/icame-2018-0007},
  abstract = {This paper offers a formally driven quantitative analysis of stance-annotated sentences in the Brexit Blog Corpus (BBC). Our goal is to identify features that determine the formal profiles of six stance categories (CONTRARIETY, HYPOTHETICALITY, NECESSITY, PREDICTION, SOURCE OF KNOWLEDGE and UNCERTAINTY) in a subset of the BBC. The study has two parts: firstly, it examines a large number of formal linguistic features, such as punctuation, words and grammatical categories that occur in the sentences in order to describe the specific characteristics of each category, and secondly, it compares characteristics in the entire data set in order to determine stance similarities in the data set. We show that among the six stance categories in the corpus, CONTRARIETY and NECESSITY are the most discriminative ones, with the former using longer sentences, more conjunctions, more repetitions and shorter forms than the sentences expressing other stances. NECESSITY has longer lexical forms but shorter sentences, which are syntactically more complex. We show that stance in our data set is expressed in sentences with around 21 words per sentence. The sentences consist mainly of alphabetical characters forming a varied vocabulary without special forms, such as digits or special characters.},
  language = {en},
  number = {1},
  journal = {ICAME Journal},
  author = {Simaki, Vasiliki and Paradis, Carita and Kerren, Andreas},
  month = jan,
  year = {2018},
  file = {/home/dan/Zotero/storage/SMCRLIM2/Simaki et al. - 2018 - Evaluating stance-annotated sentences from the Bre.pdf}
}

@inproceedings{hassanDeepLearningApproach2017,
  title = {Deep {{Learning}} Approach for Sentiment Analysis of Short Texts},
  doi = {10.1109/ICCAR.2017.7942788},
  abstract = {Unstructured text data produced on the internet grows rapidly, and sentiment analysis for short texts becomes a challenge because of the limit of the contextual information they usually contain. Learning good vector representations for sentences is a challenging task and an ongoing research area. Moreover, learning long-term dependencies with gradient descent is difficult in neural network language model because of the vanishing gradients problem. Natural Language Processing (NLP) systems traditionally treat words as discrete atomic symbols; the model can leverage small amounts of information regarding the relationship between the individual symbols. In this paper, we propose ConvLstm, neural network architecture that employs Convolutional Neural Network (CNN) and Long Short-Term Memory (LSTM) on top of pre-trained word vectors. In our experiments, ConvLstm exploit LSTM as a substitute of pooling layer in CNN to reduce the loss of detailed local information and capture long term dependencies in sequence of sentences. We validate the proposed model on two sentiment datasets IMDB, and Stanford Sentiment Treebank (SSTb). Empirical results show that ConvLstm achieved comparable performances with less parameters on sentiment analysis tasks.},
  booktitle = {2017 3rd {{International Conference}} on {{Control}}, {{Automation}} and {{Robotics}} ({{ICCAR}})},
  author = {Hassan, A. and Mahmood, A.},
  month = apr,
  year = {2017},
  keywords = {CNN,ConvLstm,convolution,convolutional neural network,deep learning,gradient methods,gradients problem,IMDB,Internet,learning (artificial intelligence),long short-term memory,LSTM,natural language processing,neural nets,neural network language model,Neural networks,NLP,pretrained word vectors,recurrent neural network,sentiment analysis,short texts,SSTb,Stanford sentiment treebank,Testing,unstructured text data},
  pages = {705-710},
  file = {/home/dan/Zotero/storage/BIWQVRNU/Hassan and Mahmood - 2017 - Deep Learning approach for sentiment analysis of s.html}
}

@article{cawleyOverfittingModelSelection10,
  title = {On {{Over}}-fitting in {{Model Selection}} and {{Subsequent Selection Bias}} in {{Performance Evaluation}}},
  abstract = {Model selection strategies for machine learning algorithms typically involve the numerical optimisation of an appropriate model selection criterion, often based on an estimator of generalisation performance, such as k-fold cross-validation. The error of such an estimator can be broken down into bias and variance components. While unbiasedness is often cited as a beneficial quality of a model selection criterion, we demonstrate that a low variance is at least as important, as a nonnegligible variance introduces the potential for over-fitting in model selection as well as in training the model. While this observation is in hindsight perhaps rather obvious, the degradation in performance due to over-fitting the model selection criterion can be surprisingly large, an observation that appears to have received little attention in the machine learning literature to date. In this paper, we show that the effects of this form of over-fitting are often of comparable magnitude to differences in performance between learning algorithms, and thus cannot be ignored in empirical evaluation. Furthermore, we show that some common performance evaluation practices are susceptible to a form of selection bias as a result of this form of over-fitting and hence are unreliable. We discuss methods to avoid over-fitting in model selection and subsequent selection bias in performance evaluation, which we hope will be incorporated into best practice. While this study concentrates on cross-validation based model selection, the findings are quite general and apply to any model selection practice involving the optimisation of a model selection criterion evaluated over a finite sample of data, including maximisation of the Bayesian evidence and optimisation of performance bounds.},
  language = {en},
  number = {11},
  journal = {Journal of Machine Learning Research},
  author = {Cawley, Gavin C and Talbot, Nicola L C},
  month = jul,
  year = {10},
  pages = {29},
  file = {/home/dan/Zotero/storage/ZZKJ9Q99/Cawley and Talbot - On Over-ﬁtting in Model Selection and Subsequent S.pdf}
}

@article{swamiEnglishHindiCodeMixedCorpus2018,
  archivePrefix = {arXiv},
  eprinttype = {arxiv},
  eprint = {1805.11868},
  primaryClass = {cs},
  title = {An {{English}}-{{Hindi Code}}-{{Mixed Corpus}}: {{Stance Annotation}} and {{Baseline System}}},
  shorttitle = {An {{English}}-{{Hindi Code}}-{{Mixed Corpus}}},
  abstract = {Social media has become one of the main channels for people to communicate and share their views with the society. We can often detect from these views whether the person is in favor, against or neutral towards a given topic. These opinions from social media are very useful for various companies. We present a new dataset that consists of 3545 English-Hindi code-mixed tweets with opinion towards Demonetisation that was implemented in India in 2016 which was followed by a large countrywide debate. We present a baseline supervised classification system for stance detection developed using the same dataset that uses various machine learning techniques to achieve an accuracy of 58.7\% on 10-fold cross validation.},
  language = {en},
  journal = {arXiv:1805.11868 [cs]},
  author = {Swami, Sahil and Khandelwal, Ankush and Singh, Vinay and Akhtar, Syed Sarfaraz and Shrivastava, Manish},
  month = may,
  year = {2018},
  keywords = {Computer Science - Computation and Language},
  file = {/home/dan/Zotero/storage/U2DALR5K/Swami et al. - 2018 - An English-Hindi Code-Mixed Corpus Stance Annotat.pdf},
  annote = {Comment: 9 pages, CICling 2018}
}

@article{vietenContemporaryFarRightRacist2016,
  title = {Contemporary {{Far}}-{{Right Racist Populism}} in {{Europe}}},
  volume = {37},
  issn = {0725-6868, 1469-9540},
  doi = {10.1080/07256868.2016.1235099},
  language = {en},
  number = {6},
  journal = {Journal of Intercultural Studies},
  author = {Vieten, Ulrike M. and Poynting, Scott},
  month = nov,
  year = {2016},
  pages = {533-540},
  file = {/home/dan/Zotero/storage/754BV44L/Vieten and Poynting - 2016 - Contemporary Far-Right Racist Populism in Europe.pdf}
}

@article{krisztinaHungaryStrongmanViktor2018,
  title = {Hungary's Strongman {{Viktor Orban}} Wins Third Term in Power},
  abstract = {Prime Minister Viktor Orban won a third straight term in power in Sunday elections after his anti-immigration campaign message secured a strong majority for his party in parliament, granting him two-thirds of seats based on preliminary results.},
  language = {en},
  journal = {Reuters},
  author = {Krisztina, Than and Gergely, Szakacs},
  month = apr,
  year = {2018},
  keywords = {Asylum / Immigration / Refugees,Central / Eastern Europe,East European Countries,Economic News (3rd Party),ELECTION,Elections / Voting,Emerging Market Countries,Europe,European Union,France,Fundamental Rights / Civil Liberties,Government / Politics,Graphics,Human Rights / Civil Rights,Hungary,HUNGARY,International Trade,Lawmaking,Major News,Pictures,Poland,Previews,Race Relations / Ethnic Issues,US,Video,Western Europe},
  file = {/home/dan/Zotero/storage/XMZAS9G8/hungarys-strongman-viktor-orban-wins-third-term-in-power-idUSKBN1HE0UC.html}
}

@article{marcinPolandEuroscepticsWin2015,
  title = {Poland's {{Eurosceptics}} Win Outright Majority in Parliament},
  abstract = {The Eurosceptic Law and Justice party (PiS) has become the first party to win an outright majority in the Polish parliament since the fall of communism in 1989, official results showed on Tuesday.},
  language = {en},
  journal = {Reuters},
  author = {Marcin, Goettig and Agnieszka, Barteczko},
  month = oct,
  year = {2015},
  keywords = {Central / Eastern Europe,East European Countries,ELECTION,Elections / Voting,Emerging Market Countries,Europe,European Union,Government / Politics,Lawmaking,Major News,Pictures,Poland,US,Video,Western Europe,Andrzej Duda,Andrzej Rychard,Crime / Law / Justice,Donald Tusk,Eastern Europe,Economic Events,Jaroslaw Kaczynski,Lech,Lower House Elections,Picture available,POLAND,Russia,Society / Social Issues,South,Taxation,Upper House Elections},
  file = {/home/dan/Zotero/storage/GZMGUM3T/polands-eurosceptics-win-outright-majority-in-parliament-idUSKCN0SL1XH20151027.html}
}

@article{gavinItalyConteSworn2018,
  title = {Italy's {{Conte}} Sworn in as {{PM}} of Anti-Establishment Government},
  abstract = {Giuseppe Conte was sworn in on Friday as Italy's prime minister, heading western Europe's first anti-establishment government bent on overhauling European Union rules on budgets and immigration.},
  language = {en},
  journal = {Reuters},
  author = {Gavin, Jones and Massimiliano, Di Giorgio},
  month = jun,
  year = {2018},
  keywords = {Economic News (3rd Party),Elections / Voting,Europe,European Union,Government / Politics,Major News,Pictures,Video,Western Europe,Currency Intervention,Euro Zone,Euro Zone as a Whole,General News,Government Finances,Italy,ITALY,National Government Debt,POLITICS,UK},
  file = {/home/dan/Zotero/storage/9CG2IHSF/italys-conte-sworn-in-as-pm-of-anti-establishment-government-idUKKCN1IX4B4.html}
}

@article{FactboxKeyFigures2017,
  title = {Factbox: {{Key}} Figures in {{Austria}}'s New Coalition Government},
  shorttitle = {Factbox},
  abstract = {Austria's center-right People's Party (OVP) led by Sebastian Kurz and the anti-immigration Freedom Party (FPO) have agreed to form a coalition government.},
  language = {en},
  journal = {Reuters},
  month = dec,
  year = {2017},
  keywords = {Asylum / Immigration / Refugees,Central / Eastern Europe,Elections / Voting,Europe,European Union,Fundamental Rights / Civil Liberties,Government / Politics,Major News,US,Western Europe,POLITICS,Austria,AUSTRIA,Automobiles / Auto Parts (Legacy),Company News,Conflicts / War / Peace,Corporate Events,Diplomacy / Foreign Policy,FACTBOX,Factboxes,Germany,PEOPLE,Personalities / People},
  file = {/home/dan/Zotero/storage/3FMQ4WCX/factbox-key-figures-in-austrias-new-coalition-government-idUSKBN1EA0GB.html}
}

@article{kirstiAustriaKurzStrikes2017,
  title = {Austria's {{Kurz}} Strikes Deal to Bring Far Right into Government},
  abstract = {Austrian conservatives led by Sebastian Kurz reached a coalition deal with the anti-immigration Freedom Party on Friday, paving the way for Austria to become the only western European country with a far-right party in government.},
  language = {en},
  journal = {Reuters},
  author = {Kirsti, Knolle and Shadia, Nasralla},
  month = dec,
  year = {2017},
  keywords = {Asylum / Immigration / Refugees,Central / Eastern Europe,Elections / Voting,Europe,European Union,France,Government / Politics,Human Rights / Civil Rights,Pictures,Video,Western Europe,Society / Social Issues,POLITICS,UK,Austria,AUSTRIA,Automobiles / Auto Parts (Legacy),Corporate Events,Diplomacy / Foreign Policy,Germany,EU Institutions,International Agencies / Treaty Groups},
  file = {/home/dan/Zotero/storage/X9Q6T5WF/austrias-kurz-strikes-deal-to-bring-far-right-into-government-idUKKBN1E91O1.html}
}

@article{michelleGermanyJubilantFarright2017,
  title = {Germany's Jubilant Far-Right Has {{Merkel}} in Its Sights},
  abstract = {Swept into parliament by those Germans angered at the arrival of more than a million refugees and migrants, the far-right Alternative for Germany (AfD) had a stark message for Chancellor Angela Merkel on Sunday.},
  language = {en},
  journal = {Reuters},
  author = {Michelle, Martin},
  month = sep,
  year = {2017},
  keywords = {Asylum / Immigration / Refugees,ELECTION,Elections / Voting,Europe,Fundamental Rights / Civil Liberties,Government / Politics,Human Rights / Civil Rights,Major News,Race Relations / Ethnic Issues,US,Western Europe,Lower House Elections,Conflicts / War / Peace,Germany,Adolf Hitler,AFD,Alexander Gauland,Alice Weidel,Angela Merkel,Bjoern Hoecke,East Germany,Frauke Petry,Georg Pazderski,GERMANY,Islam,REACTION,Religion / Belief},
  file = {/home/dan/Zotero/storage/HMFII49N/germanys-jubilant-far-right-has-merkel-in-its-sights-idUSKCN1BZ10H.html}
}

@article{ericTrumpWinsElectoral2016,
  title = {Trump Wins {{Electoral College}} Vote; a Few Electors Break Ranks},
  abstract = {Republican Donald Trump prevailed in U.S. Electoral College voting on Monday to officially win election as the next president, easily dashing a long-shot push by a small movement of detractors to try to block him from gaining the White House.},
  language = {en},
  journal = {Reuters},
  author = {Eric, Johnson and Jon, Herskovitz},
  month = dec,
  year = {2016},
  keywords = {East European Countries,ELECTION,Elections / Voting,Emerging Market Countries,Europe,Lawmaking,Major News,Pictures,US,Video,Crime / Law / Justice,Picture available,Russia,Conflicts / War / Peace,Diplomacy / Foreign Policy,Bernie Sanders,Bret Chiafalo,Christopher Suprun,Colin Powell,Computer Crime / Hacking / Cybercrime,Crime,David Bright,Donald J. Trump,Donald Trump,ELECTORALCOLLEGE,Hawaii,Hillary Clinton,Horace Greeley,International / National Security,Internet / World Wide Web,Jay Inslee,John Kasich,JOHN PODESTA,Maine,Michael Baca,Presidential Elections,Reince Priebus,Robert Erikson,Ron Paul,Science,Texas,Ulysses S. Grant,United States,US Government News,USA,Washington},
  file = {/home/dan/Zotero/storage/LG56KMXK/us-usa-election-electoralcollege-idUSKBN1480FQ.html}
}

@phdthesis{adamsDEMOCRATISATIONJOURNALISMPRACTICE,
  title = {{{THE DEMOCRATISATION OF JOURNALISM PRACTICE FOR A POLITICALLY INFORMED CITIZENRY}}: {{THE CAPACITIES OF NEW MEDIA TO ENGAGE CITIZENS IN PUBLIC LIFE A CASE STUDY}}},
  language = {en},
  author = {Adams, Debra Anne},
  file = {/home/dan/Zotero/storage/2Q9HFM3T/Adams - THE DEMOCRATISATION OF JOURNALISM PRACTICE FOR A P.pdf}
}

@techreport{gaughanIlliberalDemocracyToxic2017,
  address = {Rochester, NY},
  type = {{{SSRN Scholarly Paper}}},
  title = {Illiberal {{Democracy}}: {{The Toxic Mix}} of {{Fake News}}, {{Hyperpolarization}}, and {{Partisan Election Administration}}},
  shorttitle = {Illiberal {{Democracy}}},
  abstract = {The 2016 presidential election shook American democracy to its foundations. From Russia's hacking of Democratic National Committee emails to President Trump's false allegations of widespread voting fraud, America's democratic institutions emerged from the election battered and bruised. The stunning turn of events and the unprecedented controversy that surrounded the election had a profound impact on public opinion. National surveys now consistently find that a majority of Americans question the integrity of the nation's election system. Accordingly, this article contends that we have entered into a dangerous new chapter in the nation's history that not only threatens public confidence in election fairness but potentially could even undermine the long-term health of the nation's democracy. The unjustified fear of election fraud has itself become a threat to America's democratic principles. This article identifies three toxic developments that if left unchecked threaten the future of voting rights in America. The first is the rise of fake news. As the traditional news media has lost its gate-keeper status and as the internet has facilitated the rapid spread of misinformation, false allegations of voting fraud dominate news cycles. The pervasive nature of the claims has triggered a precipitous decline in public confidence in election integrity, even though there is no factual basis to justify the public's fear of widespread fraud. The second is the phenomenon of hyperpolarization. The partisan divide has reached such historic levels that Republicans and Democrats increasingly view the opposing party as a threat to the nation's well-being. Hyperpolarization makes partisans more inclined to attempt to limit the political influence of opposing voters, a development that is particularly dangerous in the United States because of the third toxic feature of contemporary politics: partisan control of election administration. Unusual among major democracies, the United States entrusts the majority party with responsibility for administering elections and setting voting rules. In recent years partisans have become increasingly aggressive in adopting election laws that benefit one party at the expense of the other. The real scandal of American politics is not illegal vote rigging or voter fraud but rather the extent to which partisans are legally permitted to manipulate election rules for political advantage.The United States thus stands at a uniquely dangerous moment in its history. The risk that America may evolve into an illiberal democracy is particularly high in light of the ongoing battle over voter registration restrictions and other laws that limit access to voting. In the name of safeguarding election integrity, legislatures across the country have adopted new voting laws that many courts and scholars have concluded make it harder for poor and minority voters to participate in the democratic process. As Americans increasingly view election stakes in apocalyptic terms, as false allegations of election fraud spread like wildfire, and as partisan officials control election rules, America's democratic institutions face their most serious domestic challenge since the enactment of the Voting Rights Act in 1965. This article concludes by proposing three steps to defend and preserve the vitality of America's liberal democratic norms at this dangerous moment in the nation's history.},
  language = {en},
  number = {ID 2944791},
  institution = {{Social Science Research Network}},
  author = {Gaughan, Anthony J.},
  month = apr,
  year = {2017},
  keywords = {Donald Trump,2016 Election,Democratic Norms,Disenfranchisement,Election Law,Fake News,Partisan Election Administration,Polarization,United States Constitution,Voter Identification,Voting Rights},
  file = {/home/dan/Zotero/storage/IVKMJUTW/papers.html}
}

@article{mohammadStanceSentimentTweets2016,
  archivePrefix = {arXiv},
  eprinttype = {arxiv},
  eprint = {1605.01655},
  primaryClass = {cs},
  title = {Stance and {{Sentiment}} in {{Tweets}}},
  abstract = {We can often detect from a person's utterances whether he/she is in favor of or against a given target entity -- their stance towards the target. However, a person may express the same stance towards a target by using negative or positive language. Here for the first time we present a dataset of tweet--target pairs annotated for both stance and sentiment. The targets may or may not be referred to in the tweets, and they may or may not be the target of opinion in the tweets. Partitions of this dataset were used as training and test sets in a SemEval-2016 shared task competition. We propose a simple stance detection system that outperforms submissions from all 19 teams that participated in the shared task. Additionally, access to both stance and sentiment annotations allows us to explore several research questions. We show that while knowing the sentiment expressed by a tweet is beneficial for stance classification, it alone is not sufficient. Finally, we use additional unlabeled data through distant supervision techniques and word embeddings to further improve stance classification.},
  journal = {arXiv:1605.01655 [cs]},
  author = {Mohammad, Saif M. and Sobhani, Parinaz and Kiritchenko, Svetlana},
  month = may,
  year = {2016},
  keywords = {Computer Science - Computation and Language},
  file = {/home/dan/Zotero/storage/Q9LIEBZX/Mohammad et al. - 2016 - Stance and Sentiment in Tweets.pdf;/home/dan/Zotero/storage/TMYJMNSS/1605.html},
  annote = {Comment: 22 pages}
}

@inproceedings{augensteinStanceDetectionBidirectional2016,
  title = {Stance {{Detection}} with {{Bidirectional Conditional Encoding}}},
  doi = {10.18653/v1/D16-1084},
  abstract = {Stance detection is the task of classifying the attitude Previous work has assumed that either the target is mentioned in the text or that training data for every target is given. This paper considers the more challenging version of this task, where targets are not always mentioned and no training data is available for the test targets. We experiment with conditional LSTM encoding, which builds a representation of the tweet that is dependent on the target, and demonstrate that it outperforms encoding the tweet and the target independently. Performance is improved further when the conditional model is augmented with bidirectional encoding. We evaluate our approach on the SemEval 2016 Task 6 Twitter Stance Detection corpus achieving performance second best only to a system trained on semiautomatically labelled tweets for the test target. When such weak supervision is added, our approach achieves state\textendash{}of-the-art results.},
  language = {en},
  publisher = {{Association for Computational Linguistics}},
  author = {Augenstein, Isabelle and Rockt\"aschel, Tim and Vlachos, Andreas and Bontcheva, Kalina},
  year = {2016},
  pages = {876-885},
  file = {/home/dan/Zotero/storage/FSLBVIIP/Augenstein et al. - 2016 - Stance Detection with Bidirectional Conditional En.pdf}
}

@article{rocktaschelReasoningEntailmentNeural2015,
  archivePrefix = {arXiv},
  eprinttype = {arxiv},
  eprint = {1509.06664},
  primaryClass = {cs},
  title = {Reasoning about {{Entailment}} with {{Neural Attention}}},
  abstract = {While most approaches to automatically recognizing entailment relations have used classifiers employing hand engineered features derived from complex natural language processing pipelines, in practice their performance has been only slightly better than bag-of-word pair classifiers using only lexical similarity. The only attempt so far to build an end-to-end differentiable neural network for entailment failed to outperform such a simple similarity classifier. In this paper, we propose a neural model that reads two sentences to determine entailment using long short-term memory units. We extend this model with a word-by-word neural attention mechanism that encourages reasoning over entailments of pairs of words and phrases. Furthermore, we present a qualitative analysis of attention weights produced by this model, demonstrating such reasoning capabilities. On a large entailment dataset this model outperforms the previous best neural model and a classifier with engineered features by a substantial margin. It is the first generic end-to-end differentiable system that achieves state-of-the-art accuracy on a textual entailment dataset.},
  journal = {arXiv:1509.06664 [cs]},
  author = {Rockt\"aschel, Tim and Grefenstette, Edward and Hermann, Karl Moritz and Ko{\v c}isk\'y, Tom\'a{\v s} and Blunsom, Phil},
  month = sep,
  year = {2015},
  keywords = {Computer Science - Computation and Language,68T50,Computer Science - Artificial Intelligence,Computer Science - Machine Learning,Computer Science - Neural and Evolutionary Computing,I.2.6,I.2.7},
  file = {/home/dan/Zotero/storage/CNDMNRUT/Rocktäschel et al. - 2015 - Reasoning about Entailment with Neural Attention.pdf;/home/dan/Zotero/storage/SHXPIUVB/1509.html},
  annote = {Comment: ICLR 2016 camera-ready, 9 pages, 10 figures (incl. subfigures)}
}

@misc{TaskDetectingStance,
  title = {Task 6: {{Detecting Stance}} in {{Tweets}} $<$ {{SemEval}}-2016 {{Task}} 6},
  howpublished = {http://alt.qcri.org/semeval2016/task6/},
  file = {/home/dan/Zotero/storage/WS84M58B/task6.html}
}

@article{duboisCognitivefunctionalLinguisticsDialogic2014,
  title = {From Cognitive-Functional Linguistics to Dialogic Syntax},
  volume = {25},
  issn = {1613-3641, 0936-5907},
  doi = {10.1515/cog-2014-0023},
  abstract = {Dialogic syntax investigates the linguistic, cognitive, and interactional processes involved when language users reproduce selected aspects of a prior utterance, and when recipients respond to the parallelisms and resonances that result, drawing inferences for situated meaning. The phenomenon typically $\-$arises when a language user constructs an utterance modeled in part on the utterance of a prior speaker or author. The result is resonance, defined as the catalytic activation of affinities across utterances. This paper presents the concept of $\-$dialogic syntax and outlines some directions of current research on dialogic resonance, as represented in this Special Issue.},
  language = {en},
  number = {3},
  journal = {Cognitive Linguistics},
  author = {Du Bois, John W. and Giora, Rachel},
  month = jan,
  year = {2014},
  file = {/home/dan/Zotero/storage/CIHIKCKI/Du Bois and Giora - 2014 - From cognitive-functional linguistics to dialogic .pdf}
}

@book{hunstonEvaluationTextAuthorial2000,
  title = {Evaluation in {{Text}} : {{Authorial Stance}} and the {{Construction}} of {{Discourse}}: {{Authorial Stance}} and the {{Construction}} of {{Discourse}}},
  isbn = {978-0-19-159109-9},
  shorttitle = {Evaluation in {{Text}}},
  abstract = {A crucial aspect of any discourse is what the writer or speaker thinks about his/her topic - in other words, how the writer or speaker evaluates the topic. Evaluation in Text brings together work from many different perspectives, providing a unique profile of this important topic which will be essential reading for any student or researcher of Discourse Analysis. - ;This is an accessible and wide-ranging account of current research in one of the most central aspects of discourse analsysis: evalution in and of written and spoken language. Evalution is the broad cover term for the expression of a speakers - or writers - attitudes, feelings, and values. It covers areas sometimes referred to as stance, modality, affect or appraisal. Evaluation (a) expresses the speakers opinion and thus reflects the value-system of that person and their community; (b) constructs relations between speaker and hearer (or writer and reader); (c) plays a key role in how discourse is organized. Every act of evalution expresses and contributes to a communal value-system, which in turn is a component of the ideology that lies behind every written or spoken text. Conceptually, evaluation is comparative, subjective, and value-laden. In linguistic terms it may be analysed lexically, grammatically, and textually. These themes and perspectives are richly exemplified in the chapters of this book, by authors aware and observant of the fact that processes of linguistic analysis are themselves inherently evaluative. The editors open the book by introducing the field and provide separate, contextual introductions to each chapter. They have also collated the references into one list, itself a valuable research guide. The exemplary perspectives and analyses presented by the authors will be of central interest to everyone concerned with the analysis of discourse, whether as students of language, literature, or communication. They also have much to offer students of politics and culture. The editors open the book by introducing the field and provide separate, contextual introductions to each chapter. They have also collated the references into one list, itself a valuable research guide. The exemplary perspectives and analyses presented by the authors will be of central interest to everyone concerned with the analysis of discourse, whether as students of language, literature, or communication. They also have much to offer students of politics and culture. -},
  language = {en},
  publisher = {{Oxford University Press, UK}},
  author = {Hunston, Susan and Thompson, Geoffrey},
  month = feb,
  year = {2000}
}

@book{englebretsonStancetakingDiscourseSubjectivity2007,
  title = {Stancetaking in {{Discourse}}: {{Subjectivity}}, Evaluation, Interaction},
  isbn = {978-90-272-9192-9},
  shorttitle = {Stancetaking in {{Discourse}}},
  abstract = {This volume contributes to the burgeoning field of research on stance by offering a variety of studies based in natural discourse. These collected papers explore the situated, pragmatic, and interactional character of stancetaking, and present new models and conceptions of stance to spark future research. Central to the volume is the claim that stancetaking encompasses five general principles: it involves physical, attitudinal and/or moral positioning; it is a public action; it is inherently dialogic, interactional, and sequential; it indexes broader sociocultural contexts; and it is consequential to the interactants. Each paper explores one or more of these dimensions of stance from perspectives including interactional linguistics and conversation analysis, corpus linguistics, language description, discourse analysis, and sociocultural linguistics. Research languages include conversational American English, colloquial Indonesian, and Finnish. The understanding of stance that emerges is heterogeneous and variegated, and always intertwined with the pragmatic and social aspects of human conduct.},
  language = {en},
  publisher = {{John Benjamins Publishing}},
  author = {Englebretson, Robert},
  month = oct,
  year = {2007},
  keywords = {Language Arts \& Disciplines / Linguistics / General}
}

@misc{karkkainenEpistemicStanceEnglish,
  title = {Epistemic {{Stance}} in {{English Conversation}}},
  abstract = {This book is the first corpus-based description of epistemic stance in conversational American English. It argues for epistemic stance as a pragmatic rather than semantic notion: showing commitment to the status of information is an emergent interactive activity, rooted in the interaction between conversational co-participants. The first major part of the book establishes the highly regular and routinized nature of such stance marking in the data. The second part offers a micro-analysis of I think, the prototypical stance marker, in its sequential and activity contexts. Adopting the methodology of conversation analysis and paying serious attention to the manifold prosodic cues attendant in the speakers' utterances, the study offers novel situated interpretations of I think. The author also argues for intonation units as a unit of social interaction and makes observations about the grammaticization patterns of the most frequent epistemic markers, notably the status of I think as a discourse marker.},
  language = {English},
  howpublished = {https://benjamins.com/catalog/pbns.115},
  journal = {pbns.115},
  author = {Karkkainen, Elise},
  file = {/home/dan/Zotero/storage/9REUFPB6/pbns.html}
}

@book{karkkainenEpistemicStanceEnglish2003,
  title = {Epistemic {{Stance}} in {{English Conversation}}},
  isbn = {978-90-272-9594-1},
  abstract = {This book is the first corpus-based description of epistemic stance in conversational American English. It argues for epistemic stance as a pragmatic rather than semantic notion: showing commitment to the status of information is an emergent interactive activity, rooted in the interaction between conversational co-participants. The first major part of the book establishes the highly regular and routinized nature of such stance marking in the data. The second part offers a micro-analysis of \&lt;i\&gt;I think\&lt;/i\&gt;, the prototypical stance marker, in its sequential and activity contexts. Adopting the methodology of conversation analysis and paying serious attention to the manifold prosodic cues attendant in the speakers' utterances, the study offers novel situated interpretations of \&lt;i\&gt;I think\&lt;/i\&gt;. The author also argues for intonation units as a unit of social interaction and makes observations about the grammaticization patterns of the most frequent epistemic markers, notably the status of \&lt;i\&gt;I think\&lt;/i\&gt; as a discourse marker.},
  language = {en},
  publisher = {{John Benjamins Publishing Company}},
  author = {K\"arkk\"ainen, Elise},
  month = dec,
  year = {2003},
  file = {/home/dan/Zotero/storage/M7SKL5FX/9789027295941.html},
  doi = {10.1075/pbns.115}
}

@book{barlowUsagebasedModelsLanguage2000,
  address = {Stanford, Cal.},
  title = {Usage-Based Models of Language},
  isbn = {978-1-57586-219-4},
  lccn = {410 (U)},
  language = {eng},
  publisher = {{CSLI Pubs}},
  author = {Barlow, Michael and Kemmer, Suzanne},
  year = {2000},
  keywords = {Analysis; Linguistic (Linguistics),g Analysis (Philosophy),g Grammar; Comparative and general,g Linguistics,g Typology (Linguistics),Language and languages,Linguistic analysis (Linguistics) UkShU.,Linguistic models UkShU.,Linguistic science,Linguistics.,Models; Linguistic,Science of language}
}

@article{kingmaAdamMethodStochastic2014,
  archivePrefix = {arXiv},
  eprinttype = {arxiv},
  eprint = {1412.6980},
  primaryClass = {cs},
  title = {Adam: {{A Method}} for {{Stochastic Optimization}}},
  shorttitle = {Adam},
  abstract = {We introduce Adam, an algorithm for first-order gradient-based optimization of stochastic objective functions, based on adaptive estimates of lower-order moments. The method is straightforward to implement, is computationally efficient, has little memory requirements, is invariant to diagonal rescaling of the gradients, and is well suited for problems that are large in terms of data and/or parameters. The method is also appropriate for non-stationary objectives and problems with very noisy and/or sparse gradients. The hyper-parameters have intuitive interpretations and typically require little tuning. Some connections to related algorithms, on which Adam was inspired, are discussed. We also analyze the theoretical convergence properties of the algorithm and provide a regret bound on the convergence rate that is comparable to the best known results under the online convex optimization framework. Empirical results demonstrate that Adam works well in practice and compares favorably to other stochastic optimization methods. Finally, we discuss AdaMax, a variant of Adam based on the infinity norm.},
  language = {en},
  journal = {arXiv:1412.6980 [cs]},
  author = {Kingma, Diederik P. and Ba, Jimmy},
  month = dec,
  year = {2014},
  keywords = {Computer Science - Machine Learning},
  file = {/home/dan/Zotero/storage/D9IV668Y/Kingma and Ba - 2014 - Adam A Method for Stochastic Optimization.pdf},
  annote = {Comment: Published as a conference paper at the 3rd International Conference for Learning Representations, San Diego, 2015}
}

@article{biberStylesStanceEnglish1989,
  title = {{Styles of stance in English: Lexical and grammatical marking of evidentiality and affect}},
  volume = {9},
  issn = {0165-4888},
  shorttitle = {{Styles of stance in English}},
  doi = {10.1515/text.1.1989.9.1.93},
  language = {English (US)},
  number = {1},
  journal = {Text},
  author = {Biber, Douglas},
  year = {1989},
  pages = {93-124},
  file = {/home/dan/Zotero/storage/NREJT69Q/styles-of-stance-in-english-lexical-and-grammatical-marking-of-ev.html}
}

@article{duCognitivefunctionalLinguisticsDialogic2014,
  title = {From Cognitive-Functional Linguistics to Dialogic Syntax},
  volume = {25},
  issn = {1613-3641},
  doi = {10.1515/cog-2014-0023},
  abstract = {Dialogic syntax investigates the linguistic, cognitive, and interactional processes involved when language users reproduce selected aspects of a prior utterance, and when recipients respond to the parallelisms and resonances that result, drawing inferences for situated meaning. The phenomenon typically arises when a language user constructs an utterance modeled in part on the utterance of a prior speaker or author. The result is resonance, defined as the catalytic activation of affinities across utterances. This paper presents the concept of dialogic syntax and outlines some directions of current research on dialogic resonance, as represented in this Special Issue.},
  number = {3},
  journal = {Cognitive Linguistics},
  author = {Du, Bois John W. and Giora, Rachel},
  year = {2014},
  keywords = {affinities,cognitive-functional linguistics,dialogic syntax,dialogicality,parallelism,priming,resonance},
  pages = {351--357},
  file = {/home/dan/Zotero/storage/URQZYVHF/Du and Giora - 2014 - From cognitive-functional linguistics to dialogic .pdf}
}

@incollection{matthewsSubjectivity2014,
  title = {Subjectivity},
  isbn = {978-0-19-967512-8},
  abstract = {In the ordinary sense. Also, following *Benveniste in the 1950s, of the property of language by which utterances reflect},
  language = {en},
  booktitle = {The {{Concise Oxford Dictionary}} of {{Linguistics}}},
  publisher = {{Oxford University Press}},
  author = {Matthews, P. H.},
  year = {2014},
  file = {/home/dan/Zotero/storage/YG9D2HAF/acref-9780199675128-e-3253.html}
}

@book{hunstonEvaluationTextAuthorial2000a,
  title = {Evaluation in {{Text}} : {{Authorial Stance}} and the {{Construction}} of {{Discourse}}: {{Authorial Stance}} and the {{Construction}} of {{Discourse}}},
  isbn = {978-0-19-159109-9},
  shorttitle = {Evaluation in {{Text}}},
  abstract = {A crucial aspect of any discourse is what the writer or speaker thinks about his/her topic - in other words, how the writer or speaker evaluates the topic. Evaluation in Text brings together work from many different perspectives, providing a unique profile of this important topic which will be essential reading for any student or researcher of Discourse Analysis. - ;This is an accessible and wide-ranging account of current research in one of the most central aspects of discourse analsysis: evalution in and of written and spoken language. Evalution is the broad cover term for the expression of a speakers - or writers - attitudes, feelings, and values. It covers areas sometimes referred to as stance, modality, affect or appraisal. Evaluation (a) expresses the speakers opinion and thus reflects the value-system of that person and their community; (b) constructs relations between speaker and hearer (or writer and reader); (c) plays a key role in how discourse is organized. Every act of evalution expresses and contributes to a communal value-system, which in turn is a component of the ideology that lies behind every written or spoken text. Conceptually, evaluation is comparative, subjective, and value-laden. In linguistic terms it may be analysed lexically, grammatically, and textually. These themes and perspectives are richly exemplified in the chapters of this book, by authors aware and observant of the fact that processes of linguistic analysis are themselves inherently evaluative. The editors open the book by introducing the field and provide separate, contextual introductions to each chapter. They have also collated the references into one list, itself a valuable research guide. The exemplary perspectives and analyses presented by the authors will be of central interest to everyone concerned with the analysis of discourse, whether as students of language, literature, or communication. They also have much to offer students of politics and culture. The editors open the book by introducing the field and provide separate, contextual introductions to each chapter. They have also collated the references into one list, itself a valuable research guide. The exemplary perspectives and analyses presented by the authors will be of central interest to everyone concerned with the analysis of discourse, whether as students of language, literature, or communication. They also have much to offer students of politics and culture. -},
  language = {en},
  publisher = {{Oxford University Press, UK}},
  author = {Hunston, Susan and Thompson, Geoffrey},
  month = feb,
  year = {2000}
}

@book{karkkainenEpistemicStanceEnglish2003a,
  title = {Epistemic {{Stance}} in {{English Conversation}}: {{A Description}} of {{Its Interactional Functions}}, with a {{Focus}} on {{I Think}}},
  isbn = {978-1-58811-444-0},
  shorttitle = {Epistemic {{Stance}} in {{English Conversation}}},
  abstract = {This book is the first corpus-based description of epistemic stance in conversational American English. It argues for epistemic stance as a pragmatic rather than semantic notion: showing commitment to the status of information is an emergent interactive activity, rooted in the interaction between conversational co-participants. The first major part of the book establishes the highly regular and routinized nature of such stance marking in the data. The second part offers a micro-analysis of "I think," the prototypical stance marker, in its sequential and activity contexts. Adopting the methodology of conversation analysis and paying serious attention to the manifold prosodic cues attendant in the speakers utterances, the study offers novel situated interpretations of "I think." The author also argues for intonation units as a unit of social interaction and makes observations about the grammaticization patterns of the most frequent epistemic markers, notably the status of "I think" as a discourse marker.},
  language = {en},
  publisher = {{John Benjamins Publishing}},
  author = {K\"arkk\"ainen, Elise},
  year = {2003},
  keywords = {Language Arts \& Disciplines / Linguistics / General}
}

@article{hughesFunctionalcognitiveFrameworkPsychological2016,
  title = {The Functional-Cognitive Framework for Psychological Research: {{Controversies}} and Resolutions},
  volume = {51},
  issn = {1464-066X},
  shorttitle = {The Functional-Cognitive Framework for Psychological Research},
  doi = {10.1002/ijop.12239},
  abstract = {The scientific goals, values and assumptions of functional and cognitive researchers have propelled them down two very different scientific pathways. Many have, and continue to argue, that these differences undermine any potential communication and collaboration between the two traditions. We explore a different view on this debate. Specifically, we focus on the Functional-Cognitive (FC) framework, and in particular, the idea that cognitive and functional researchers can and should interact to the benefit of both. Our article begins with a short introduction to the FC framework. We sweep aside misconceptions about the framework, present the original version as it was outlined by De Houwer (2011) and then offer our most recent thoughts on how it should be implemented. Thereafter, we reflect on its strengths and weaknesses, clarify the functional (effect-centric vs. analytic-abstractive) level and consider its many implications for cognitive research and theorising. In the final section, we briefly review the articles contained in this Special Issue. These contributions provide clear examples of the conceptual, empirical and methodological developments that can emerge when cognitive, clinical, personality and neuroscientists fully engage with the functional-cognitive perspective.},
  language = {eng},
  number = {1},
  journal = {International Journal of Psychology: Journal International De Psychologie},
  author = {Hughes, Sean and De Houwer, Jan and Perugini, Marco},
  month = feb,
  year = {2016},
  keywords = {Adaptation; Psychological,Cognition,Cognitive psychology,Communication,Cooperative Behavior,Functional psychology,Functional-cognitive framework,Humans,Meta-theory,Personality,Psychology,Research,Theory of Mind},
  pages = {4-14},
  pmid = {26616481}
}

@incollection{duboisStanceTriangle2007,
  title = {The {{Stance Triangle}}},
  language = {English},
  booktitle = {Stancetaking in {{Discourse}}: {{Subjectivity}}, Evaluation , Interaction},
  publisher = {{John Benjamins Publishing}},
  author = {Du Bois, John W.},
  year = {2007},
  pages = {139}
}

@article{wangJointEmbeddingWords2018,
  archivePrefix = {arXiv},
  eprinttype = {arxiv},
  eprint = {1805.04174},
  primaryClass = {cs},
  title = {Joint {{Embedding}} of {{Words}} and {{Labels}} for {{Text Classification}}},
  abstract = {Word embeddings are effective intermediate representations for capturing semantic regularities between words, when learning the representations of text sequences. We propose to view text classification as a label-word joint embedding problem: each label is embedded in the same space with the word vectors. We introduce an attention framework that measures the compatibility of embeddings between text sequences and labels. The attention is learned on a training set of labeled samples to ensure that, given a text sequence, the relevant words are weighted higher than the irrelevant ones. Our method maintains the interpretability of word embeddings, and enjoys a built-in ability to leverage alternative sources of information, in addition to input text sequences. Extensive results on the several large text datasets show that the proposed framework outperforms the state-of-the-art methods by a large margin, in terms of both accuracy and speed.},
  language = {en},
  journal = {arXiv:1805.04174 [cs]},
  author = {Wang, Guoyin and Li, Chunyuan and Wang, Wenlin and Zhang, Yizhe and Shen, Dinghan and Zhang, Xinyuan and Henao, Ricardo and Carin, Lawrence},
  month = may,
  year = {2018},
  keywords = {Computer Science - Computation and Language,Computer Science - Machine Learning},
  file = {/home/dan/Zotero/storage/2K9YP8FG/Wang et al. - 2018 - Joint Embedding of Words and Labels for Text Class.pdf},
  annote = {Comment: Published in ACL 2018; Code: https://github.com/guoyinwang/LEAM}
}

@misc{StanceOxfordReference,
  title = {Stance - {{Oxford Reference}}},
  abstract = {$\RHD$noun 1 the way in which someone stands, especially when deliberately adopted (as in cricket, golf, and other sports); a person's posture: she altered her stance, resting all her weight on one leg.way in which someone stands, especially when deliberately adoptedpostureSportstancestances \ding{110}the attitude of a person or organization towards something; a standpoint: the party is changing its stance on Europe.attitude of person or organization towards somethingstance onmental attitude 2 Scottish a site on a street for a market, street vendor's stall, or taxi rank.site on street for market, street vendor's stallmarketplace 3 Climbing a ledge or foothold on which a belay can be secured.ledge or foothold on which belay can be securedindentationMountaineering},
  language = {en},
  howpublished = {http://www.oxfordreference.com/abstract/10.1093/acref/9780199571123.001.0001/m\_en\_gb0808260},
  file = {/home/dan/Zotero/storage/735IGTKL/m_en_gb0808260.html}
}

@article{stubbsMatterProlongedField1986,
  title = {'{{A Matter}} of {{Prolonged Field Work}}': {{Notes Towards}} a {{Modal Grammar}} of {{English1}}},
  volume = {7},
  issn = {0142-6001, 1477-450X},
  shorttitle = {'{{A Matter}} of {{Prolonged Field Work}}'},
  doi = {10.1093/applin/7.1.1},
  language = {en},
  number = {1},
  journal = {Applied Linguistics},
  author = {Stubbs, M.},
  month = jan,
  year = {1986},
  pages = {1-25},
  file = {/home/dan/Zotero/storage/6NK8NTNR/Stubbs - 1986 - 'A Matter of Prolonged Field Work' Notes Towards .pdf}
}

@book{alpaydinIntroductionMachineLearning2014,
  address = {Cambridge, Massachusetts, Piscataqay, New Jersey]},
  edition = {Third edition.},
  series = {Adaptive computation and machine learning},
  title = {Introduction to Machine Learning},
  isbn = {978-0-262-32574-5},
  abstract = {Introduction -- Supervised learning -- Bayesian decision theory -- Parametric methods -- Multivariate methods -- Dimensionality reduction -- Clustering -- Nonparametric methods -- Decision trees -- Linear discrimination -- Multilayer perceptrons -- Local models -- Kernel machines -- Graphical models -- Brief contents -- Hidden markov models -- Bayesian estimation -- Combining multiple learners -- Reinforcement learning -- Design and analysis of machine learning experiments., The goal of machine learning is to program computers to use example data or past experience to solve a given problem. Many successful applications of machine learning exist already, including systems that analyze past sales data to predict customer behavior, optimize robot behavior so that a task can be completed using minimum resources, and extract knowledge from bioinformatics data. Introduction to Machine Learning is a comprehensive textbook on the subject, covering a broad array of topics not usually included in introductory machine learning texts. Subjects include supervised learning; Bayesian decision theory; parametric, semi-parametric, and nonparametric methods; multivariate analysis; hidden Markov models; reinforcement learning; kernel machines; graphical models; Bayesian estimation; and statistical testing.Machine learning is rapidly becoming a skill that computer science students must master before graduation. The third edition of Introduction to Machine Learning reflects this shift, with added support for beginners, including selected solutions for exercises and additional example data sets (with code available online). Other substantial changes include discussions of outlier detection; ranking algorithms for perceptrons and support vector machines; matrix decomposition and spectral methods; distance estimation; new kernel algorithms; deep learning in multilayered perceptrons; and the nonparametric approach to Bayesian methods. All learning algorithms are explained so that students can easily move from the equations in the book to a computer program. The book can be used by both advanced undergraduates and graduate students. It will also be of interest to professionals who are concerned with the application of machine learning methods.},
  language = {eng},
  publisher = {{MIT Press, IEEE Xplore}},
  author = {Alpaydin, Ethem and {author}},
  year = {2014},
  keywords = {Electronic books.,g Artificial intelligence,g Machine theory,Learning; Machine,Machine learning.}
}

@book{wittenDataMiningPractical2011,
  title = {Data Mining: Practical Machine Learning Tools and Techniques},
  isbn = {978-0-12-374856-0},
  shorttitle = {Data Mining},
  abstract = {Data mining: practical machine learning tools and techniques offers a thorough grounding in machine learning concepts as well as practical advice on applying machine learning tools and techniques in real-world data mining situations. This highly anticipated third edition of the most acclaimed work on data mining and machine learning will teach you everything you need to know about preparing inputs, interpreting outputs, evaluating results, and the algorithmic methods at the heart of successful data mining. Thorough updates reflect the technical changes and modernizations that have taken place in the field since the last edition, including new material on Data Transformations, Ensemble Learning, Massive Data Sets, Multi-instance Learning, plus a new version of the popular Weka machine learning software developed by the authors. Witten, Frank and Hall include both tried-and-true techniques of today as well as methods at the leading edge of contemporary research. Summary reprinted by permission of Morgan Kaufmann},
  language = {eng},
  publisher = {{Morgan Kaufmann}},
  author = {Witten, I. and Frank, Eibe and Hall, Mark},
  year = {2011},
  keywords = {Algorithms,Data Analysis,Data Mining,Data Processing,Economics,Java Language}
}

@book{geronHandsonMachineLearning2017,
  address = {Sebastopol, California},
  title = {Hands-on Machine Learning with {{Scikit}}-{{Learn}} and {{TensorFlow}} [Electronic Resource]: Concepts, Tools, and Techniques to Build Intelligent Systems},
  isbn = {978-1-4919-6226-8},
  shorttitle = {Hands-on Machine Learning with {{Scikit}}-{{Learn}} and {{TensorFlow}} [Electronic Resource]},
  language = {eng},
  publisher = {{O'Reilly Media, Inc}},
  author = {G\'eron, Aur\'elien and {author}},
  year = {2017},
  keywords = {g Artificial intelligence,g Machine theory,Learning; Machine,Machine learning.}
}

@article{wuMachineLearningNotation,
  title = {Machine {{Learning Notation}}},
  language = {en},
  author = {Wu, Shan-Hung},
  pages = {2},
  file = {/home/dan/Zotero/storage/75IBMYH8/Wu - Machine Learning Notation.pdf}
}

@book{jurafskySpeechLanguageProcessing,
  edition = {3rd Edition, Draft},
  title = {Speech and {{Language Processing}}},
  author = {Jurafsky, Daniel and Martin, James H.},
  file = {/home/dan/Zotero/storage/6NZCYAW7/slp3.html}
}

@book{manningIntroductionInformationRetrieval2009,
  edition = {Online Edition},
  title = {Introduction to {{Information Retrieval}}},
  language = {en},
  publisher = {{Cambridge University Press}},
  author = {Manning, Christopher and Raghavan, Prabhakar and Schuetze, Hinrich},
  year = {2009},
  file = {/home/dan/Zotero/storage/HTZG2YKN/Manning et al. - 2009 - Introduction to Information Retrieval.pdf}
}

@book{mendelsonAdvancedLecturesMachine2003,
  address = {Berlin Heidelberg},
  series = {Lecture Notes in Computer Science, Lect.Notes Computer. Tutorial},
  title = {Advanced {{Lectures}} on {{Machine Learning}}: {{Machine Learning Summer School}} 2002, {{Canberra}}, {{Australia}}, {{February}} 11-22, 2002, {{Revised Lectures}}},
  isbn = {978-3-540-00529-2},
  shorttitle = {Advanced {{Lectures}} on {{Machine Learning}}},
  abstract = {Machine Learning has become a key enabling technology for many engineering applications and theoretical problems alike. To further discussions and to dis- minate new results, a Summer School was held on February 11\textendash{}22, 2002 at the Australian National University. The current book contains a collection of the main talks held during those two weeks in February, presented as tutorial chapters on topics such as Boosting, Data Mining, Kernel Methods, Logic, Reinforcement Learning, and Statistical Learning Theory. The papers provide an in-depth overview of these exciting new areas, contain a large set of references, and thereby provide the interested reader with further information to start or to pursue his own research in these directions. Complementary to the book, a recorded video of the presentations during the Summer School can be obtained at http://mlg. anu. edu. au/summer2002 It is our hope that graduate students, lecturers, and researchers alike will ?nd this book useful in learning and teaching Machine Learning, thereby continuing the mission of the Summer School. Canberra, November 2002 Shahar Mendelson Alexander Smola Research School of Information Sciences and Engineering, The Australian National University Thanks and Acknowledgments We gratefully thank all the individuals and organizations responsible for the success of the workshop.},
  language = {en},
  publisher = {{Springer-Verlag}},
  editor = {Mendelson, Shahar and Smola, Alexander J.},
  year = {2003},
  file = {/home/dan/Zotero/storage/V47DZUDY/9783540005292.html}
}

@article{saltonVectorSpaceModel1975,
  title = {A Vector Space Model for Automatic Indexing},
  volume = {18},
  issn = {00010782},
  doi = {10.1145/361219.361220},
  language = {en},
  number = {11},
  journal = {Communications of the ACM},
  author = {Salton, G. and Wong, A. and Yang, C. S.},
  month = nov,
  year = {1975},
  pages = {613-620},
  file = {/home/dan/Zotero/storage/TG4AMJYS/Salton et al. - 1975 - A vector space model for automatic indexing.pdf}
}

@book{bishopPatternRecognitionMachine2006,
  address = {New York},
  series = {Information science and statistics},
  title = {Pattern Recognition and Machine Learning},
  isbn = {978-0-387-31073-2},
  lccn = {Q327 .B52 2006},
  language = {en},
  publisher = {{Springer}},
  author = {Bishop, Christopher M.},
  year = {2006},
  keywords = {Machine learning,Pattern perception},
  file = {/home/dan/Zotero/storage/TJYZNVF3/Bishop - 2006 - Pattern recognition and machine learning.pdf}
}

@article{tsoumakasMultiLabelClassificationOverview2007,
  title = {Multi-{{Label Classification}}: {{An Overview}}},
  volume = {3},
  issn = {1548-3924},
  shorttitle = {Multi-{{Label Classification}}},
  abstract = {Multi-label classification methods are increasingly required by modern applications, such as protein function classification, music categorization, and semantic scene classification. This article introduces the task of multi-label classification, organizes the sparse related literature into a structured presentation and performs comparative experimental results of certain multilabel classification methods. It also contributes the definition of concepts for the quantification of the multi-label nature of a data set.},
  number = {3},
  journal = {International Journal of Data Warehousing and Mining (IJDWM)},
  author = {Tsoumakas, Grigorios and Katakis, Ioannis},
  year = {2007},
  pages = {1-13},
  file = {/home/dan/Zotero/storage/YZWNA85F/v_3a3_3ay_3a2007_3ai_3a3_3ap_3a1-13.html}
}

@incollection{tsoumakasMiningMultilabelData2009,
  title = {Mining {{Multi}}-Label {{Data}}},
  isbn = {978-0-387-09822-7 978-0-387-09823-4},
  abstract = {A large body of research in supervised learning deals with the analysis of single-label data, where training examples are associated with a single label $\lambda$ from a set of disjoint labels L. However, training examples in several application domains are often associated with a set of labels Y $\subseteq$ L. Such data are called multi-label.Textual data, such as documents and web pages, are frequently annotated with more than a single label. For example, a news article concerning the reactions of the Christian church to the release of the ``Da Vinci Code'' film can be labeled as both religion and movies. The categorization of textual data is perhaps the dominant multi-label application.},
  language = {en},
  booktitle = {Data {{Mining}} and {{Knowledge Discovery Handbook}}},
  publisher = {{Springer, Boston, MA}},
  author = {Tsoumakas, Grigorios and Katakis, Ioannis and Vlahavas, Ioannis},
  year = {2009},
  pages = {667-685},
  file = {/home/dan/Zotero/storage/HX9VBM6W/978-0-387-09823-4_34.html},
  doi = {10.1007/978-0-387-09823-4_34}
}

@inproceedings{zhangMultilabelLearningExploiting2010,
  address = {Washington, DC, USA},
  title = {Multi-Label Learning by Exploiting Label Dependency},
  isbn = {978-1-4503-0055-1},
  doi = {10.1145/1835804.1835930},
  abstract = {In multi-label learning, each training example is associated with a set of labels and the task is to predict the proper label set for the unseen example. Due to the tremendous (exponential) number of possible label sets, the task of learning from multi-label examples is rather challenging. Therefore, the key to successful multi-label learning is how to effectively exploit correlations between different labels to facilitate the learning process. In this paper, we propose to use a Bayesian network structure to efficiently encode the conditional dependencies of the labels as well as the feature set, with the feature set as the common parent of all labels. To make it practical, we give an approximate yet efficient procedure to find such a network structure. With the help of this network, multi-label learning is decomposed into a series of single-label classification problems, where a classifier is constructed for each label by incorporating its parental labels as additional features. Label sets of unseen examples are predicted recursively according to the label ordering given by the network. Extensive experiments on a broad range of data sets validate the effectiveness of our approach against other well-established methods.},
  language = {en},
  booktitle = {Proceedings of the 16th {{ACM SIGKDD}} International Conference on {{Knowledge}} Discovery and Data Mining - {{KDD}} '10},
  publisher = {{ACM Press}},
  author = {Zhang, Min-Ling and Zhang, Kun},
  year = {2010},
  pages = {999},
  file = {/home/dan/Zotero/storage/VPLPCQGI/Zhang and Zhang - 2010 - Multi-label learning by exploiting label dependenc.pdf}
}

@article{zhangSurveyMultiTaskLearning2017,
  archivePrefix = {arXiv},
  eprinttype = {arxiv},
  eprint = {1707.08114},
  primaryClass = {cs},
  title = {A {{Survey}} on {{Multi}}-{{Task Learning}}},
  abstract = {Multi-Task Learning (MTL) is a learning paradigm in machine learning and its aim is to leverage useful information contained in multiple related tasks to help improve the generalization performance of all the tasks. In this paper, we give a survey for MTL. First, we classify different MTL algorithms into several categories, including feature learning approach, low-rank approach, task clustering approach, task relation learning approach, and decomposition approach, and then discuss the characteristics of each approach. In order to improve the performance of learning tasks further, MTL can be combined with other learning paradigms including semi-supervised learning, active learning, unsupervised learning, reinforcement learning, multi-view learning and graphical models. When the number of tasks is large or the data dimensionality is high, batch MTL models are difficult to handle this situation and online, parallel and distributed MTL models as well as dimensionality reduction and feature hashing are reviewed to reveal their computational and storage advantages. Many real-world applications use MTL to boost their performance and we review representative works.},
  language = {en},
  journal = {arXiv:1707.08114 [cs]},
  author = {Zhang, Yu and Yang, Qiang},
  month = jul,
  year = {2017},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Machine Learning},
  file = {/home/dan/Zotero/storage/JUBVBVTJ/Zhang and Yang - 2017 - A Survey on Multi-Task Learning.pdf}
}

@article{pengDeepMultitaskLearning2017,
  archivePrefix = {arXiv},
  eprinttype = {arxiv},
  eprint = {1704.06855},
  primaryClass = {cs},
  title = {Deep {{Multitask Learning}} for {{Semantic Dependency Parsing}}},
  abstract = {We present a deep neural architecture that parses sentences into three semantic dependency graph formalisms. By using efficient, nearly arc-factored inference and a bidirectional-LSTM composed with a multi-layer perceptron, our base system is able to significantly improve the state of the art for semantic dependency parsing, without using hand-engineered features or syntax. We then explore two multitask learning approaches\textemdash{}one that shares parameters across formalisms, and one that uses higher-order structures to predict the graphs jointly. We find that both approaches improve performance across formalisms on average, achieving a new state of the art. Our code is open-source and available at https://github.com/ Noahs-ARK/NeurboParser.},
  language = {en},
  journal = {arXiv:1704.06855 [cs]},
  author = {Peng, Hao and Thomson, Sam and Smith, Noah A.},
  month = apr,
  year = {2017},
  keywords = {Computer Science - Computation and Language},
  file = {/home/dan/Zotero/storage/WUP2B46Q/Peng et al. - 2017 - Deep Multitask Learning for Semantic Dependency Pa.pdf},
  annote = {Comment: Proceedings of ACL 2017}
}

@article{ruderOverviewMultiTaskLearning2017,
  archivePrefix = {arXiv},
  eprinttype = {arxiv},
  eprint = {1706.05098},
  primaryClass = {cs, stat},
  title = {An {{Overview}} of {{Multi}}-{{Task Learning}} in {{Deep Neural Networks}}},
  abstract = {Multi-task learning (MTL) has led to successes in many applications of machine learning, from natural language processing and speech recognition to computer vision and drug discovery. This article aims to give a general overview of MTL, particularly in deep neural networks. It introduces the two most common methods for MTL in Deep Learning, gives an overview of the literature, and discusses recent advances. In particular, it seeks to help ML practitioners apply MTL by shedding light on how MTL works and providing guidelines for choosing appropriate auxiliary tasks.},
  journal = {arXiv:1706.05098 [cs, stat]},
  author = {Ruder, Sebastian},
  month = jun,
  year = {2017},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Machine Learning,Statistics - Machine Learning},
  file = {/home/dan/Zotero/storage/6IBGC7CB/Ruder - 2017 - An Overview of Multi-Task Learning in Deep Neural .pdf;/home/dan/Zotero/storage/RGHIJ2RF/1706.html},
  annote = {Comment: 14 pages, 8 figures}
}

@inproceedings{sariContinuousNgramRepresentations2017,
  address = {Valencia, Spain},
  title = {Continuous {{N}}-Gram {{Representations}} for {{Authorship Attribution}}},
  doi = {10.18653/v1/E17-2043},
  abstract = {This paper presents work on using continuous representations for authorship attribution. In contrast to previous work, which uses discrete feature representations, our model learns continuous representations for n-gram features via a neural network jointly with the classification layer. Experimental results demonstrate that the proposed model outperforms the state-of-the-art on two datasets, while producing comparable results on the remaining two.},
  language = {en},
  booktitle = {Proceedings of the 15th {{Conference}} of the {{European Chapter}} of the           {{Association}} for {{Computational Linguistics}}: {{Volume}} 2, {{Short Papers}}},
  publisher = {{Association for Computational Linguistics}},
  author = {Sari, Yunita and Vlachos, Andreas and Stevenson, Mark},
  year = {2017},
  pages = {267-273},
  file = {/home/dan/Zotero/storage/742XB3SI/Sari et al. - 2017 - Continuous N-gram Representations for Authorship A.pdf}
}

@article{srikumarLearningDistributedRepresentations,
  title = {Learning {{Distributed Representations}} for {{Structured Output Prediction}}},
  abstract = {In recent years, distributed representations of inputs have led to performance gains in many applications by allowing statistical information to be shared across inputs. However, the predicted outputs (labels, and more generally structures) are still treated as discrete objects even though outputs are often not discrete units of meaning. In this paper, we present a new formulation for structured prediction where we represent individual labels in a structure as dense vectors and allow semantically similar labels to share parameters. We extend this representation to larger structures by defining compositionality using tensor products to give a natural generalization of standard structured prediction approaches. We define a learning objective for jointly learning the model parameters and the label vectors and propose an alternating minimization algorithm for learning. We show that our formulation outperforms structural SVM baselines in two tasks: multiclass document classification and part-of-speech tagging.},
  language = {en},
  author = {Srikumar, Vivek and Manning, Christopher D},
  pages = {9},
  file = {/home/dan/Zotero/storage/722VQMGV/Srikumar and Manning - Learning Distributed Representations for Structure.pdf}
}

@article{ribeiroAnchorsHighPrecision,
  title = {Anchors: {{High Precision Model}}-{{Agnostic Explanations}}},
  abstract = {We introduce a novel model-agnostic system that explains the behavior of complex models with high-precision rules called anchors, representing local, ``sufficient'' conditions for predictions. We propose an algorithm to efficiently compute these explanations for any black-box model with high-probability guarantees. We demonstrate the flexibility of anchors by explaining a myriad of different models for different domains and tasks. In a user study, we show that anchors enable users to predict how a model would behave on unseen instances with less effort and higher precision, as compared to existing linear explanations or no explanations.},
  language = {en},
  author = {Ribeiro, Marco Tulio and Singh, Sameer and Guestrin, Carlos},
  pages = {9},
  file = {/home/dan/Zotero/storage/V9CLXKH8/Ribeiro et al. - Anchors High Precision Model-Agnostic Explanation.pdf}
}

@article{martinsSoftmaxSparsemaxSparse2016,
  archivePrefix = {arXiv},
  eprinttype = {arxiv},
  eprint = {1602.02068},
  primaryClass = {cs, stat},
  title = {From {{Softmax}} to {{Sparsemax}}: {{A Sparse Model}} of {{Attention}} and {{Multi}}-{{Label Classification}}},
  shorttitle = {From {{Softmax}} to {{Sparsemax}}},
  abstract = {We propose sparsemax, a new activation function similar to the traditional softmax, but able to output sparse probabilities. After deriving its properties, we show how its Jacobian can be efficiently computed, enabling its use in a network trained with backpropagation. Then, we propose a new smooth and convex loss function which is the sparsemax analogue of the logistic loss. We reveal an unexpected connection between this new loss and the Huber classification loss. We obtain promising empirical results in multi-label classification problems and in attention-based neural networks for natural language inference. For the latter, we achieve a similar performance as the traditional softmax, but with a selective, more compact, attention focus.},
  language = {en},
  journal = {arXiv:1602.02068 [cs, stat]},
  author = {Martins, Andr\'e F. T. and Astudillo, Ram\'on Fernandez},
  month = feb,
  year = {2016},
  keywords = {Computer Science - Computation and Language,Computer Science - Machine Learning,Statistics - Machine Learning},
  file = {/home/dan/Zotero/storage/2YVT5RRU/Martins and Astudillo - 2016 - From Softmax to Sparsemax A Sparse Model of Atten.pdf},
  annote = {Comment: Minor corrections}
}

@inproceedings{ferreiraEmergentNovelDataset2016,
  address = {San Diego, California},
  title = {Emergent: A Novel Data-Set for Stance Classification},
  shorttitle = {Emergent},
  doi = {10.18653/v1/N16-1138},
  abstract = {We present Emergent, a novel data-set derived from a digital journalism project for rumour debunking. The data-set contains 300 rumoured claims and 2,595 associated news articles, collected and labelled by journalists with an estimation of their veracity (true, false or unverified). Each associated article is summarized into a headline and labelled to indicate whether its stance is for, against, or observing the claim, where observing indicates that the article merely repeats the claim. Thus, Emergent provides a real-world data source for a variety of natural language processing tasks in the context of fact-checking. Further to presenting the dataset, we address the task of determining the article headline stance with respect to the claim. For this purpose we use a logistic regression classifier and develop features that examine the headline and its agreement with the claim. The accuracy achieved was 73\% which is 26\% higher than the one achieved by the Excitement Open Platform (Magnini et al., 2014).},
  language = {en},
  booktitle = {Proceedings of the 2016 {{Conference}} of the {{North American Chapter}} of the {{Association}} for {{Computational Linguistics}}: {{Human Language Technologies}}},
  publisher = {{Association for Computational Linguistics}},
  author = {Ferreira, William and Vlachos, Andreas},
  year = {2016},
  pages = {1163-1168},
  file = {/home/dan/Zotero/storage/TCNUR47T/Ferreira and Vlachos - 2016 - Emergent a novel data-set for stance classificati.pdf}
}

@book{pattersonDeepLearningPractitioner2017,
  address = {Beijing, [China]},
  title = {Deep Learning: A Practitioner's Approach},
  isbn = {978-1-4919-1423-6},
  shorttitle = {Deep Learning},
  language = {eng},
  publisher = {{O'Reilly Media}},
  author = {Patterson, Josh and {author}},
  collaborator = {{Adam Gibson author}},
  year = {2017},
  keywords = {g Artificial intelligence,g Machine theory,Learning; Machine,Machine learning.,Artificial neural networks,g Natural computation,g Soft computing,Nets; Neural (Computer science),Networks; Neural (Computer science),Neural nets (Computer science),Neural networks (Computer science)}
}

@misc{ReadSpeechLanguage,
  title = {Read: {{Speech}} and {{Language Processing}}: {{Pearson New International Edition}}},
  howpublished = {https://www.dawsonera.com/readonline/9781292037936},
  file = {/home/dan/Zotero/storage/VR594S6K/9781292037936.html}
}

@misc{HowManyWords,
  title = {How Many Words Are There in the {{Engli}}... | {{Oxford Dictionaries}}},
  abstract = {How many words are there in the English language? This question might be much more difficult to answer that you thought. This article explains why.},
  howpublished = {https://en.oxforddictionaries.com/explore/how-many-words-are-there-in-the-english-language/},
  journal = {Oxford Dictionaries | English},
  file = {/home/dan/Zotero/storage/MRGHV49L/how-many-words-are-there-in-the-english-language.html}
}

@article{sahlgrenDistributionalHypothesis,
  title = {The Distributional Hypothesis},
  language = {en},
  author = {Sahlgren, Magnus},
  pages = {18},
  file = {/home/dan/Zotero/storage/IWNCNHMZ/Sahlgren - The distributional hypothesis.pdf}
}

@article{sahlgren2008distributional,
  title = {The Distributional Hypothesis},
  volume = {20},
  journal = {Italian Journal of Disability Studies},
  author = {Sahlgren, Magnus},
  year = {2008},
  pages = {33-53}
}

@inproceedings{penningtonGloveGlobalVectors2014,
  address = {Doha, Qatar},
  title = {Glove: {{Global Vectors}} for {{Word Representation}}},
  shorttitle = {Glove},
  doi = {10.3115/v1/D14-1162},
  abstract = {Recent methods for learning vector space representations of words have succeeded in capturing fine-grained semantic and syntactic regularities using vector arithmetic, but the origin of these regularities has remained opaque. We analyze and make explicit the model properties needed for such regularities to emerge in word vectors. The result is a new global logbilinear regression model that combines the advantages of the two major model families in the literature: global matrix factorization and local context window methods. Our model efficiently leverages statistical information by training only on the nonzero elements in a word-word cooccurrence matrix, rather than on the entire sparse matrix or on individual context windows in a large corpus. The model produces a vector space with meaningful substructure, as evidenced by its performance of 75\% on a recent word analogy task. It also outperforms related models on similarity tasks and named entity recognition.},
  language = {en},
  booktitle = {Proceedings of the 2014 {{Conference}} on {{Empirical Methods}} in {{Natural Language Processing}} ({{EMNLP}})},
  publisher = {{Association for Computational Linguistics}},
  author = {Pennington, Jeffrey and Socher, Richard and Manning, Christopher},
  year = {2014},
  pages = {1532-1543},
  file = {/home/dan/Zotero/storage/NIFA2JYR/Pennington et al. - 2014 - Glove Global Vectors for Word Representation.pdf}
}

@article{joulinBagTricksEfficient2016,
  archivePrefix = {arXiv},
  eprinttype = {arxiv},
  eprint = {1607.01759},
  primaryClass = {cs},
  title = {Bag of {{Tricks}} for {{Efficient Text Classification}}},
  abstract = {This paper explores a simple and efficient baseline for text classification. Our experiments show that our fast text classifier fastText is often on par with deep learning classifiers in terms of accuracy, and many orders of magnitude faster for training and evaluation. We can train fastText on more than one billion words in less than ten minutes using a standard multicore CPU, and classify half a million sentences among 312K classes in less than a minute.},
  language = {en},
  journal = {arXiv:1607.01759 [cs]},
  author = {Joulin, Armand and Grave, Edouard and Bojanowski, Piotr and Mikolov, Tomas},
  month = jul,
  year = {2016},
  keywords = {Computer Science - Computation and Language},
  file = {/home/dan/Zotero/storage/KJ2UCTB8/Joulin et al. - 2016 - Bag of Tricks for Efficient Text Classification.pdf}
}

@article{mikolovEfficientEstimationWord2013,
  archivePrefix = {arXiv},
  eprinttype = {arxiv},
  eprint = {1301.3781},
  primaryClass = {cs},
  title = {Efficient {{Estimation}} of {{Word Representations}} in {{Vector Space}}},
  abstract = {We propose two novel model architectures for computing continuous vector representations of words from very large data sets. The quality of these representations is measured in a word similarity task, and the results are compared to the previously best performing techniques based on different types of neural networks. We observe large improvements in accuracy at much lower computational cost, i.e. it takes less than a day to learn high quality word vectors from a 1.6 billion words data set. Furthermore, we show that these vectors provide state-of-the-art performance on our test set for measuring syntactic and semantic word similarities.},
  language = {en},
  journal = {arXiv:1301.3781 [cs]},
  author = {Mikolov, Tomas and Chen, Kai and Corrado, Greg and Dean, Jeffrey},
  month = jan,
  year = {2013},
  keywords = {Computer Science - Computation and Language},
  file = {/home/dan/Zotero/storage/VJAX7ZET/Mikolov et al. - 2013 - Efficient Estimation of Word Representations in Ve.pdf}
}

@inproceedings{deyTwitterStanceDetection2017,
  title = {Twitter {{Stance Detection}} \textemdash{} {{A Subjectivity}} and {{Sentiment Polarity Inspired Two}}-{{Phase Approach}}},
  doi = {10.1109/ICDMW.2017.53},
  abstract = {The problem of stance detection from Twitter tweets, has recently gained significant research attention. This paper addresses the problem of detecting the stance of given tweets, with respect to given topics, from user-generated text (tweets). We use the SemEval 2016 stance detection task dataset. The labels comprise of positive, negative and neutral stances, with respect to given topics. We develop a two-phase feature-driven model. First, the tweets are classified as neutral vs. non-neutral. Next, non-neutral tweets are classified as positive vs. negative. The first phase of our work draws inspiration from the subjectivity classification and the second phase from the sentiment classification literature. We propose the use of two novel features, which along with our streamlined approach, plays a key role deriving the strong results that we obtain. We use traditional support vector machine (SVM) based machine learning. Our system (F-score: 74.44 for SemEval 2016 Task A and 61.57 for Task B) significantly outperforms the state of the art (F-score: 68.98 for Task A and 56.28 for Task B). While the performance of the system on Task A shows the effectiveness of our model for targets on which the model was trained upon, the performance of the system on Task B shows the generalization that our model achieves. The stance detection problem in Twitter is applicable for user opinion mining related applications and other social influence and information flow modeling applications, in real life.},
  booktitle = {2017 {{IEEE International Conference}} on {{Data Mining Workshops}} ({{ICDMW}})},
  author = {Dey, K. and Shrivastava, R. and Kaushik, S.},
  month = nov,
  year = {2017},
  keywords = {learning (artificial intelligence),natural language processing,Machine learning,Benchmark testing,data mining,Feature extraction,machine learning,negative stances,neutral stances,nonneutral tweets,pattern classification,positive stances,SemEval 2016 stance detection,sentiment classification literature,sentiment polarity inspired two phase,social networking (online),stance detection on Twitter,stance detection problem,subjectivity classification,subjectivity polarity inspired two phase,support vector machine,support vector machines,Support vector machines,text,text analysis,Twitter,Twitter stance detection,Twitter tweets,two-phase feature-driven model},
  pages = {365-372},
  file = {/home/dan/Zotero/storage/8Q52VYZ9/Dey et al. - 2017 - Twitter Stance Detection — A Subjectivity and Sent.pdf;/home/dan/Zotero/storage/LAJNEZQK/8215685.html}
}

@article{rakholiaItTrueDeep,
  title = {``{{Is}} It True?'' \textendash{} {{Deep Learning}} for {{Stance Detection}} in {{News}}},
  abstract = {Stance detection is an important component of fake news detection. In this project we explore different neural net architectures for stance detection in news articles. In particular, we analyze the effectiveness of recurrent neural nets for this problem. We discover that a modified attentive reader model is well suited for the task. While our best deep learning model comfortably exceeds the baseline score set by Fake News Challenge, a simple feedforward network marginally outperforms it. As far as we are aware, our LSTM-based RNN model is the state of the art end-to-end deep learning model for this dataset.},
  language = {en},
  author = {Rakholia, Neel and Bhargava, Shruti},
  pages = {14},
  file = {/home/dan/Zotero/storage/RWYQXBE9/Rakholia and Bhargava - “Is it true” – Deep Learning for Stance Detection.pdf}
}

@inproceedings{mohammadSemEval2016TaskDetecting2016,
  address = {San Diego, California},
  title = {{{SemEval}}-2016 {{Task}} 6: {{Detecting Stance}} in {{Tweets}}},
  shorttitle = {{{SemEval}}-2016 {{Task}} 6},
  doi = {10.18653/v1/S16-1003},
  abstract = {Here for the first time we present a shared task on detecting stance from tweets: given a tweet and a target entity (person, organization, etc.), automatic natural language systems must determine whether the tweeter is in favor of the given target, against the given target, or whether neither inference is likely. The target of interest may or may not be referred to in the tweet, and it may or may not be the target of opinion. Two tasks are proposed. Task A is a traditional supervised classification task where 70\% of the annotated data for a target is used as training and the rest for testing. For Task B, we use as test data all of the instances for a new target (not used in task A) and no training data is provided. Our shared task received submissions from 19 teams for Task A and from 9 teams for Task B. The highest classification F-score obtained was 67.82 for Task A and 56.28 for Task B. However, systems found it markedly more difficult to infer stance towards the target of interest from tweets that express opinion towards another entity.},
  language = {en},
  booktitle = {Proceedings of the 10th {{International Workshop}} on {{Semantic Evaluation}} ({{SemEval}}-2016)},
  publisher = {{Association for Computational Linguistics}},
  author = {Mohammad, Saif and Kiritchenko, Svetlana and Sobhani, Parinaz and Zhu, Xiaodan and Cherry, Colin},
  year = {2016},
  pages = {31-41},
  file = {/home/dan/Zotero/storage/WIFTYJYS/Mohammad et al. - 2016 - SemEval-2016 Task 6 Detecting Stance in Tweets.pdf}
}

@article{sobhaniStanceDetectionAnalysis,
  title = {Stance {{Detection}} and {{Analysis}} in {{Social Media}}},
  language = {en},
  author = {Sobhani, Parinaz},
  pages = {137},
  file = {/home/dan/Zotero/storage/983IBVXZ/Sobhani - Stance Detection and Analysis in Social Media.pdf}
}

@inproceedings{deyTopicalStanceDetection2018,
  series = {Lecture Notes in Computer Science},
  title = {Topical {{Stance Detection}} for {{Twitter}}: {{A Two}}-{{Phase LSTM Model Using Attention}}},
  isbn = {978-3-319-76940-0 978-3-319-76941-7},
  shorttitle = {Topical {{Stance Detection}} for {{Twitter}}},
  doi = {10.1007/978-3-319-76941-7_40},
  abstract = {The topical stance detection problem addresses detecting the stance of the text content with respect to a given topic: whether the sentiment of the given text content is in favor of (positive), is against (negative), or is none (neutral) towards the given topic. Using the concept of attention, we develop a two-phase solution. In the first phase, we classify subjectivity - whether a given tweet is neutral or subjective with respect to the given topic. In the second phase, we classify sentiment of the subjective tweets (ignoring the neutral tweets) - whether a given subjective tweet has a favor or against stance towards the topic. We propose a Long Short-Term memory (LSTM) based deep neural network for each phase, and embed attention at each of the phases. On the SemEval 2016 stance detection Twitter task dataset [7], we obtain a best-case macro F-score of 68.84\% and a best-case accuracy of 60.2\%, outperforming the existing deep learning based solutions. Our framework, T-PAN, is the first in the topical stance detection literature, that uses deep learning within a two-phase architecture.},
  language = {en},
  booktitle = {Advances in {{Information Retrieval}}},
  publisher = {{Springer, Cham}},
  author = {Dey, Kuntal and Shrivastava, Ritvik and Kaushik, Saroj},
  month = mar,
  year = {2018},
  pages = {529-536},
  file = {/home/dan/Zotero/storage/7NYZR384/Dey et al. - 2018 - Topical Stance Detection for Twitter A Two-Phase .pdf;/home/dan/Zotero/storage/WX86U4PB/978-3-319-76941-7_40.html}
}

@misc{MultiModalStanceDetection,
  title = {{{MultiModal Stance Detection}} in Tweets on {{Catalan 1Oct Referendum}} ({{MultiStanceCat}})},
  language = {en-GB},
  file = {/home/dan/Zotero/storage/QF8WPPCD/MultiStanceCat-IberEval2018.html}
}

@article{respallStanceDetectionCatalan,
  title = {Stance {{Detection}} in {{Catalan}} and {{Spanish Tweets}}},
  abstract = {Stance is given an ongoing interaction, the way speakers place themselves in it. In this paper we describe a simple technique for stance detection using Independence of Catalonia tweets. We have used word2vec word embedding (Mikolov, 2013) features for this detection. Our system had produce a best result for Spanish tweets as compare to other participants in IberEval 2017.},
  language = {en},
  author = {Respall, Victor Massague and Derczynski, Leon},
  pages = {3},
  file = {/home/dan/Zotero/storage/MWXR5HMP/Respall and Derczynski - Stance Detection in Catalan and Spanish Tweets.pdf}
}

@article{duStanceClassificationTargetspecific,
  title = {Stance {{Classification}} with {{Target}}-Specific {{Neural Attention}}},
  abstract = {Stance classification, which aims at detecting the stance expressed in text towards a specific target, is an emerging problem in sentiment analysis. A major difference between stance classification and traditional aspect-level sentiment classification is that the identification of stance is dependent on target which might not be explicitly mentioned in text. This indicates that apart from text content, the target information is important to stance detection. To this end, we propose a neural network-based model, which incorporates target-specific information into stance classification by following a novel attention mechanism. In specific, the attention mechanism is expected to locate the critical parts of text which are related to target. Our evaluations on both the English and Chinese Stance Detection datasets show that the proposed model achieves the state-of-theart performance.},
  language = {en},
  author = {Du, Jiachen and Xu, Ruifeng and He, Yulan and Gui, Lin},
  pages = {7},
  file = {/home/dan/Zotero/storage/99RRL2WW/Du et al. - Stance Classification with Target-specific Neural .pdf}
}

@misc{FakeNewsChallenge,
  title = {Fake {{News Challenge}}},
  howpublished = {http://www.fakenewschallenge.org/},
  file = {/home/dan/Zotero/storage/L9PPX6EV/www.fakenewschallenge.org.html}
}

@article{liuSentimentAnalysisOpinion,
  title = {Sentiment {{Analysis}} and {{Opinion Mining}}},
  language = {en},
  author = {Liu, Bing},
  pages = {168},
  file = {/home/dan/Zotero/storage/XIXV7FB9/Liu - Sentiment Analysis and Opinion Mining.pdf}
}

@article{hanselowskiRetrospectiveAnalysisFake2018,
  archivePrefix = {arXiv},
  eprinttype = {arxiv},
  eprint = {1806.05180},
  primaryClass = {cs},
  title = {A {{Retrospective Analysis}} of the {{Fake News Challenge Stance Detection Task}}},
  abstract = {The 2017 Fake News Challenge Stage 1 (FNC-1) shared task addressed a stance classification task as a crucial first step towards detecting fake news. To date, there is no in-depth analysis paper to critically discuss FNC-1's experimental setup, reproduce the results, and draw conclusions for next-generation stance classification methods. In this paper, we provide such an in-depth analysis for the three top-performing systems. We first find that FNC-1's proposed evaluation metric favors the majority class, which can be easily classified, and thus overestimates the true discriminative power of the methods. Therefore, we propose a new F1-based metric yielding a changed system ranking. Next, we compare the features and architectures used, which leads to a novel feature-rich stacked LSTM model that performs on par with the best systems, but is superior in predicting minority classes. To understand the methods' ability to generalize, we derive a new dataset and perform both in-domain and cross-domain experiments. Our qualitative and quantitative study helps interpreting the original FNC-1 scores and understand which features help improving performance and why. Our new dataset and all source code used during the reproduction study are publicly available for future research1.},
  language = {en},
  journal = {arXiv:1806.05180 [cs]},
  author = {Hanselowski, Andreas and PVS, Avinesh and Schiller, Benjamin and Caspelherr, Felix and Chaudhuri, Debanjan and Meyer, Christian M. and Gurevych, Iryna},
  month = jun,
  year = {2018},
  keywords = {Computer Science - Computation and Language,Computer Science - Artificial Intelligence,Computer Science - Information Retrieval,Computer Science - Social and Information Networks},
  file = {/home/dan/Zotero/storage/H9X8CMXG/Hanselowski et al. - 2018 - A Retrospective Analysis of the Fake News Challeng.pdf}
}

@misc{StanceGenderDetection,
  title = {Stance and {{Gender Detection}} in {{Tweets}} on {{Catalan Independence}} - {{IBEREVAL}} 2017},
  howpublished = {http://stel.ub.edu/Stance-IberEval2017/},
  file = {/home/dan/Zotero/storage/5R975HFI/Stance-IberEval2017.html}
}

@article{hochreiterLongShorttermMemory1997,
  title = {Long Short-Term Memory},
  volume = {9},
  issn = {0899-7667},
  abstract = {Learning to store information over extended time intervals by recurrent backpropagation takes a very long time, mostly because of insufficient, decaying error backflow. We briefly review Hochreiter's (1991) analysis of this problem, then address it by introducing a novel, efficient, gradient-based method called long short-term memory (LSTM). Truncating the gradient where this does not do harm, LSTM can learn to bridge minimal time lags in excess of 1000 discrete-time steps by enforcing constant error flow through constant error carousels within special units. Multiplicative gate units learn to open and close access to the constant error flow. LSTM is local in space and time; its computational complexity per time step and weight is O(1). Our experiments with artificial data involve local, distributed, real-valued, and noisy pattern representations. In comparisons with real-time recurrent learning, back propagation through time, recurrent cascade correlation, Elman nets, and neural sequence chunking, LSTM leads to many more successful runs, and learns much faster. LSTM also solves complex, artificial long-time-lag tasks that have never been solved by previous recurrent network algorithms.},
  language = {eng},
  number = {8},
  journal = {Neural Computation},
  author = {Hochreiter, S. and Schmidhuber, J.},
  month = nov,
  year = {1997},
  keywords = {Algorithms,Learning,Memory,Memory; Short-Term,Models; Neurological,Models; Psychological,Nerve Net,Neural Networks (Computer),Time Factors},
  pages = {1735-1780},
  pmid = {9377276}
}

@misc{SubjectivityLexiconMPQA,
  title = {Subjectivity {{Lexicon}} | {{MPQA}}},
  howpublished = {https://mpqa.cs.pitt.edu/lexicons/subj\_lexicon/},
  file = {/home/dan/Zotero/storage/YDDHZD9I/subj_lexicon.html}
}

@misc{WordNetLexicalDatabase,
  title = {{{WordNet}} | {{A Lexical Database}} for {{English}}},
  howpublished = {https://wordnet.princeton.edu/},
  file = {/home/dan/Zotero/storage/Q6UWGRR7/wordnet.princeton.edu.html}
}

@misc{SentiWordNet,
  title = {{{SentiWordNet}}},
  howpublished = {http://sentiwordnet.isti.cnr.it/},
  file = {/home/dan/Zotero/storage/WQP6C4LS/sentiwordnet.isti.cnr.it.html}
}

@article{mohammadStanceSentimentTweets2016a,
  archivePrefix = {arXiv},
  eprinttype = {arxiv},
  eprint = {1605.01655},
  primaryClass = {cs},
  title = {Stance and {{Sentiment}} in {{Tweets}}},
  abstract = {We can often detect from a person's utterances whether he/she is in favor of or against a given target entity -- their stance towards the target. However, a person may express the same stance towards a target by using negative or positive language. Here for the first time we present a dataset of tweet--target pairs annotated for both stance and sentiment. The targets may or may not be referred to in the tweets, and they may or may not be the target of opinion in the tweets. Partitions of this dataset were used as training and test sets in a SemEval-2016 shared task competition. We propose a simple stance detection system that outperforms submissions from all 19 teams that participated in the shared task. Additionally, access to both stance and sentiment annotations allows us to explore several research questions. We show that while knowing the sentiment expressed by a tweet is beneficial for stance classification, it alone is not sufficient. Finally, we use additional unlabeled data through distant supervision techniques and word embeddings to further improve stance classification.},
  language = {en},
  journal = {arXiv:1605.01655 [cs]},
  author = {Mohammad, Saif M. and Sobhani, Parinaz and Kiritchenko, Svetlana},
  month = may,
  year = {2016},
  keywords = {Computer Science - Computation and Language},
  file = {/home/dan/Zotero/storage/E2Z4VED3/Mohammad et al. - 2016 - Stance and Sentiment in Tweets.pdf},
  annote = {Comment: 22 pages}
}

@article{mohtaramiAutomaticStanceDetection2018,
  archivePrefix = {arXiv},
  eprinttype = {arxiv},
  eprint = {1804.07581},
  primaryClass = {cs},
  title = {Automatic {{Stance Detection Using End}}-to-{{End Memory Networks}}},
  abstract = {We present a novel end-to-end memory network for stance detection, which jointly (i) predicts whether a document agrees, disagrees, discusses or is unrelated with respect to a given target claim, and also (ii) extracts snippets of evidence for that prediction. The network operates at the paragraph level and integrates convolutional and recurrent neural networks, as well as a similarity matrix as part of the overall architecture. The experimental evaluation on the Fake News Challenge dataset shows state-of-the-art performance.},
  journal = {arXiv:1804.07581 [cs]},
  author = {Mohtarami, Mitra and Baly, Ramy and Glass, James and Nakov, Preslav and Marquez, Lluis and Moschitti, Alessandro},
  month = apr,
  year = {2018},
  keywords = {Computer Science - Computation and Language,68T50,I.2.7},
  file = {/home/dan/Zotero/storage/Q3STWNA3/Mohtarami et al. - 2018 - Automatic Stance Detection Using End-to-End Memory.pdf;/home/dan/Zotero/storage/GR5GL6A5/1804.html},
  annote = {Comment: NAACL-2018; Stance detection; Fact-Checking; Veracity; Memory networks; Neural Networks; Distributed Representations}
}

@inproceedings{skeppstedtDetectionStanceSentiment2017,
  series = {Lecture Notes in Computer Science},
  title = {Detection of {{Stance}} and {{Sentiment Modifiers}} in {{Political Blogs}}},
  isbn = {978-3-319-66429-3},
  abstract = {The automatic detection of seven types of modifiers was studied: Certainty, Uncertainty, Hypotheticality, Prediction, Recommendation, Concession/Contrast and Source. A classifier aimed at detecting local cue words that signal the categories was the most successful method for five of the categories. For Prediction and Hypotheticality, however, better results were obtained with a classifier trained on tokens and bigrams present in the entire sentence. Unsupervised cluster features were shown useful for the categories Source and Uncertainty, when a subset of the training data available was used. However, when all of the 2,095 sentences that had been actively selected and manually annotated were used as training data, the cluster features had a very limited effect. Some of the classification errors made by the models would be possible to avoid by extending the training data set, while other features and feature representations, as well as the incorporation of pragmatic knowledge, would be required for other error types.},
  language = {en},
  booktitle = {Speech and {{Computer}}},
  publisher = {{Springer International Publishing}},
  author = {Skeppstedt, Maria and Simaki, Vasiliki and Paradis, Carita and Kerren, Andreas},
  editor = {Karpov, Alexey and Potapova, Rodmonga and Mporas, Iosif},
  year = {2017},
  keywords = {Active learning,Sentiment modifiers,Sesource-aware natural language processing,Stance modifiers,Unsupervised features},
  pages = {302-311},
  file = {/home/dan/Zotero/storage/HEKY5Y8D/Skeppstedt et al. - 2017 - Detection of Stance and Sentiment Modifiers in Pol.pdf}
}

@inproceedings{thomasGetOutVote2006,
  address = {Sydney, Australia},
  title = {Get out the Vote: Determining Support or Opposition from Congressional Floor-Debate Transcripts},
  isbn = {978-1-932432-73-2},
  shorttitle = {Get out the Vote},
  doi = {10.3115/1610075.1610122},
  abstract = {We investigate whether one can determine from the transcripts of U.S. Congressional floor debates whether the speeches represent support of or opposition to proposed legislation. To address this problem, we exploit the fact that these speeches occur as part of a discussion; this allows us to use sources of information regarding relationships between discourse segments, such as whether a given utterance indicates agreement with the opinion expressed by another. We find that the incorporation of such information yields substantial improvements over classifying speeches in isolation.},
  language = {en},
  booktitle = {Proceedings of the 2006 {{Conference}} on {{Empirical Methods}} in {{Natural Language Processing}} - {{EMNLP}} '06},
  publisher = {{Association for Computational Linguistics}},
  author = {Thomas, Matt and Pang, Bo and Lee, Lillian},
  year = {2006},
  pages = {327},
  file = {/home/dan/Zotero/storage/Z99AE2CT/Thomas et al. - 2006 - Get out the vote determining support or oppositio.pdf}
}

@inproceedings{sobhaniDetectingStanceTweets2016,
  address = {Berlin, Germany},
  title = {Detecting {{Stance}} in {{Tweets And Analyzing}} Its {{Interaction}} with {{Sentiment}}},
  doi = {10.18653/v1/S16-2021},
  abstract = {One may express favor (or disfavor) towards a target by using positive or negative language. Here for the first time we present a dataset of tweets annotated for whether the tweeter is in favor of or against pre-chosen targets, as well as for sentiment. These targets may or may not be referred to in the tweets, and they may or may not be the target of opinion in the tweets. We develop a simple stance detection system that outperforms all 19 teams that participated in a recent shared task competition on the same dataset (SemEval-2016 Task \#6). Additionally, access to both stance and sentiment annotations allows us to conduct several experiments to tease out their interactions. We show that while sentiment features are useful for stance classification, they alone are not sufficient. We also show the impacts of various features on detecting stance and sentiment, respectively.},
  language = {en},
  booktitle = {Proceedings of the {{Fifth Joint Conference}} on {{Lexical}} and {{Computational Semantics}}},
  publisher = {{Association for Computational Linguistics}},
  author = {Sobhani, Parinaz and Mohammad, Saif and Kiritchenko, Svetlana},
  year = {2016},
  pages = {159-169},
  file = {/home/dan/Zotero/storage/5C9Q47BF/Sobhani et al. - 2016 - Detecting Stance in Tweets And Analyzing its Inter.pdf}
}

@article{castellaniCompetitiveCoevolutionMultilayer2018,
  title = {Competitive Co-Evolution of Multi-Layer Perceptron Classifiers},
  volume = {22},
  issn = {1433-7479},
  doi = {10.1007/s00500-017-2587-6},
  abstract = {This paper analyses the competitive approach to the co-evolutionary training of multi-layer perceptron classifiers. Two algorithms were tested: the first opposes a population of classifiers to a population of training patterns; the second pits a population of classifiers against a population of subsets of training patterns. The classifiers are regarded as predators that need to `capture' (correctly categorise) the prey (training patterns). Success for the predators is measured on their ability to capture prey. Success for the prey is measured on their ability to escape predation (be misclassified). The aim of the procedure is to create an evolutionary tug-of-war between the best classifiers and the most difficult data samples, increasing the efficiency and accuracy of the learning process. The two co-evolutionary algorithms were tested on a number of well-known benchmarks and on several artificial data sets modelling different kinds of common classification problems such as overlapping data categories, noisy training inputs, and unbalanced data classes. The performance of the co-evolutionary methods was compared with that of two traditional training techniques: the standard backpropagation rule and a conventional evolutionary algorithm. The co-evolutionary procedures achieved top accuracy in all classification problems. They particularly excelled on data sets containing noisy training inputs, where they outperformed the backpropagation rule, and on tasks involving unbalanced data classes, where they outperformed both backpropagation and the conventional evolutionary algorithm. Compared to the standard evolutionary algorithm, the co-evolutionary procedures were able to obtain similar or superior learning accuracies, whilst needing considerably less presentations of the training patterns. This economy in the use of training patterns translated into significant savings in computational overheads and algorithms running time.},
  language = {en},
  number = {10},
  journal = {Soft Computing},
  author = {Castellani, Marco},
  month = may,
  year = {2018},
  keywords = {Learning,Co-evolution,Competition,Evolutionary algorithms,Multi-layer perceptron,Predator–prey systems},
  pages = {3417-3432},
  file = {/home/dan/Zotero/storage/DLY8NEJY/Castellani - 2018 - Competitive co-evolution of multi-layer perceptron.pdf}
}


