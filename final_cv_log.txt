Using TensorFlow backend.
Namespace(domain='all', file_path=None, model_type='all', save_model=False)
['logistic_regression', 'fast_text', 'mlp']
['logistic_regression', 'fast_text', 'mlp']
Fold  1
multi-class
Loading Data
Training Model
Fold  2
multi-class
Loading Data
Training Model
Fold  3
multi-class
Loading Data
Training Model
Fold  4
multi-class
Loading Data
Training Model
Fold  5
multi-class
Loading Data
Training Model
time elapsed: 23.71054375800304
Fold  1
multi-class
Loading Data
Training Model
Fold  2
multi-class
Loading Data
Training Model
Fold  3
multi-class
Loading Data
Training Model
Fold  4
multi-class
Loading Data
Training Model
Fold  5
multi-class
Loading Data
Training Model
time elapsed: 22.89744319599413
Fold  1
multi-class
Loading Data
Training Model
Fold  2
multi-class
Loading Data
Training Model
Fold  3
multi-class
Loading Data
Training Model
Fold  4
multi-class
Loading Data
Training Model
Fold  5
multi-class
Loading Data
Training Model
time elapsed: 22.87986656800058
Fold  1
multi-class
Loading Data
Training Model
Fold  2
multi-class
Loading Data
Training Model
Fold  3
multi-class
Loading Data
Training Model
Fold  4
multi-class
Loading Data
Training Model
Fold  5
multi-class
Loading Data
Training Model
time elapsed: 22.952802363004594
Fold  1
multi-class
Loading Data
Training Model
Fold  2
multi-class
Loading Data
Training Model
Fold  3
multi-class
Loading Data
Training Model
Fold  4
multi-class
Loading Data
Training Model
Fold  5
multi-class
Loading Data
Training Model
time elapsed: 23.025754103997315
Fold  1
multi-class
Loading Data
Training Model
Fold  2
multi-class
Loading Data
Training Model
Fold  3
multi-class
Loading Data
Training Model
Fold  4
multi-class
Loading Data
Training Model
Fold  5
multi-class
Loading Data
Training Model
time elapsed: 22.90824843599694
Fold  1
multi-class
Loading Data
Training Model
Fold  2
multi-class
Loading Data
Training Model
Fold  3
multi-class
Loading Data
Training Model
Fold  4
multi-class
Loading Data
Training Model
Fold  5
multi-class
Loading Data
Training Model
time elapsed: 22.95420065199869
Fold  1
multi-class
Loading Data
Training Model
Fold  2
multi-class
Loading Data
Training Model
Fold  3
multi-class
Loading Data
Training Model
Fold  4
multi-class
Loading Data
Training Model
Fold  5
multi-class
Loading Data
Training Model
time elapsed: 22.952354822002235
Fold  1
multi-class
Loading Data
Training Model
Fold  2
multi-class
Loading Data
Training Model
Fold  3
multi-class
Loading Data
Training Model
Fold  4
multi-class
Loading Data
Training Model
Fold  5
multi-class
Loading Data
Training Model
time elapsed: 22.974417946999893


Epochs: 10
/home/dan/.local/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
/home/dan/.local/lib/python3.6/site-packages/sklearn/metrics/classification.py:1137: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true samples.
  'recall', 'true', average, warn_for)

Hamming Loss:                 0.355


Micro-f1 score:               0.645
Macro-f1 score:               0.783

Accuracy                      0.645
['LR', 'Multi-class', 10, 0.7831130492189871, 0.6450491027271443, 0.6450491027271443]


Epochs: 50

Hamming Loss:                 0.355


Micro-f1 score:               0.645
Macro-f1 score:               0.783

Accuracy                      0.645
['LR', 'Multi-class', 50, 0.7831130492189871, 0.6450491027271443, 0.6450491027271443]


Epochs: 100

Hamming Loss:                 0.355


Micro-f1 score:               0.645
Macro-f1 score:               0.783

Accuracy                      0.645
['LR', 'Multi-class', 100, 0.7831130492189871, 0.6450491027271443, 0.6450491027271443]


Epochs: 150

Hamming Loss:                 0.355


Micro-f1 score:               0.645
Macro-f1 score:               0.783

Accuracy                      0.645
['LR', 'Multi-class', 150, 0.7831130492189871, 0.6450491027271443, 0.6450491027271443]


Epochs: 200

Hamming Loss:                 0.355


Micro-f1 score:               0.645
Macro-f1 score:               0.783

Accuracy                      0.645
['LR', 'Multi-class', 200, 0.7831130492189871, 0.6450491027271443, 0.6450491027271443]


Epochs: 250

Hamming Loss:                 0.355


Micro-f1 score:               0.645
Macro-f1 score:               0.783

Accuracy                      0.645
['LR', 'Multi-class', 250, 0.7831130492189871, 0.6450491027271443, 0.6450491027271443]


Epochs: 300

Hamming Loss:                 0.355


Micro-f1 score:               0.645
Macro-f1 score:               0.783

Accuracy                      0.645
['LR', 'Multi-class', 300, 0.7831130492189871, 0.6450491027271443, 0.6450491027271443]


Epochs: 350

Hamming Loss:                 0.355


Micro-f1 score:               0.645
Macro-f1 score:               0.783

Accuracy                      0.645
['LR', 'Multi-class', 350, 0.7831130492189871, 0.6450491027271443, 0.6450491027271443]


Epochs: 400

Hamming Loss:                 0.355


Micro-f1 score:               0.645
Macro-f1 score:               0.783

Accuracy                      0.645
['LR', 'Multi-class', 400, 0.7831130492189871, 0.6450491027271443, 0.6450491027271443]
Fold  1
multi-label
Loading Data
Training Model
Fold  2
multi-label
Loading Data
Training Model
Fold  3
multi-label
Loading Data
Training Model
Fold  4
multi-label
Loading Data
Training Model
Fold  5
multi-label
Loading Data
Training Model
time elapsed: 11.736114227998769
Fold  1
multi-label
Loading Data
Training Model
Fold  2
multi-label
Loading Data
Training Model
Fold  3
multi-label
Loading Data
Training Model
Fold  4
multi-label
Loading Data
Training Model
Fold  5
multi-label
Loading Data
Training Model
time elapsed: 11.75948979799432
Fold  1
multi-label
Loading Data
Training Model
Fold  2
multi-label
Loading Data
Training Model
Fold  3
multi-label
Loading Data
Training Model
Fold  4
multi-label
Loading Data
Training Model
Fold  5
multi-label
Loading Data
Training Model
time elapsed: 11.758710276000784
Fold  1
multi-label
Loading Data
Training Model
Fold  2
multi-label
Loading Data
Training Model
Fold  3
multi-label
Loading Data
Training Model
Fold  4
multi-label
Loading Data
Training Model
Fold  5
multi-label
Loading Data
Training Model
time elapsed: 11.750222073998884
Fold  1
multi-label
Loading Data
Training Model
Fold  2
multi-label
Loading Data
Training Model
Fold  3
multi-label
Loading Data
Training Model
Fold  4
multi-label
Loading Data
Training Model
Fold  5
multi-label
Loading Data
Training Model
time elapsed: 11.747974992998934
Fold  1
multi-label
Loading Data
Training Model
Fold  2
multi-label
Loading Data
Training Model
Fold  3
multi-label
Loading Data
Training Model
Fold  4
multi-label
Loading Data
Training Model
Fold  5
multi-label
Loading Data
Training Model
time elapsed: 11.806840211000235
Fold  1
multi-label
Loading Data
Training Model
Fold  2
multi-label
Loading Data
Training Model
Fold  3
multi-label
Loading Data
Training Model
Fold  4
multi-label
Loading Data
Training Model
Fold  5
multi-label
Loading Data
Training Model
time elapsed: 11.706917430004978
Fold  1
multi-label
Loading Data
Training Model
Fold  2
multi-label
Loading Data
Training Model
Fold  3
multi-label
Loading Data
Training Model
Fold  4
multi-label
Loading Data
Training Model
Fold  5
multi-label
Loading Data
Training Model
time elapsed: 11.768632609993801
Fold  1
multi-label
Loading Data
Training Model
Fold  2
multi-label
Loading Data
Training Model
Fold  3
multi-label
Loading Data
Training Model
Fold  4
multi-label
Loading Data
Training Model
Fold  5
multi-label
Loading Data
Training Model
time elapsed: 11.983968813001411


Epochs: 10

Hamming Loss:                 0.060

f1 scores 
 -----------
Agreement/disagreement:       0.792        13
Certainty:                    0.841        29
Contrariety:                  0.823       109
Hypotheticality:              0.796        48
Necessity:                    0.757        56
Prediction:                   0.839        88
Source of knowledge:          0.756        95
Tact/rudeness:                0.779        24
Uncertainty:                  0.859        83
Volition:                     0.791        13

Micro-f1 score:               0.810
Macro-f1 score:               0.803

Accuracy                      0.578
['LR', 'Multi-label', 10, 0.8033894662811203, 0.8103901272045435, 0.5784619188921859]


Epochs: 50

Hamming Loss:                 0.060

f1 scores 
 -----------
Agreement/disagreement:       0.792        13
Certainty:                    0.841        29
Contrariety:                  0.823       109
Hypotheticality:              0.796        48
Necessity:                    0.757        56
Prediction:                   0.839        88
Source of knowledge:          0.756        95
Tact/rudeness:                0.779        24
Uncertainty:                  0.859        83
Volition:                     0.791        13

Micro-f1 score:               0.810
Macro-f1 score:               0.803

Accuracy                      0.578
['LR', 'Multi-label', 50, 0.8033894662811203, 0.8103901272045435, 0.5784619188921859]


Epochs: 100

Hamming Loss:                 0.060

f1 scores 
 -----------
Agreement/disagreement:       0.792        13
Certainty:                    0.841        29
Contrariety:                  0.823       109
Hypotheticality:              0.796        48
Necessity:                    0.757        56
Prediction:                   0.839        88
Source of knowledge:          0.756        95
Tact/rudeness:                0.779        24
Uncertainty:                  0.859        83
Volition:                     0.791        13

Micro-f1 score:               0.810
Macro-f1 score:               0.803

Accuracy                      0.578
['LR', 'Multi-label', 100, 0.8033894662811203, 0.8103901272045435, 0.5784619188921859]


Epochs: 150

Hamming Loss:                 0.060

f1 scores 
 -----------
Agreement/disagreement:       0.792        13
Certainty:                    0.841        29
Contrariety:                  0.823       109
Hypotheticality:              0.796        48
Necessity:                    0.757        56
Prediction:                   0.839        88
Source of knowledge:          0.756        95
Tact/rudeness:                0.779        24
Uncertainty:                  0.859        83
Volition:                     0.791        13

Micro-f1 score:               0.810
Macro-f1 score:               0.803

Accuracy                      0.578
['LR', 'Multi-label', 150, 0.8033894662811203, 0.8103901272045435, 0.5784619188921859]


Epochs: 200

Hamming Loss:                 0.060

f1 scores 
 -----------
Agreement/disagreement:       0.792        13
Certainty:                    0.841        29
Contrariety:                  0.823       109
Hypotheticality:              0.796        48
Necessity:                    0.757        56
Prediction:                   0.839        88
Source of knowledge:          0.756        95
Tact/rudeness:                0.779        24
Uncertainty:                  0.859        83
Volition:                     0.791        13

Micro-f1 score:               0.810
Macro-f1 score:               0.803

Accuracy                      0.578
['LR', 'Multi-label', 200, 0.8033894662811203, 0.8103901272045435, 0.5784619188921859]


Epochs: 250

Hamming Loss:                 0.060

f1 scores 
 -----------
Agreement/disagreement:       0.792        13
Certainty:                    0.841        29
Contrariety:                  0.823       109
Hypotheticality:              0.796        48
Necessity:                    0.757        56
Prediction:                   0.839        88
Source of knowledge:          0.756        95
Tact/rudeness:                0.779        24
Uncertainty:                  0.859        83
Volition:                     0.791        13

Micro-f1 score:               0.810
Macro-f1 score:               0.803

Accuracy                      0.578
['LR', 'Multi-label', 250, 0.8033894662811203, 0.8103901272045435, 0.5784619188921859]


Epochs: 300

Hamming Loss:                 0.060

f1 scores 
 -----------
Agreement/disagreement:       0.792        13
Certainty:                    0.841        29
Contrariety:                  0.823       109
Hypotheticality:              0.796        48
Necessity:                    0.757        56
Prediction:                   0.839        88
Source of knowledge:          0.756        95
Tact/rudeness:                0.779        24
Uncertainty:                  0.859        83
Volition:                     0.791        13

Micro-f1 score:               0.810
Macro-f1 score:               0.803

Accuracy                      0.578
['LR', 'Multi-label', 300, 0.8033894662811203, 0.8103901272045435, 0.5784619188921859]


Epochs: 350

Hamming Loss:                 0.060

f1 scores 
 -----------
Agreement/disagreement:       0.792        13
Certainty:                    0.841        29
Contrariety:                  0.823       109
Hypotheticality:              0.796        48
Necessity:                    0.757        56
Prediction:                   0.839        88
Source of knowledge:          0.756        95
Tact/rudeness:                0.779        24
Uncertainty:                  0.859        83
Volition:                     0.791        13

Micro-f1 score:               0.810
Macro-f1 score:               0.803

Accuracy                      0.578
['LR', 'Multi-label', 350, 0.8033894662811203, 0.8103901272045435, 0.5784619188921859]


Epochs: 400

Hamming Loss:                 0.060

f1 scores 
 -----------
Agreement/disagreement:       0.792        13
Certainty:                    0.841        29
Contrariety:                  0.823       109
Hypotheticality:              0.796        48
Necessity:                    0.757        56
Prediction:                   0.839        88
Source of knowledge:          0.756        95
Tact/rudeness:                0.779        24
Uncertainty:                  0.859        83
Volition:                     0.791        13

Micro-f1 score:               0.810
Macro-f1 score:               0.803

Accuracy                      0.578
['LR', 'Multi-label', 400, 0.8033894662811203, 0.8103901272045435, 0.5784619188921859]
Fold  1
multi-class
multi-class
Loading Data
Training Model
vocab size 4537, sequence length 43
Building FastText Model
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_1 (InputLayer)         (None, 43)                0         
_________________________________________________________________
embedding_1 (Embedding)      (None, 43, 100)           453700    
_________________________________________________________________
global_average_pooling1d_1 ( (None, 100)               0         
_________________________________________________________________
dense_1 (Dense)              (None, 637)               64337     
=================================================================
Total params: 518,037
Trainable params: 518,037
Non-trainable params: 0
_________________________________________________________________
None
2018-09-09 01:22:56.437561: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
Fold  2
multi-class
multi-class
Loading Data
Training Model
vocab size 4561, sequence length 45
Building FastText Model
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_2 (InputLayer)         (None, 45)                0         
_________________________________________________________________
embedding_2 (Embedding)      (None, 45, 100)           456100    
_________________________________________________________________
global_average_pooling1d_2 ( (None, 100)               0         
_________________________________________________________________
dense_2 (Dense)              (None, 637)               64337     
=================================================================
Total params: 520,437
Trainable params: 520,437
Non-trainable params: 0
_________________________________________________________________
None
Fold  3
multi-class
multi-class
Loading Data
Training Model
vocab size 4569, sequence length 45
Building FastText Model
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_3 (InputLayer)         (None, 45)                0         
_________________________________________________________________
embedding_3 (Embedding)      (None, 45, 100)           456900    
_________________________________________________________________
global_average_pooling1d_3 ( (None, 100)               0         
_________________________________________________________________
dense_3 (Dense)              (None, 637)               64337     
=================================================================
Total params: 521,237
Trainable params: 521,237
Non-trainable params: 0
_________________________________________________________________
None
Fold  4
multi-class
multi-class
Loading Data
Training Model
vocab size 4518, sequence length 45
Building FastText Model
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_4 (InputLayer)         (None, 45)                0         
_________________________________________________________________
embedding_4 (Embedding)      (None, 45, 100)           451800    
_________________________________________________________________
global_average_pooling1d_4 ( (None, 100)               0         
_________________________________________________________________
dense_4 (Dense)              (None, 637)               64337     
=================================================================
Total params: 516,137
Trainable params: 516,137
Non-trainable params: 0
_________________________________________________________________
None
Fold  5
multi-class
multi-class
Loading Data
Training Model
vocab size 4426, sequence length 45
Building FastText Model
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_5 (InputLayer)         (None, 45)                0         
_________________________________________________________________
embedding_5 (Embedding)      (None, 45, 100)           442600    
_________________________________________________________________
global_average_pooling1d_5 ( (None, 100)               0         
_________________________________________________________________
dense_5 (Dense)              (None, 637)               64337     
=================================================================
Total params: 506,937
Trainable params: 506,937
Non-trainable params: 0
_________________________________________________________________
None
time elapsed: 14.681339155002206
Fold  1
multi-class
multi-class
Loading Data
Training Model
vocab size 4537, sequence length 43
Building FastText Model
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_6 (InputLayer)         (None, 43)                0         
_________________________________________________________________
embedding_6 (Embedding)      (None, 43, 100)           453700    
_________________________________________________________________
global_average_pooling1d_6 ( (None, 100)               0         
_________________________________________________________________
dense_6 (Dense)              (None, 637)               64337     
=================================================================
Total params: 518,037
Trainable params: 518,037
Non-trainable params: 0
_________________________________________________________________
None
Fold  2
multi-class
multi-class
Loading Data
Training Model
vocab size 4561, sequence length 45
Building FastText Model
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_7 (InputLayer)         (None, 45)                0         
_________________________________________________________________
embedding_7 (Embedding)      (None, 45, 100)           456100    
_________________________________________________________________
global_average_pooling1d_7 ( (None, 100)               0         
_________________________________________________________________
dense_7 (Dense)              (None, 637)               64337     
=================================================================
Total params: 520,437
Trainable params: 520,437
Non-trainable params: 0
_________________________________________________________________
None
Fold  3
multi-class
multi-class
Loading Data
Training Model
vocab size 4569, sequence length 45
Building FastText Model
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_8 (InputLayer)         (None, 45)                0         
_________________________________________________________________
embedding_8 (Embedding)      (None, 45, 100)           456900    
_________________________________________________________________
global_average_pooling1d_8 ( (None, 100)               0         
_________________________________________________________________
dense_8 (Dense)              (None, 637)               64337     
=================================================================
Total params: 521,237
Trainable params: 521,237
Non-trainable params: 0
_________________________________________________________________
None
Fold  4
multi-class
multi-class
Loading Data
Training Model
vocab size 4518, sequence length 45
Building FastText Model
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_9 (InputLayer)         (None, 45)                0         
_________________________________________________________________
embedding_9 (Embedding)      (None, 45, 100)           451800    
_________________________________________________________________
global_average_pooling1d_9 ( (None, 100)               0         
_________________________________________________________________
dense_9 (Dense)              (None, 637)               64337     
=================================================================
Total params: 516,137
Trainable params: 516,137
Non-trainable params: 0
_________________________________________________________________
None
Fold  5
multi-class
multi-class
Loading Data
Training Model
vocab size 4426, sequence length 45
Building FastText Model
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_10 (InputLayer)        (None, 45)                0         
_________________________________________________________________
embedding_10 (Embedding)     (None, 45, 100)           442600    
_________________________________________________________________
global_average_pooling1d_10  (None, 100)               0         
_________________________________________________________________
dense_10 (Dense)             (None, 637)               64337     
=================================================================
Total params: 506,937
Trainable params: 506,937
Non-trainable params: 0
_________________________________________________________________
None
time elapsed: 68.18887095800164
Fold  1
multi-class
multi-class
Loading Data
Training Model
vocab size 4537, sequence length 43
Building FastText Model
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_11 (InputLayer)        (None, 43)                0         
_________________________________________________________________
embedding_11 (Embedding)     (None, 43, 100)           453700    
_________________________________________________________________
global_average_pooling1d_11  (None, 100)               0         
_________________________________________________________________
dense_11 (Dense)             (None, 637)               64337     
=================================================================
Total params: 518,037
Trainable params: 518,037
Non-trainable params: 0
_________________________________________________________________
None
Fold  2
multi-class
multi-class
Loading Data
Training Model
vocab size 4561, sequence length 45
Building FastText Model
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_12 (InputLayer)        (None, 45)                0         
_________________________________________________________________
embedding_12 (Embedding)     (None, 45, 100)           456100    
_________________________________________________________________
global_average_pooling1d_12  (None, 100)               0         
_________________________________________________________________
dense_12 (Dense)             (None, 637)               64337     
=================================================================
Total params: 520,437
Trainable params: 520,437
Non-trainable params: 0
_________________________________________________________________
None
Fold  3
multi-class
multi-class
Loading Data
Training Model
vocab size 4569, sequence length 45
Building FastText Model
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_13 (InputLayer)        (None, 45)                0         
_________________________________________________________________
embedding_13 (Embedding)     (None, 45, 100)           456900    
_________________________________________________________________
global_average_pooling1d_13  (None, 100)               0         
_________________________________________________________________
dense_13 (Dense)             (None, 637)               64337     
=================================================================
Total params: 521,237
Trainable params: 521,237
Non-trainable params: 0
_________________________________________________________________
None
Fold  4
multi-class
multi-class
Loading Data
Training Model
vocab size 4518, sequence length 45
Building FastText Model
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_14 (InputLayer)        (None, 45)                0         
_________________________________________________________________
embedding_14 (Embedding)     (None, 45, 100)           451800    
_________________________________________________________________
global_average_pooling1d_14  (None, 100)               0         
_________________________________________________________________
dense_14 (Dense)             (None, 637)               64337     
=================================================================
Total params: 516,137
Trainable params: 516,137
Non-trainable params: 0
_________________________________________________________________
None
Fold  5
multi-class
multi-class
Loading Data
Training Model
vocab size 4426, sequence length 45
Building FastText Model
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_15 (InputLayer)        (None, 45)                0         
_________________________________________________________________
embedding_15 (Embedding)     (None, 45, 100)           442600    
_________________________________________________________________
global_average_pooling1d_15  (None, 100)               0         
_________________________________________________________________
dense_15 (Dense)             (None, 637)               64337     
=================================================================
Total params: 506,937
Trainable params: 506,937
Non-trainable params: 0
_________________________________________________________________
None
time elapsed: 121.27967850000277
Fold  1
multi-class
multi-class
Loading Data
Training Model
vocab size 4537, sequence length 43
Building FastText Model
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_16 (InputLayer)        (None, 43)                0         
_________________________________________________________________
embedding_16 (Embedding)     (None, 43, 100)           453700    
_________________________________________________________________
global_average_pooling1d_16  (None, 100)               0         
_________________________________________________________________
dense_16 (Dense)             (None, 637)               64337     
=================================================================
Total params: 518,037
Trainable params: 518,037
Non-trainable params: 0
_________________________________________________________________
None
Fold  2
multi-class
multi-class
Loading Data
Training Model
vocab size 4561, sequence length 45
Building FastText Model
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_17 (InputLayer)        (None, 45)                0         
_________________________________________________________________
embedding_17 (Embedding)     (None, 45, 100)           456100    
_________________________________________________________________
global_average_pooling1d_17  (None, 100)               0         
_________________________________________________________________
dense_17 (Dense)             (None, 637)               64337     
=================================================================
Total params: 520,437
Trainable params: 520,437
Non-trainable params: 0
_________________________________________________________________
None
Fold  3
multi-class
multi-class
Loading Data
Training Model
vocab size 4569, sequence length 45
Building FastText Model
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_18 (InputLayer)        (None, 45)                0         
_________________________________________________________________
embedding_18 (Embedding)     (None, 45, 100)           456900    
_________________________________________________________________
global_average_pooling1d_18  (None, 100)               0         
_________________________________________________________________
dense_18 (Dense)             (None, 637)               64337     
=================================================================
Total params: 521,237
Trainable params: 521,237
Non-trainable params: 0
_________________________________________________________________
None
Fold  4
multi-class
multi-class
Loading Data
Training Model
vocab size 4518, sequence length 45
Building FastText Model
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_19 (InputLayer)        (None, 45)                0         
_________________________________________________________________
embedding_19 (Embedding)     (None, 45, 100)           451800    
_________________________________________________________________
global_average_pooling1d_19  (None, 100)               0         
_________________________________________________________________
dense_19 (Dense)             (None, 637)               64337     
=================================================================
Total params: 516,137
Trainable params: 516,137
Non-trainable params: 0
_________________________________________________________________
None
Fold  5
multi-class
multi-class
Loading Data
Training Model
vocab size 4426, sequence length 45
Building FastText Model
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_20 (InputLayer)        (None, 45)                0         
_________________________________________________________________
embedding_20 (Embedding)     (None, 45, 100)           442600    
_________________________________________________________________
global_average_pooling1d_20  (None, 100)               0         
_________________________________________________________________
dense_20 (Dense)             (None, 637)               64337     
=================================================================
Total params: 506,937
Trainable params: 506,937
Non-trainable params: 0
_________________________________________________________________
None
time elapsed: 171.7468875429986
Fold  1
multi-class
multi-class
Loading Data
Training Model
vocab size 4537, sequence length 43
Building FastText Model
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_21 (InputLayer)        (None, 43)                0         
_________________________________________________________________
embedding_21 (Embedding)     (None, 43, 100)           453700    
_________________________________________________________________
global_average_pooling1d_21  (None, 100)               0         
_________________________________________________________________
dense_21 (Dense)             (None, 637)               64337     
=================================================================
Total params: 518,037
Trainable params: 518,037
Non-trainable params: 0
_________________________________________________________________
None
Fold  2
multi-class
multi-class
Loading Data
Training Model
vocab size 4561, sequence length 45
Building FastText Model
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_22 (InputLayer)        (None, 45)                0         
_________________________________________________________________
embedding_22 (Embedding)     (None, 45, 100)           456100    
_________________________________________________________________
global_average_pooling1d_22  (None, 100)               0         
_________________________________________________________________
dense_22 (Dense)             (None, 637)               64337     
=================================================================
Total params: 520,437
Trainable params: 520,437
Non-trainable params: 0
_________________________________________________________________
None
Fold  3
multi-class
multi-class
Loading Data
Training Model
vocab size 4569, sequence length 45
Building FastText Model
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_23 (InputLayer)        (None, 45)                0         
_________________________________________________________________
embedding_23 (Embedding)     (None, 45, 100)           456900    
_________________________________________________________________
global_average_pooling1d_23  (None, 100)               0         
_________________________________________________________________
dense_23 (Dense)             (None, 637)               64337     
=================================================================
Total params: 521,237
Trainable params: 521,237
Non-trainable params: 0
_________________________________________________________________
None
Fold  4
multi-class
multi-class
Loading Data
Training Model
vocab size 4518, sequence length 45
Building FastText Model
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_24 (InputLayer)        (None, 45)                0         
_________________________________________________________________
embedding_24 (Embedding)     (None, 45, 100)           451800    
_________________________________________________________________
global_average_pooling1d_24  (None, 100)               0         
_________________________________________________________________
dense_24 (Dense)             (None, 637)               64337     
=================================================================
Total params: 516,137
Trainable params: 516,137
Non-trainable params: 0
_________________________________________________________________
None
Fold  5
multi-class
multi-class
Loading Data
Training Model
vocab size 4426, sequence length 45
Building FastText Model
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_25 (InputLayer)        (None, 45)                0         
_________________________________________________________________
embedding_25 (Embedding)     (None, 45, 100)           442600    
_________________________________________________________________
global_average_pooling1d_25  (None, 100)               0         
_________________________________________________________________
dense_25 (Dense)             (None, 637)               64337     
=================================================================
Total params: 506,937
Trainable params: 506,937
Non-trainable params: 0
_________________________________________________________________
None
time elapsed: 220.52205097499973
Fold  1
multi-class
multi-class
Loading Data
Training Model
vocab size 4537, sequence length 43
Building FastText Model
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_26 (InputLayer)        (None, 43)                0         
_________________________________________________________________
embedding_26 (Embedding)     (None, 43, 100)           453700    
_________________________________________________________________
global_average_pooling1d_26  (None, 100)               0         
_________________________________________________________________
dense_26 (Dense)             (None, 637)               64337     
=================================================================
Total params: 518,037
Trainable params: 518,037
Non-trainable params: 0
_________________________________________________________________
None
Fold  2
multi-class
multi-class
Loading Data
Training Model
vocab size 4561, sequence length 45
Building FastText Model
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_27 (InputLayer)        (None, 45)                0         
_________________________________________________________________
embedding_27 (Embedding)     (None, 45, 100)           456100    
_________________________________________________________________
global_average_pooling1d_27  (None, 100)               0         
_________________________________________________________________
dense_27 (Dense)             (None, 637)               64337     
=================================================================
Total params: 520,437
Trainable params: 520,437
Non-trainable params: 0
_________________________________________________________________
None
Fold  3
multi-class
multi-class
Loading Data
Training Model
vocab size 4569, sequence length 45
Building FastText Model
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_28 (InputLayer)        (None, 45)                0         
_________________________________________________________________
embedding_28 (Embedding)     (None, 45, 100)           456900    
_________________________________________________________________
global_average_pooling1d_28  (None, 100)               0         
_________________________________________________________________
dense_28 (Dense)             (None, 637)               64337     
=================================================================
Total params: 521,237
Trainable params: 521,237
Non-trainable params: 0
_________________________________________________________________
None
Fold  4
multi-class
multi-class
Loading Data
Training Model
vocab size 4518, sequence length 45
Building FastText Model
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_29 (InputLayer)        (None, 45)                0         
_________________________________________________________________
embedding_29 (Embedding)     (None, 45, 100)           451800    
_________________________________________________________________
global_average_pooling1d_29  (None, 100)               0         
_________________________________________________________________
dense_29 (Dense)             (None, 637)               64337     
=================================================================
Total params: 516,137
Trainable params: 516,137
Non-trainable params: 0
_________________________________________________________________
None
Fold  5
multi-class
multi-class
Loading Data
Training Model
vocab size 4426, sequence length 45
Building FastText Model
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_30 (InputLayer)        (None, 45)                0         
_________________________________________________________________
embedding_30 (Embedding)     (None, 45, 100)           442600    
_________________________________________________________________
global_average_pooling1d_30  (None, 100)               0         
_________________________________________________________________
dense_30 (Dense)             (None, 637)               64337     
=================================================================
Total params: 506,937
Trainable params: 506,937
Non-trainable params: 0
_________________________________________________________________
None
time elapsed: 265.1699156649993
Fold  1
multi-class
multi-class
Loading Data
Training Model
vocab size 4537, sequence length 43
Building FastText Model
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_31 (InputLayer)        (None, 43)                0         
_________________________________________________________________
embedding_31 (Embedding)     (None, 43, 100)           453700    
_________________________________________________________________
global_average_pooling1d_31  (None, 100)               0         
_________________________________________________________________
dense_31 (Dense)             (None, 637)               64337     
=================================================================
Total params: 518,037
Trainable params: 518,037
Non-trainable params: 0
_________________________________________________________________
None
Fold  2
multi-class
multi-class
Loading Data
Training Model
vocab size 4561, sequence length 45
Building FastText Model
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_32 (InputLayer)        (None, 45)                0         
_________________________________________________________________
embedding_32 (Embedding)     (None, 45, 100)           456100    
_________________________________________________________________
global_average_pooling1d_32  (None, 100)               0         
_________________________________________________________________
dense_32 (Dense)             (None, 637)               64337     
=================================================================
Total params: 520,437
Trainable params: 520,437
Non-trainable params: 0
_________________________________________________________________
None
Fold  3
multi-class
multi-class
Loading Data
Training Model
vocab size 4569, sequence length 45
Building FastText Model
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_33 (InputLayer)        (None, 45)                0         
_________________________________________________________________
embedding_33 (Embedding)     (None, 45, 100)           456900    
_________________________________________________________________
global_average_pooling1d_33  (None, 100)               0         
_________________________________________________________________
dense_33 (Dense)             (None, 637)               64337     
=================================================================
Total params: 521,237
Trainable params: 521,237
Non-trainable params: 0
_________________________________________________________________
None
Fold  4
multi-class
multi-class
Loading Data
Training Model
vocab size 4518, sequence length 45
Building FastText Model
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_34 (InputLayer)        (None, 45)                0         
_________________________________________________________________
embedding_34 (Embedding)     (None, 45, 100)           451800    
_________________________________________________________________
global_average_pooling1d_34  (None, 100)               0         
_________________________________________________________________
dense_34 (Dense)             (None, 637)               64337     
=================================================================
Total params: 516,137
Trainable params: 516,137
Non-trainable params: 0
_________________________________________________________________
None
Fold  5
multi-class
multi-class
Loading Data
Training Model
vocab size 4426, sequence length 45
Building FastText Model
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_35 (InputLayer)        (None, 45)                0         
_________________________________________________________________
embedding_35 (Embedding)     (None, 45, 100)           442600    
_________________________________________________________________
global_average_pooling1d_35  (None, 100)               0         
_________________________________________________________________
dense_35 (Dense)             (None, 637)               64337     
=================================================================
Total params: 506,937
Trainable params: 506,937
Non-trainable params: 0
_________________________________________________________________
None
time elapsed: 313.39542596099636
Fold  1
multi-class
multi-class
Loading Data
Training Model
vocab size 4537, sequence length 43
Building FastText Model
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_36 (InputLayer)        (None, 43)                0         
_________________________________________________________________
embedding_36 (Embedding)     (None, 43, 100)           453700    
_________________________________________________________________
global_average_pooling1d_36  (None, 100)               0         
_________________________________________________________________
dense_36 (Dense)             (None, 637)               64337     
=================================================================
Total params: 518,037
Trainable params: 518,037
Non-trainable params: 0
_________________________________________________________________
None
Fold  2
multi-class
multi-class
Loading Data
Training Model
vocab size 4561, sequence length 45
Building FastText Model
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_37 (InputLayer)        (None, 45)                0         
_________________________________________________________________
embedding_37 (Embedding)     (None, 45, 100)           456100    
_________________________________________________________________
global_average_pooling1d_37  (None, 100)               0         
_________________________________________________________________
dense_37 (Dense)             (None, 637)               64337     
=================================================================
Total params: 520,437
Trainable params: 520,437
Non-trainable params: 0
_________________________________________________________________
None
Fold  3
multi-class
multi-class
Loading Data
Training Model
vocab size 4569, sequence length 45
Building FastText Model
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_38 (InputLayer)        (None, 45)                0         
_________________________________________________________________
embedding_38 (Embedding)     (None, 45, 100)           456900    
_________________________________________________________________
global_average_pooling1d_38  (None, 100)               0         
_________________________________________________________________
dense_38 (Dense)             (None, 637)               64337     
=================================================================
Total params: 521,237
Trainable params: 521,237
Non-trainable params: 0
_________________________________________________________________
None
Fold  4
multi-class
multi-class
Loading Data
Training Model
vocab size 4518, sequence length 45
Building FastText Model
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_39 (InputLayer)        (None, 45)                0         
_________________________________________________________________
embedding_39 (Embedding)     (None, 45, 100)           451800    
_________________________________________________________________
global_average_pooling1d_39  (None, 100)               0         
_________________________________________________________________
dense_39 (Dense)             (None, 637)               64337     
=================================================================
Total params: 516,137
Trainable params: 516,137
Non-trainable params: 0
_________________________________________________________________
None
Fold  5
multi-class
multi-class
Loading Data
Training Model
vocab size 4426, sequence length 45
Building FastText Model
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_40 (InputLayer)        (None, 45)                0         
_________________________________________________________________
embedding_40 (Embedding)     (None, 45, 100)           442600    
_________________________________________________________________
global_average_pooling1d_40  (None, 100)               0         
_________________________________________________________________
dense_40 (Dense)             (None, 637)               64337     
=================================================================
Total params: 506,937
Trainable params: 506,937
Non-trainable params: 0
_________________________________________________________________
None
time elapsed: 364.92785476700374
Fold  1
multi-class
multi-class
Loading Data
Training Model
vocab size 4537, sequence length 43
Building FastText Model
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_41 (InputLayer)        (None, 43)                0         
_________________________________________________________________
embedding_41 (Embedding)     (None, 43, 100)           453700    
_________________________________________________________________
global_average_pooling1d_41  (None, 100)               0         
_________________________________________________________________
dense_41 (Dense)             (None, 637)               64337     
=================================================================
Total params: 518,037
Trainable params: 518,037
Non-trainable params: 0
_________________________________________________________________
None
Fold  2
multi-class
multi-class
Loading Data
Training Model
vocab size 4561, sequence length 45
Building FastText Model
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_42 (InputLayer)        (None, 45)                0         
_________________________________________________________________
embedding_42 (Embedding)     (None, 45, 100)           456100    
_________________________________________________________________
global_average_pooling1d_42  (None, 100)               0         
_________________________________________________________________
dense_42 (Dense)             (None, 637)               64337     
=================================================================
Total params: 520,437
Trainable params: 520,437
Non-trainable params: 0
_________________________________________________________________
None
Fold  3
multi-class
multi-class
Loading Data
Training Model
vocab size 4569, sequence length 45
Building FastText Model
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_43 (InputLayer)        (None, 45)                0         
_________________________________________________________________
embedding_43 (Embedding)     (None, 45, 100)           456900    
_________________________________________________________________
global_average_pooling1d_43  (None, 100)               0         
_________________________________________________________________
dense_43 (Dense)             (None, 637)               64337     
=================================================================
Total params: 521,237
Trainable params: 521,237
Non-trainable params: 0
_________________________________________________________________
None
Fold  4
multi-class
multi-class
Loading Data
Training Model
vocab size 4518, sequence length 45
Building FastText Model
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_44 (InputLayer)        (None, 45)                0         
_________________________________________________________________
embedding_44 (Embedding)     (None, 45, 100)           451800    
_________________________________________________________________
global_average_pooling1d_44  (None, 100)               0         
_________________________________________________________________
dense_44 (Dense)             (None, 637)               64337     
=================================================================
Total params: 516,137
Trainable params: 516,137
Non-trainable params: 0
_________________________________________________________________
None
Fold  5
multi-class
multi-class
Loading Data
Training Model
vocab size 4426, sequence length 45
Building FastText Model
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_45 (InputLayer)        (None, 45)                0         
_________________________________________________________________
embedding_45 (Embedding)     (None, 45, 100)           442600    
_________________________________________________________________
global_average_pooling1d_45  (None, 100)               0         
_________________________________________________________________
dense_45 (Dense)             (None, 637)               64337     
=================================================================
Total params: 506,937
Trainable params: 506,937
Non-trainable params: 0
_________________________________________________________________
None
time elapsed: 417.6429088110017


Epochs: 10
/home/dan/.local/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)

Hamming Loss:                 0.897


Micro-f1 score:               0.103
Macro-f1 score:               0.004

Accuracy                      0.103
['FastText', 'Multi-class', 10, 0.003500132401890016, 0.10344778861099338, 0.10344778861099338]


Epochs: 50

Hamming Loss:                 0.891


Micro-f1 score:               0.109
Macro-f1 score:               0.008

Accuracy                      0.109
['FastText', 'Multi-class', 50, 0.007677524520771879, 0.10938780556733078, 0.10938780556733078]


Epochs: 100

Hamming Loss:                 0.751


Micro-f1 score:               0.249
Macro-f1 score:               0.062

Accuracy                      0.249
['FastText', 'Multi-class', 100, 0.061965957550309016, 0.2485039564787339, 0.2485039564787339]


Epochs: 150
/home/dan/.local/lib/python3.6/site-packages/sklearn/metrics/classification.py:1137: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true samples.
  'recall', 'true', average, warn_for)

Hamming Loss:                 0.578


Micro-f1 score:               0.422
Macro-f1 score:               0.281

Accuracy                      0.422
['FastText', 'Multi-class', 150, 0.28051829864140015, 0.42208916207432534, 0.42208916207432534]


Epochs: 200

Hamming Loss:                 0.447


Micro-f1 score:               0.553
Macro-f1 score:               0.546

Accuracy                      0.553
['FastText', 'Multi-class', 200, 0.5455745369321423, 0.5528896425038858, 0.5528896425038858]


Epochs: 250

Hamming Loss:                 0.378


Micro-f1 score:               0.622
Macro-f1 score:               0.686

Accuracy                      0.622
['FastText', 'Multi-class', 250, 0.6859484736622438, 0.6218577787197965, 0.6218577787197965]


Epochs: 300

Hamming Loss:                 0.359


Micro-f1 score:               0.641
Macro-f1 score:               0.752

Accuracy                      0.641
['FastText', 'Multi-class', 300, 0.7522433000233477, 0.6408859686307757, 0.6408859686307757]


Epochs: 350

Hamming Loss:                 0.350


Micro-f1 score:               0.650
Macro-f1 score:               0.782

Accuracy                      0.650
['FastText', 'Multi-class', 350, 0.7820690175580596, 0.6504009467288399, 0.6504009467288399]


Epochs: 400

Hamming Loss:                 0.345


Micro-f1 score:               0.655
Macro-f1 score:               0.792

Accuracy                      0.655
['FastText', 'Multi-class', 400, 0.7915221850321199, 0.6545711459658047, 0.6545711459658047]
Fold  1
multi-label
multi-label
Loading Data
Training Model
vocab size 4537, sequence length 43
Building FastText Model
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_46 (InputLayer)        (None, 43)                0         
_________________________________________________________________
embedding_46 (Embedding)     (None, 43, 100)           453700    
_________________________________________________________________
global_average_pooling1d_46  (None, 100)               0         
_________________________________________________________________
dense_46 (Dense)             (None, 10)                1010      
=================================================================
Total params: 454,710
Trainable params: 454,710
Non-trainable params: 0
_________________________________________________________________
None
Fold  2
multi-label
multi-label
Loading Data
Training Model
vocab size 4561, sequence length 45
Building FastText Model
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_47 (InputLayer)        (None, 45)                0         
_________________________________________________________________
embedding_47 (Embedding)     (None, 45, 100)           456100    
_________________________________________________________________
global_average_pooling1d_47  (None, 100)               0         
_________________________________________________________________
dense_47 (Dense)             (None, 10)                1010      
=================================================================
Total params: 457,110
Trainable params: 457,110
Non-trainable params: 0
_________________________________________________________________
None
Fold  3
multi-label
multi-label
Loading Data
Training Model
vocab size 4569, sequence length 45
Building FastText Model
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_48 (InputLayer)        (None, 45)                0         
_________________________________________________________________
embedding_48 (Embedding)     (None, 45, 100)           456900    
_________________________________________________________________
global_average_pooling1d_48  (None, 100)               0         
_________________________________________________________________
dense_48 (Dense)             (None, 10)                1010      
=================================================================
Total params: 457,910
Trainable params: 457,910
Non-trainable params: 0
_________________________________________________________________
None
Fold  4
multi-label
multi-label
Loading Data
Training Model
vocab size 4518, sequence length 45
Building FastText Model
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_49 (InputLayer)        (None, 45)                0         
_________________________________________________________________
embedding_49 (Embedding)     (None, 45, 100)           451800    
_________________________________________________________________
global_average_pooling1d_49  (None, 100)               0         
_________________________________________________________________
dense_49 (Dense)             (None, 10)                1010      
=================================================================
Total params: 452,810
Trainable params: 452,810
Non-trainable params: 0
_________________________________________________________________
None
Fold  5
multi-label
multi-label
Loading Data
Training Model
vocab size 4426, sequence length 45
Building FastText Model
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_50 (InputLayer)        (None, 45)                0         
_________________________________________________________________
embedding_50 (Embedding)     (None, 45, 100)           442600    
_________________________________________________________________
global_average_pooling1d_50  (None, 100)               0         
_________________________________________________________________
dense_50 (Dense)             (None, 10)                1010      
=================================================================
Total params: 443,610
Trainable params: 443,610
Non-trainable params: 0
_________________________________________________________________
None
time elapsed: 18.41443814500235
Fold  1
multi-label
multi-label
Loading Data
Training Model
vocab size 4537, sequence length 43
Building FastText Model
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_51 (InputLayer)        (None, 43)                0         
_________________________________________________________________
embedding_51 (Embedding)     (None, 43, 100)           453700    
_________________________________________________________________
global_average_pooling1d_51  (None, 100)               0         
_________________________________________________________________
dense_51 (Dense)             (None, 10)                1010      
=================================================================
Total params: 454,710
Trainable params: 454,710
Non-trainable params: 0
_________________________________________________________________
None
Fold  2
multi-label
multi-label
Loading Data
Training Model
vocab size 4561, sequence length 45
Building FastText Model
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_52 (InputLayer)        (None, 45)                0         
_________________________________________________________________
embedding_52 (Embedding)     (None, 45, 100)           456100    
_________________________________________________________________
global_average_pooling1d_52  (None, 100)               0         
_________________________________________________________________
dense_52 (Dense)             (None, 10)                1010      
=================================================================
Total params: 457,110
Trainable params: 457,110
Non-trainable params: 0
_________________________________________________________________
None
Fold  3
multi-label
multi-label
Loading Data
Training Model
vocab size 4569, sequence length 45
Building FastText Model
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_53 (InputLayer)        (None, 45)                0         
_________________________________________________________________
embedding_53 (Embedding)     (None, 45, 100)           456900    
_________________________________________________________________
global_average_pooling1d_53  (None, 100)               0         
_________________________________________________________________
dense_53 (Dense)             (None, 10)                1010      
=================================================================
Total params: 457,910
Trainable params: 457,910
Non-trainable params: 0
_________________________________________________________________
None
Fold  4
multi-label
multi-label
Loading Data
Training Model
vocab size 4518, sequence length 45
Building FastText Model
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_54 (InputLayer)        (None, 45)                0         
_________________________________________________________________
embedding_54 (Embedding)     (None, 45, 100)           451800    
_________________________________________________________________
global_average_pooling1d_54  (None, 100)               0         
_________________________________________________________________
dense_54 (Dense)             (None, 10)                1010      
=================================================================
Total params: 452,810
Trainable params: 452,810
Non-trainable params: 0
_________________________________________________________________
None
Fold  5
multi-label
multi-label
Loading Data
Training Model
vocab size 4426, sequence length 45
Building FastText Model
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_55 (InputLayer)        (None, 45)                0         
_________________________________________________________________
embedding_55 (Embedding)     (None, 45, 100)           442600    
_________________________________________________________________
global_average_pooling1d_55  (None, 100)               0         
_________________________________________________________________
dense_55 (Dense)             (None, 10)                1010      
=================================================================
Total params: 443,610
Trainable params: 443,610
Non-trainable params: 0
_________________________________________________________________
None
time elapsed: 52.81745912599581
Fold  1
multi-label
multi-label
Loading Data
Training Model
vocab size 4537, sequence length 43
Building FastText Model
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_56 (InputLayer)        (None, 43)                0         
_________________________________________________________________
embedding_56 (Embedding)     (None, 43, 100)           453700    
_________________________________________________________________
global_average_pooling1d_56  (None, 100)               0         
_________________________________________________________________
dense_56 (Dense)             (None, 10)                1010      
=================================================================
Total params: 454,710
Trainable params: 454,710
Non-trainable params: 0
_________________________________________________________________
None
Fold  2
multi-label
multi-label
Loading Data
Training Model
vocab size 4561, sequence length 45
Building FastText Model
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_57 (InputLayer)        (None, 45)                0         
_________________________________________________________________
embedding_57 (Embedding)     (None, 45, 100)           456100    
_________________________________________________________________
global_average_pooling1d_57  (None, 100)               0         
_________________________________________________________________
dense_57 (Dense)             (None, 10)                1010      
=================================================================
Total params: 457,110
Trainable params: 457,110
Non-trainable params: 0
_________________________________________________________________
None
Fold  3
multi-label
multi-label
Loading Data
Training Model
vocab size 4569, sequence length 45
Building FastText Model
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_58 (InputLayer)        (None, 45)                0         
_________________________________________________________________
embedding_58 (Embedding)     (None, 45, 100)           456900    
_________________________________________________________________
global_average_pooling1d_58  (None, 100)               0         
_________________________________________________________________
dense_58 (Dense)             (None, 10)                1010      
=================================================================
Total params: 457,910
Trainable params: 457,910
Non-trainable params: 0
_________________________________________________________________
None
Fold  4
multi-label
multi-label
Loading Data
Training Model
vocab size 4518, sequence length 45
Building FastText Model
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_59 (InputLayer)        (None, 45)                0         
_________________________________________________________________
embedding_59 (Embedding)     (None, 45, 100)           451800    
_________________________________________________________________
global_average_pooling1d_59  (None, 100)               0         
_________________________________________________________________
dense_59 (Dense)             (None, 10)                1010      
=================================================================
Total params: 452,810
Trainable params: 452,810
Non-trainable params: 0
_________________________________________________________________
None
Fold  5
multi-label
multi-label
Loading Data
Training Model
vocab size 4426, sequence length 45
Building FastText Model
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_60 (InputLayer)        (None, 45)                0         
_________________________________________________________________
embedding_60 (Embedding)     (None, 45, 100)           442600    
_________________________________________________________________
global_average_pooling1d_60  (None, 100)               0         
_________________________________________________________________
dense_60 (Dense)             (None, 10)                1010      
=================================================================
Total params: 443,610
Trainable params: 443,610
Non-trainable params: 0
_________________________________________________________________
None
time elapsed: 96.4572725830003
Fold  1
multi-label
multi-label
Loading Data
Training Model
vocab size 4537, sequence length 43
Building FastText Model
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_61 (InputLayer)        (None, 43)                0         
_________________________________________________________________
embedding_61 (Embedding)     (None, 43, 100)           453700    
_________________________________________________________________
global_average_pooling1d_61  (None, 100)               0         
_________________________________________________________________
dense_61 (Dense)             (None, 10)                1010      
=================================================================
Total params: 454,710
Trainable params: 454,710
Non-trainable params: 0
_________________________________________________________________
None
Fold  2
multi-label
multi-label
Loading Data
Training Model
vocab size 4561, sequence length 45
Building FastText Model
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_62 (InputLayer)        (None, 45)                0         
_________________________________________________________________
embedding_62 (Embedding)     (None, 45, 100)           456100    
_________________________________________________________________
global_average_pooling1d_62  (None, 100)               0         
_________________________________________________________________
dense_62 (Dense)             (None, 10)                1010      
=================================================================
Total params: 457,110
Trainable params: 457,110
Non-trainable params: 0
_________________________________________________________________
None
Fold  3
multi-label
multi-label
Loading Data
Training Model
vocab size 4569, sequence length 45
Building FastText Model
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_63 (InputLayer)        (None, 45)                0         
_________________________________________________________________
embedding_63 (Embedding)     (None, 45, 100)           456900    
_________________________________________________________________
global_average_pooling1d_63  (None, 100)               0         
_________________________________________________________________
dense_63 (Dense)             (None, 10)                1010      
=================================================================
Total params: 457,910
Trainable params: 457,910
Non-trainable params: 0
_________________________________________________________________
None
Fold  4
multi-label
multi-label
Loading Data
Training Model
vocab size 4518, sequence length 45
Building FastText Model
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_64 (InputLayer)        (None, 45)                0         
_________________________________________________________________
embedding_64 (Embedding)     (None, 45, 100)           451800    
_________________________________________________________________
global_average_pooling1d_64  (None, 100)               0         
_________________________________________________________________
dense_64 (Dense)             (None, 10)                1010      
=================================================================
Total params: 452,810
Trainable params: 452,810
Non-trainable params: 0
_________________________________________________________________
None
Fold  5
multi-label
multi-label
Loading Data
Training Model
vocab size 4426, sequence length 45
Building FastText Model
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_65 (InputLayer)        (None, 45)                0         
_________________________________________________________________
embedding_65 (Embedding)     (None, 45, 100)           442600    
_________________________________________________________________
global_average_pooling1d_65  (None, 100)               0         
_________________________________________________________________
dense_65 (Dense)             (None, 10)                1010      
=================================================================
Total params: 443,610
Trainable params: 443,610
Non-trainable params: 0
_________________________________________________________________
None
time elapsed: 141.66924686700077
Fold  1
multi-label
multi-label
Loading Data
Training Model
vocab size 4537, sequence length 43
Building FastText Model
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_66 (InputLayer)        (None, 43)                0         
_________________________________________________________________
embedding_66 (Embedding)     (None, 43, 100)           453700    
_________________________________________________________________
global_average_pooling1d_66  (None, 100)               0         
_________________________________________________________________
dense_66 (Dense)             (None, 10)                1010      
=================================================================
Total params: 454,710
Trainable params: 454,710
Non-trainable params: 0
_________________________________________________________________
None
Fold  2
multi-label
multi-label
Loading Data
Training Model
vocab size 4561, sequence length 45
Building FastText Model
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_67 (InputLayer)        (None, 45)                0         
_________________________________________________________________
embedding_67 (Embedding)     (None, 45, 100)           456100    
_________________________________________________________________
global_average_pooling1d_67  (None, 100)               0         
_________________________________________________________________
dense_67 (Dense)             (None, 10)                1010      
=================================================================
Total params: 457,110
Trainable params: 457,110
Non-trainable params: 0
_________________________________________________________________
None
Fold  3
multi-label
multi-label
Loading Data
Training Model
vocab size 4569, sequence length 45
Building FastText Model
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_68 (InputLayer)        (None, 45)                0         
_________________________________________________________________
embedding_68 (Embedding)     (None, 45, 100)           456900    
_________________________________________________________________
global_average_pooling1d_68  (None, 100)               0         
_________________________________________________________________
dense_68 (Dense)             (None, 10)                1010      
=================================================================
Total params: 457,910
Trainable params: 457,910
Non-trainable params: 0
_________________________________________________________________
None
Fold  4
multi-label
multi-label
Loading Data
Training Model
vocab size 4518, sequence length 45
Building FastText Model
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_69 (InputLayer)        (None, 45)                0         
_________________________________________________________________
embedding_69 (Embedding)     (None, 45, 100)           451800    
_________________________________________________________________
global_average_pooling1d_69  (None, 100)               0         
_________________________________________________________________
dense_69 (Dense)             (None, 10)                1010      
=================================================================
Total params: 452,810
Trainable params: 452,810
Non-trainable params: 0
_________________________________________________________________
None
Fold  5
multi-label
multi-label
Loading Data
Training Model
vocab size 4426, sequence length 45
Building FastText Model
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_70 (InputLayer)        (None, 45)                0         
_________________________________________________________________
embedding_70 (Embedding)     (None, 45, 100)           442600    
_________________________________________________________________
global_average_pooling1d_70  (None, 100)               0         
_________________________________________________________________
dense_70 (Dense)             (None, 10)                1010      
=================================================================
Total params: 443,610
Trainable params: 443,610
Non-trainable params: 0
_________________________________________________________________
None
time elapsed: 187.23010651100049
Fold  1
multi-label
multi-label
Loading Data
Training Model
vocab size 4537, sequence length 43
Building FastText Model
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_71 (InputLayer)        (None, 43)                0         
_________________________________________________________________
embedding_71 (Embedding)     (None, 43, 100)           453700    
_________________________________________________________________
global_average_pooling1d_71  (None, 100)               0         
_________________________________________________________________
dense_71 (Dense)             (None, 10)                1010      
=================================================================
Total params: 454,710
Trainable params: 454,710
Non-trainable params: 0
_________________________________________________________________
None
Fold  2
multi-label
multi-label
Loading Data
Training Model
vocab size 4561, sequence length 45
Building FastText Model
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_72 (InputLayer)        (None, 45)                0         
_________________________________________________________________
embedding_72 (Embedding)     (None, 45, 100)           456100    
_________________________________________________________________
global_average_pooling1d_72  (None, 100)               0         
_________________________________________________________________
dense_72 (Dense)             (None, 10)                1010      
=================================================================
Total params: 457,110
Trainable params: 457,110
Non-trainable params: 0
_________________________________________________________________
None
Fold  3
multi-label
multi-label
Loading Data
Training Model
vocab size 4569, sequence length 45
Building FastText Model
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_73 (InputLayer)        (None, 45)                0         
_________________________________________________________________
embedding_73 (Embedding)     (None, 45, 100)           456900    
_________________________________________________________________
global_average_pooling1d_73  (None, 100)               0         
_________________________________________________________________
dense_73 (Dense)             (None, 10)                1010      
=================================================================
Total params: 457,910
Trainable params: 457,910
Non-trainable params: 0
_________________________________________________________________
None
Fold  4
multi-label
multi-label
Loading Data
Training Model
vocab size 4518, sequence length 45
Building FastText Model
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_74 (InputLayer)        (None, 45)                0         
_________________________________________________________________
embedding_74 (Embedding)     (None, 45, 100)           451800    
_________________________________________________________________
global_average_pooling1d_74  (None, 100)               0         
_________________________________________________________________
dense_74 (Dense)             (None, 10)                1010      
=================================================================
Total params: 452,810
Trainable params: 452,810
Non-trainable params: 0
_________________________________________________________________
None
Fold  5
multi-label
multi-label
Loading Data
Training Model
vocab size 4426, sequence length 45
Building FastText Model
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_75 (InputLayer)        (None, 45)                0         
_________________________________________________________________
embedding_75 (Embedding)     (None, 45, 100)           442600    
_________________________________________________________________
global_average_pooling1d_75  (None, 100)               0         
_________________________________________________________________
dense_75 (Dense)             (None, 10)                1010      
=================================================================
Total params: 443,610
Trainable params: 443,610
Non-trainable params: 0
_________________________________________________________________
None
time elapsed: 234.54498272700584
Fold  1
multi-label
multi-label
Loading Data
Training Model
vocab size 4537, sequence length 43
Building FastText Model
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_76 (InputLayer)        (None, 43)                0         
_________________________________________________________________
embedding_76 (Embedding)     (None, 43, 100)           453700    
_________________________________________________________________
global_average_pooling1d_76  (None, 100)               0         
_________________________________________________________________
dense_76 (Dense)             (None, 10)                1010      
=================================================================
Total params: 454,710
Trainable params: 454,710
Non-trainable params: 0
_________________________________________________________________
None
Fold  2
multi-label
multi-label
Loading Data
Training Model
vocab size 4561, sequence length 45
Building FastText Model
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_77 (InputLayer)        (None, 45)                0         
_________________________________________________________________
embedding_77 (Embedding)     (None, 45, 100)           456100    
_________________________________________________________________
global_average_pooling1d_77  (None, 100)               0         
_________________________________________________________________
dense_77 (Dense)             (None, 10)                1010      
=================================================================
Total params: 457,110
Trainable params: 457,110
Non-trainable params: 0
_________________________________________________________________
None
Fold  3
multi-label
multi-label
Loading Data
Training Model
vocab size 4569, sequence length 45
Building FastText Model
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_78 (InputLayer)        (None, 45)                0         
_________________________________________________________________
embedding_78 (Embedding)     (None, 45, 100)           456900    
_________________________________________________________________
global_average_pooling1d_78  (None, 100)               0         
_________________________________________________________________
dense_78 (Dense)             (None, 10)                1010      
=================================================================
Total params: 457,910
Trainable params: 457,910
Non-trainable params: 0
_________________________________________________________________
None
Fold  4
multi-label
multi-label
Loading Data
Training Model
vocab size 4518, sequence length 45
Building FastText Model
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_79 (InputLayer)        (None, 45)                0         
_________________________________________________________________
embedding_79 (Embedding)     (None, 45, 100)           451800    
_________________________________________________________________
global_average_pooling1d_79  (None, 100)               0         
_________________________________________________________________
dense_79 (Dense)             (None, 10)                1010      
=================================================================
Total params: 452,810
Trainable params: 452,810
Non-trainable params: 0
_________________________________________________________________
None
Fold  5
multi-label
multi-label
Loading Data
Training Model
vocab size 4426, sequence length 45
Building FastText Model
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_80 (InputLayer)        (None, 45)                0         
_________________________________________________________________
embedding_80 (Embedding)     (None, 45, 100)           442600    
_________________________________________________________________
global_average_pooling1d_80  (None, 100)               0         
_________________________________________________________________
dense_80 (Dense)             (None, 10)                1010      
=================================================================
Total params: 443,610
Trainable params: 443,610
Non-trainable params: 0
_________________________________________________________________
None
time elapsed: 281.5229938620032
Fold  1
multi-label
multi-label
Loading Data
Training Model
vocab size 4537, sequence length 43
Building FastText Model
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_81 (InputLayer)        (None, 43)                0         
_________________________________________________________________
embedding_81 (Embedding)     (None, 43, 100)           453700    
_________________________________________________________________
global_average_pooling1d_81  (None, 100)               0         
_________________________________________________________________
dense_81 (Dense)             (None, 10)                1010      
=================================================================
Total params: 454,710
Trainable params: 454,710
Non-trainable params: 0
_________________________________________________________________
None
Fold  2
multi-label
multi-label
Loading Data
Training Model
vocab size 4561, sequence length 45
Building FastText Model
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_82 (InputLayer)        (None, 45)                0         
_________________________________________________________________
embedding_82 (Embedding)     (None, 45, 100)           456100    
_________________________________________________________________
global_average_pooling1d_82  (None, 100)               0         
_________________________________________________________________
dense_82 (Dense)             (None, 10)                1010      
=================================================================
Total params: 457,110
Trainable params: 457,110
Non-trainable params: 0
_________________________________________________________________
None
Fold  3
multi-label
multi-label
Loading Data
Training Model
vocab size 4569, sequence length 45
Building FastText Model
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_83 (InputLayer)        (None, 45)                0         
_________________________________________________________________
embedding_83 (Embedding)     (None, 45, 100)           456900    
_________________________________________________________________
global_average_pooling1d_83  (None, 100)               0         
_________________________________________________________________
dense_83 (Dense)             (None, 10)                1010      
=================================================================
Total params: 457,910
Trainable params: 457,910
Non-trainable params: 0
_________________________________________________________________
None
Fold  4
multi-label
multi-label
Loading Data
Training Model
vocab size 4518, sequence length 45
Building FastText Model
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_84 (InputLayer)        (None, 45)                0         
_________________________________________________________________
embedding_84 (Embedding)     (None, 45, 100)           451800    
_________________________________________________________________
global_average_pooling1d_84  (None, 100)               0         
_________________________________________________________________
dense_84 (Dense)             (None, 10)                1010      
=================================================================
Total params: 452,810
Trainable params: 452,810
Non-trainable params: 0
_________________________________________________________________
None
Fold  5
multi-label
multi-label
Loading Data
Training Model
vocab size 4426, sequence length 45
Building FastText Model
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_85 (InputLayer)        (None, 45)                0         
_________________________________________________________________
embedding_85 (Embedding)     (None, 45, 100)           442600    
_________________________________________________________________
global_average_pooling1d_85  (None, 100)               0         
_________________________________________________________________
dense_85 (Dense)             (None, 10)                1010      
=================================================================
Total params: 443,610
Trainable params: 443,610
Non-trainable params: 0
_________________________________________________________________
None
time elapsed: 331.5048608760044
Fold  1
multi-label
multi-label
Loading Data
Training Model
vocab size 4537, sequence length 43
Building FastText Model
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_86 (InputLayer)        (None, 43)                0         
_________________________________________________________________
embedding_86 (Embedding)     (None, 43, 100)           453700    
_________________________________________________________________
global_average_pooling1d_86  (None, 100)               0         
_________________________________________________________________
dense_86 (Dense)             (None, 10)                1010      
=================================================================
Total params: 454,710
Trainable params: 454,710
Non-trainable params: 0
_________________________________________________________________
None
Fold  2
multi-label
multi-label
Loading Data
Training Model
vocab size 4561, sequence length 45
Building FastText Model
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_87 (InputLayer)        (None, 45)                0         
_________________________________________________________________
embedding_87 (Embedding)     (None, 45, 100)           456100    
_________________________________________________________________
global_average_pooling1d_87  (None, 100)               0         
_________________________________________________________________
dense_87 (Dense)             (None, 10)                1010      
=================================================================
Total params: 457,110
Trainable params: 457,110
Non-trainable params: 0
_________________________________________________________________
None
Fold  3
multi-label
multi-label
Loading Data
Training Model
vocab size 4569, sequence length 45
Building FastText Model
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_88 (InputLayer)        (None, 45)                0         
_________________________________________________________________
embedding_88 (Embedding)     (None, 45, 100)           456900    
_________________________________________________________________
global_average_pooling1d_88  (None, 100)               0         
_________________________________________________________________
dense_88 (Dense)             (None, 10)                1010      
=================================================================
Total params: 457,910
Trainable params: 457,910
Non-trainable params: 0
_________________________________________________________________
None
Fold  4
multi-label
multi-label
Loading Data
Training Model
vocab size 4518, sequence length 45
Building FastText Model
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_89 (InputLayer)        (None, 45)                0         
_________________________________________________________________
embedding_89 (Embedding)     (None, 45, 100)           451800    
_________________________________________________________________
global_average_pooling1d_89  (None, 100)               0         
_________________________________________________________________
dense_89 (Dense)             (None, 10)                1010      
=================================================================
Total params: 452,810
Trainable params: 452,810
Non-trainable params: 0
_________________________________________________________________
None
Fold  5
multi-label
multi-label
Loading Data
Training Model
vocab size 4426, sequence length 45
Building FastText Model
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_90 (InputLayer)        (None, 45)                0         
_________________________________________________________________
embedding_90 (Embedding)     (None, 45, 100)           442600    
_________________________________________________________________
global_average_pooling1d_90  (None, 100)               0         
_________________________________________________________________
dense_90 (Dense)             (None, 10)                1010      
=================================================================
Total params: 443,610
Trainable params: 443,610
Non-trainable params: 0
_________________________________________________________________
None
time elapsed: 379.98453513799905


Epochs: 10
/home/dan/.local/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
/home/dan/.local/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.
  'precision', 'predicted', average, warn_for)

Hamming Loss:                 0.171

f1 scores 
 -----------
Agreement/disagreement:       0.000        13
Certainty:                    0.000        29
Contrariety:                  0.000       109
Hypotheticality:              0.000        48
Necessity:                    0.000        56
Prediction:                   0.000        88
Source of knowledge:          0.000        95
Tact/rudeness:                0.000        24
Uncertainty:                  0.000        83
Volition:                     0.000        13

Micro-f1 score:               0.000
Macro-f1 score:               0.000

Accuracy                      0.000
['FastText', 'Multi-label', 10, 0.0, 0.0, 0.0]


Epochs: 50

Hamming Loss:                 0.095

f1 scores 
 -----------
Agreement/disagreement:       0.035        13
Certainty:                    0.258        29
Contrariety:                  0.771       109
Hypotheticality:              0.598        48
Necessity:                    0.422        56
Prediction:                   0.759        88
Source of knowledge:          0.598        95
Tact/rudeness:                0.055        24
Uncertainty:                  0.774        83
Volition:                     0.133        13

Micro-f1 score:               0.636
Macro-f1 score:               0.441

Accuracy                      0.257
['FastText', 'Multi-label', 50, 0.44057204184965393, 0.6356758578532881, 0.25740426734492017]


Epochs: 100

Hamming Loss:                 0.064

f1 scores 
 -----------
Agreement/disagreement:       0.704        13
Certainty:                    0.810        29
Contrariety:                  0.810       109
Hypotheticality:              0.733        48
Necessity:                    0.742        56
Prediction:                   0.844        88
Source of knowledge:          0.712        95
Tact/rudeness:                0.615        24
Uncertainty:                  0.871        83
Volition:                     0.706        13

Micro-f1 score:               0.786
Macro-f1 score:               0.755

Accuracy                      0.508
['FastText', 'Multi-label', 100, 0.7545271586434745, 0.786206700046034, 0.5082909424897555]


Epochs: 150

Hamming Loss:                 0.062

f1 scores 
 -----------
Agreement/disagreement:       0.818        13
Certainty:                    0.832        29
Contrariety:                  0.802       109
Hypotheticality:              0.746        48
Necessity:                    0.755        56
Prediction:                   0.842        88
Source of knowledge:          0.724        95
Tact/rudeness:                0.760        24
Uncertainty:                  0.869        83
Volition:                     0.765        13

Micro-f1 score:               0.797
Macro-f1 score:               0.791

Accuracy                      0.536
['FastText', 'Multi-label', 150, 0.7914156216122518, 0.7974410886698766, 0.5356489331637699]


Epochs: 200

Hamming Loss:                 0.061

f1 scores 
 -----------
Agreement/disagreement:       0.824        13
Certainty:                    0.848        29
Contrariety:                  0.802       109
Hypotheticality:              0.760        48
Necessity:                    0.747        56
Prediction:                   0.845        88
Source of knowledge:          0.736        95
Tact/rudeness:                0.791        24
Uncertainty:                  0.867        83
Volition:                     0.765        13

Micro-f1 score:               0.802
Macro-f1 score:               0.799

Accuracy                      0.550
['FastText', 'Multi-label', 200, 0.798527797623594, 0.801619451746404, 0.5499152183128444]


Epochs: 250

Hamming Loss:                 0.062

f1 scores 
 -----------
Agreement/disagreement:       0.819        13
Certainty:                    0.848        29
Contrariety:                  0.802       109
Hypotheticality:              0.757        48
Necessity:                    0.740        56
Prediction:                   0.842        88
Source of knowledge:          0.729        95
Tact/rudeness:                0.801        24
Uncertainty:                  0.878        83
Volition:                     0.765        13

Micro-f1 score:               0.801
Macro-f1 score:               0.798

Accuracy                      0.552
['FastText', 'Multi-label', 250, 0.7981607469403698, 0.8008744662197756, 0.5522944044086477]


Epochs: 300

Hamming Loss:                 0.062

f1 scores 
 -----------
Agreement/disagreement:       0.819        13
Certainty:                    0.848        29
Contrariety:                  0.800       109
Hypotheticality:              0.757        48
Necessity:                    0.739        56
Prediction:                   0.846        88
Source of knowledge:          0.732        95
Tact/rudeness:                0.801        24
Uncertainty:                  0.873        83
Volition:                     0.777        13

Micro-f1 score:               0.801
Macro-f1 score:               0.799

Accuracy                      0.551
['FastText', 'Multi-label', 300, 0.799213297502444, 0.8009457345233312, 0.5511039282181716]


Epochs: 350

Hamming Loss:                 0.062

f1 scores 
 -----------
Agreement/disagreement:       0.819        13
Certainty:                    0.845        29
Contrariety:                  0.802       109
Hypotheticality:              0.760        48
Necessity:                    0.746        56
Prediction:                   0.844        88
Source of knowledge:          0.726        95
Tact/rudeness:                0.801        24
Uncertainty:                  0.869        83
Volition:                     0.777        13

Micro-f1 score:               0.800
Macro-f1 score:               0.799

Accuracy                      0.548
['FastText', 'Multi-label', 350, 0.7988364486530848, 0.8003797746110995, 0.5475360322170411]


Epochs: 400

Hamming Loss:                 0.062

f1 scores 
 -----------
Agreement/disagreement:       0.819        13
Certainty:                    0.857        29
Contrariety:                  0.797       109
Hypotheticality:              0.751        48
Necessity:                    0.742        56
Prediction:                   0.839        88
Source of knowledge:          0.727        95
Tact/rudeness:                0.801        24
Uncertainty:                  0.869        83
Volition:                     0.777        13

Micro-f1 score:               0.798
Macro-f1 score:               0.798

Accuracy                      0.546
['FastText', 'Multi-label', 400, 0.7978496992052639, 0.7982748689355856, 0.5463490885968632]
Fold  1
multi-task
multi-task
Loading Data
Training Model
vocab size 4537, sequence length 43
Building FastText Model
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_91 (InputLayer)           (None, 43)           0                                            
__________________________________________________________________________________________________
embedding_91 (Embedding)        (None, 43, 100)      453700      input_91[0][0]                   
__________________________________________________________________________________________________
global_average_pooling1d_91 (Gl (None, 100)          0           embedding_91[0][0]               
__________________________________________________________________________________________________
dense_91 (Dense)                (None, 1)            101         global_average_pooling1d_91[0][0]
__________________________________________________________________________________________________
dense_92 (Dense)                (None, 1)            101         global_average_pooling1d_91[0][0]
__________________________________________________________________________________________________
dense_93 (Dense)                (None, 1)            101         global_average_pooling1d_91[0][0]
__________________________________________________________________________________________________
dense_94 (Dense)                (None, 1)            101         global_average_pooling1d_91[0][0]
__________________________________________________________________________________________________
dense_95 (Dense)                (None, 1)            101         global_average_pooling1d_91[0][0]
__________________________________________________________________________________________________
dense_96 (Dense)                (None, 1)            101         global_average_pooling1d_91[0][0]
__________________________________________________________________________________________________
dense_97 (Dense)                (None, 1)            101         global_average_pooling1d_91[0][0]
__________________________________________________________________________________________________
dense_98 (Dense)                (None, 1)            101         global_average_pooling1d_91[0][0]
__________________________________________________________________________________________________
dense_99 (Dense)                (None, 1)            101         global_average_pooling1d_91[0][0]
__________________________________________________________________________________________________
dense_100 (Dense)               (None, 1)            101         global_average_pooling1d_91[0][0]
==================================================================================================
Total params: 454,710
Trainable params: 454,710
Non-trainable params: 0
__________________________________________________________________________________________________
None
stacking
Fold  2
multi-task
multi-task
Loading Data
Training Model
vocab size 4561, sequence length 45
Building FastText Model
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_92 (InputLayer)           (None, 45)           0                                            
__________________________________________________________________________________________________
embedding_92 (Embedding)        (None, 45, 100)      456100      input_92[0][0]                   
__________________________________________________________________________________________________
global_average_pooling1d_92 (Gl (None, 100)          0           embedding_92[0][0]               
__________________________________________________________________________________________________
dense_101 (Dense)               (None, 1)            101         global_average_pooling1d_92[0][0]
__________________________________________________________________________________________________
dense_102 (Dense)               (None, 1)            101         global_average_pooling1d_92[0][0]
__________________________________________________________________________________________________
dense_103 (Dense)               (None, 1)            101         global_average_pooling1d_92[0][0]
__________________________________________________________________________________________________
dense_104 (Dense)               (None, 1)            101         global_average_pooling1d_92[0][0]
__________________________________________________________________________________________________
dense_105 (Dense)               (None, 1)            101         global_average_pooling1d_92[0][0]
__________________________________________________________________________________________________
dense_106 (Dense)               (None, 1)            101         global_average_pooling1d_92[0][0]
__________________________________________________________________________________________________
dense_107 (Dense)               (None, 1)            101         global_average_pooling1d_92[0][0]
__________________________________________________________________________________________________
dense_108 (Dense)               (None, 1)            101         global_average_pooling1d_92[0][0]
__________________________________________________________________________________________________
dense_109 (Dense)               (None, 1)            101         global_average_pooling1d_92[0][0]
__________________________________________________________________________________________________
dense_110 (Dense)               (None, 1)            101         global_average_pooling1d_92[0][0]
==================================================================================================
Total params: 457,110
Trainable params: 457,110
Non-trainable params: 0
__________________________________________________________________________________________________
None
stacking
Fold  3
multi-task
multi-task
Loading Data
Training Model
vocab size 4569, sequence length 45
Building FastText Model
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_93 (InputLayer)           (None, 45)           0                                            
__________________________________________________________________________________________________
embedding_93 (Embedding)        (None, 45, 100)      456900      input_93[0][0]                   
__________________________________________________________________________________________________
global_average_pooling1d_93 (Gl (None, 100)          0           embedding_93[0][0]               
__________________________________________________________________________________________________
dense_111 (Dense)               (None, 1)            101         global_average_pooling1d_93[0][0]
__________________________________________________________________________________________________
dense_112 (Dense)               (None, 1)            101         global_average_pooling1d_93[0][0]
__________________________________________________________________________________________________
dense_113 (Dense)               (None, 1)            101         global_average_pooling1d_93[0][0]
__________________________________________________________________________________________________
dense_114 (Dense)               (None, 1)            101         global_average_pooling1d_93[0][0]
__________________________________________________________________________________________________
dense_115 (Dense)               (None, 1)            101         global_average_pooling1d_93[0][0]
__________________________________________________________________________________________________
dense_116 (Dense)               (None, 1)            101         global_average_pooling1d_93[0][0]
__________________________________________________________________________________________________
dense_117 (Dense)               (None, 1)            101         global_average_pooling1d_93[0][0]
__________________________________________________________________________________________________
dense_118 (Dense)               (None, 1)            101         global_average_pooling1d_93[0][0]
__________________________________________________________________________________________________
dense_119 (Dense)               (None, 1)            101         global_average_pooling1d_93[0][0]
__________________________________________________________________________________________________
dense_120 (Dense)               (None, 1)            101         global_average_pooling1d_93[0][0]
==================================================================================================
Total params: 457,910
Trainable params: 457,910
Non-trainable params: 0
__________________________________________________________________________________________________
None
stacking
Fold  4
multi-task
multi-task
Loading Data
Training Model
vocab size 4518, sequence length 45
Building FastText Model
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_94 (InputLayer)           (None, 45)           0                                            
__________________________________________________________________________________________________
embedding_94 (Embedding)        (None, 45, 100)      451800      input_94[0][0]                   
__________________________________________________________________________________________________
global_average_pooling1d_94 (Gl (None, 100)          0           embedding_94[0][0]               
__________________________________________________________________________________________________
dense_121 (Dense)               (None, 1)            101         global_average_pooling1d_94[0][0]
__________________________________________________________________________________________________
dense_122 (Dense)               (None, 1)            101         global_average_pooling1d_94[0][0]
__________________________________________________________________________________________________
dense_123 (Dense)               (None, 1)            101         global_average_pooling1d_94[0][0]
__________________________________________________________________________________________________
dense_124 (Dense)               (None, 1)            101         global_average_pooling1d_94[0][0]
__________________________________________________________________________________________________
dense_125 (Dense)               (None, 1)            101         global_average_pooling1d_94[0][0]
__________________________________________________________________________________________________
dense_126 (Dense)               (None, 1)            101         global_average_pooling1d_94[0][0]
__________________________________________________________________________________________________
dense_127 (Dense)               (None, 1)            101         global_average_pooling1d_94[0][0]
__________________________________________________________________________________________________
dense_128 (Dense)               (None, 1)            101         global_average_pooling1d_94[0][0]
__________________________________________________________________________________________________
dense_129 (Dense)               (None, 1)            101         global_average_pooling1d_94[0][0]
__________________________________________________________________________________________________
dense_130 (Dense)               (None, 1)            101         global_average_pooling1d_94[0][0]
==================================================================================================
Total params: 452,810
Trainable params: 452,810
Non-trainable params: 0
__________________________________________________________________________________________________
None
stacking
Fold  5
multi-task
multi-task
Loading Data
Training Model
vocab size 4426, sequence length 45
Building FastText Model
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_95 (InputLayer)           (None, 45)           0                                            
__________________________________________________________________________________________________
embedding_95 (Embedding)        (None, 45, 100)      442600      input_95[0][0]                   
__________________________________________________________________________________________________
global_average_pooling1d_95 (Gl (None, 100)          0           embedding_95[0][0]               
__________________________________________________________________________________________________
dense_131 (Dense)               (None, 1)            101         global_average_pooling1d_95[0][0]
__________________________________________________________________________________________________
dense_132 (Dense)               (None, 1)            101         global_average_pooling1d_95[0][0]
__________________________________________________________________________________________________
dense_133 (Dense)               (None, 1)            101         global_average_pooling1d_95[0][0]
__________________________________________________________________________________________________
dense_134 (Dense)               (None, 1)            101         global_average_pooling1d_95[0][0]
__________________________________________________________________________________________________
dense_135 (Dense)               (None, 1)            101         global_average_pooling1d_95[0][0]
__________________________________________________________________________________________________
dense_136 (Dense)               (None, 1)            101         global_average_pooling1d_95[0][0]
__________________________________________________________________________________________________
dense_137 (Dense)               (None, 1)            101         global_average_pooling1d_95[0][0]
__________________________________________________________________________________________________
dense_138 (Dense)               (None, 1)            101         global_average_pooling1d_95[0][0]
__________________________________________________________________________________________________
dense_139 (Dense)               (None, 1)            101         global_average_pooling1d_95[0][0]
__________________________________________________________________________________________________
dense_140 (Dense)               (None, 1)            101         global_average_pooling1d_95[0][0]
==================================================================================================
Total params: 443,610
Trainable params: 443,610
Non-trainable params: 0
__________________________________________________________________________________________________
None
stacking
time elapsed: 44.086975141995936
Fold  1
multi-task
multi-task
Loading Data
Training Model
vocab size 4537, sequence length 43
Building FastText Model
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_96 (InputLayer)           (None, 43)           0                                            
__________________________________________________________________________________________________
embedding_96 (Embedding)        (None, 43, 100)      453700      input_96[0][0]                   
__________________________________________________________________________________________________
global_average_pooling1d_96 (Gl (None, 100)          0           embedding_96[0][0]               
__________________________________________________________________________________________________
dense_141 (Dense)               (None, 1)            101         global_average_pooling1d_96[0][0]
__________________________________________________________________________________________________
dense_142 (Dense)               (None, 1)            101         global_average_pooling1d_96[0][0]
__________________________________________________________________________________________________
dense_143 (Dense)               (None, 1)            101         global_average_pooling1d_96[0][0]
__________________________________________________________________________________________________
dense_144 (Dense)               (None, 1)            101         global_average_pooling1d_96[0][0]
__________________________________________________________________________________________________
dense_145 (Dense)               (None, 1)            101         global_average_pooling1d_96[0][0]
__________________________________________________________________________________________________
dense_146 (Dense)               (None, 1)            101         global_average_pooling1d_96[0][0]
__________________________________________________________________________________________________
dense_147 (Dense)               (None, 1)            101         global_average_pooling1d_96[0][0]
__________________________________________________________________________________________________
dense_148 (Dense)               (None, 1)            101         global_average_pooling1d_96[0][0]
__________________________________________________________________________________________________
dense_149 (Dense)               (None, 1)            101         global_average_pooling1d_96[0][0]
__________________________________________________________________________________________________
dense_150 (Dense)               (None, 1)            101         global_average_pooling1d_96[0][0]
==================================================================================================
Total params: 454,710
Trainable params: 454,710
Non-trainable params: 0
__________________________________________________________________________________________________
None
stacking
Fold  2
multi-task
multi-task
Loading Data
Training Model
vocab size 4561, sequence length 45
Building FastText Model
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_97 (InputLayer)           (None, 45)           0                                            
__________________________________________________________________________________________________
embedding_97 (Embedding)        (None, 45, 100)      456100      input_97[0][0]                   
__________________________________________________________________________________________________
global_average_pooling1d_97 (Gl (None, 100)          0           embedding_97[0][0]               
__________________________________________________________________________________________________
dense_151 (Dense)               (None, 1)            101         global_average_pooling1d_97[0][0]
__________________________________________________________________________________________________
dense_152 (Dense)               (None, 1)            101         global_average_pooling1d_97[0][0]
__________________________________________________________________________________________________
dense_153 (Dense)               (None, 1)            101         global_average_pooling1d_97[0][0]
__________________________________________________________________________________________________
dense_154 (Dense)               (None, 1)            101         global_average_pooling1d_97[0][0]
__________________________________________________________________________________________________
dense_155 (Dense)               (None, 1)            101         global_average_pooling1d_97[0][0]
__________________________________________________________________________________________________
dense_156 (Dense)               (None, 1)            101         global_average_pooling1d_97[0][0]
__________________________________________________________________________________________________
dense_157 (Dense)               (None, 1)            101         global_average_pooling1d_97[0][0]
__________________________________________________________________________________________________
dense_158 (Dense)               (None, 1)            101         global_average_pooling1d_97[0][0]
__________________________________________________________________________________________________
dense_159 (Dense)               (None, 1)            101         global_average_pooling1d_97[0][0]
__________________________________________________________________________________________________
dense_160 (Dense)               (None, 1)            101         global_average_pooling1d_97[0][0]
==================================================================================================
Total params: 457,110
Trainable params: 457,110
Non-trainable params: 0
__________________________________________________________________________________________________
None
stacking
Fold  3
multi-task
multi-task
Loading Data
Training Model
vocab size 4569, sequence length 45
Building FastText Model
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_98 (InputLayer)           (None, 45)           0                                            
__________________________________________________________________________________________________
embedding_98 (Embedding)        (None, 45, 100)      456900      input_98[0][0]                   
__________________________________________________________________________________________________
global_average_pooling1d_98 (Gl (None, 100)          0           embedding_98[0][0]               
__________________________________________________________________________________________________
dense_161 (Dense)               (None, 1)            101         global_average_pooling1d_98[0][0]
__________________________________________________________________________________________________
dense_162 (Dense)               (None, 1)            101         global_average_pooling1d_98[0][0]
__________________________________________________________________________________________________
dense_163 (Dense)               (None, 1)            101         global_average_pooling1d_98[0][0]
__________________________________________________________________________________________________
dense_164 (Dense)               (None, 1)            101         global_average_pooling1d_98[0][0]
__________________________________________________________________________________________________
dense_165 (Dense)               (None, 1)            101         global_average_pooling1d_98[0][0]
__________________________________________________________________________________________________
dense_166 (Dense)               (None, 1)            101         global_average_pooling1d_98[0][0]
__________________________________________________________________________________________________
dense_167 (Dense)               (None, 1)            101         global_average_pooling1d_98[0][0]
__________________________________________________________________________________________________
dense_168 (Dense)               (None, 1)            101         global_average_pooling1d_98[0][0]
__________________________________________________________________________________________________
dense_169 (Dense)               (None, 1)            101         global_average_pooling1d_98[0][0]
__________________________________________________________________________________________________
dense_170 (Dense)               (None, 1)            101         global_average_pooling1d_98[0][0]
==================================================================================================
Total params: 457,910
Trainable params: 457,910
Non-trainable params: 0
__________________________________________________________________________________________________
None
stacking
Fold  4
multi-task
multi-task
Loading Data
Training Model
vocab size 4518, sequence length 45
Building FastText Model
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_99 (InputLayer)           (None, 45)           0                                            
__________________________________________________________________________________________________
embedding_99 (Embedding)        (None, 45, 100)      451800      input_99[0][0]                   
__________________________________________________________________________________________________
global_average_pooling1d_99 (Gl (None, 100)          0           embedding_99[0][0]               
__________________________________________________________________________________________________
dense_171 (Dense)               (None, 1)            101         global_average_pooling1d_99[0][0]
__________________________________________________________________________________________________
dense_172 (Dense)               (None, 1)            101         global_average_pooling1d_99[0][0]
__________________________________________________________________________________________________
dense_173 (Dense)               (None, 1)            101         global_average_pooling1d_99[0][0]
__________________________________________________________________________________________________
dense_174 (Dense)               (None, 1)            101         global_average_pooling1d_99[0][0]
__________________________________________________________________________________________________
dense_175 (Dense)               (None, 1)            101         global_average_pooling1d_99[0][0]
__________________________________________________________________________________________________
dense_176 (Dense)               (None, 1)            101         global_average_pooling1d_99[0][0]
__________________________________________________________________________________________________
dense_177 (Dense)               (None, 1)            101         global_average_pooling1d_99[0][0]
__________________________________________________________________________________________________
dense_178 (Dense)               (None, 1)            101         global_average_pooling1d_99[0][0]
__________________________________________________________________________________________________
dense_179 (Dense)               (None, 1)            101         global_average_pooling1d_99[0][0]
__________________________________________________________________________________________________
dense_180 (Dense)               (None, 1)            101         global_average_pooling1d_99[0][0]
==================================================================================================
Total params: 452,810
Trainable params: 452,810
Non-trainable params: 0
__________________________________________________________________________________________________
None
stacking
Fold  5
multi-task
multi-task
Loading Data
Training Model
vocab size 4426, sequence length 45
Building FastText Model
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_100 (InputLayer)          (None, 45)           0                                            
__________________________________________________________________________________________________
embedding_100 (Embedding)       (None, 45, 100)      442600      input_100[0][0]                  
__________________________________________________________________________________________________
global_average_pooling1d_100 (G (None, 100)          0           embedding_100[0][0]              
__________________________________________________________________________________________________
dense_181 (Dense)               (None, 1)            101         global_average_pooling1d_100[0][0
__________________________________________________________________________________________________
dense_182 (Dense)               (None, 1)            101         global_average_pooling1d_100[0][0
__________________________________________________________________________________________________
dense_183 (Dense)               (None, 1)            101         global_average_pooling1d_100[0][0
__________________________________________________________________________________________________
dense_184 (Dense)               (None, 1)            101         global_average_pooling1d_100[0][0
__________________________________________________________________________________________________
dense_185 (Dense)               (None, 1)            101         global_average_pooling1d_100[0][0
__________________________________________________________________________________________________
dense_186 (Dense)               (None, 1)            101         global_average_pooling1d_100[0][0
__________________________________________________________________________________________________
dense_187 (Dense)               (None, 1)            101         global_average_pooling1d_100[0][0
__________________________________________________________________________________________________
dense_188 (Dense)               (None, 1)            101         global_average_pooling1d_100[0][0
__________________________________________________________________________________________________
dense_189 (Dense)               (None, 1)            101         global_average_pooling1d_100[0][0
__________________________________________________________________________________________________
dense_190 (Dense)               (None, 1)            101         global_average_pooling1d_100[0][0
==================================================================================================
Total params: 443,610
Trainable params: 443,610
Non-trainable params: 0
__________________________________________________________________________________________________
None
stacking
time elapsed: 98.94631143099832
Fold  1
multi-task
multi-task
Loading Data
Training Model
vocab size 4537, sequence length 43
Building FastText Model
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_101 (InputLayer)          (None, 43)           0                                            
__________________________________________________________________________________________________
embedding_101 (Embedding)       (None, 43, 100)      453700      input_101[0][0]                  
__________________________________________________________________________________________________
global_average_pooling1d_101 (G (None, 100)          0           embedding_101[0][0]              
__________________________________________________________________________________________________
dense_191 (Dense)               (None, 1)            101         global_average_pooling1d_101[0][0
__________________________________________________________________________________________________
dense_192 (Dense)               (None, 1)            101         global_average_pooling1d_101[0][0
__________________________________________________________________________________________________
dense_193 (Dense)               (None, 1)            101         global_average_pooling1d_101[0][0
__________________________________________________________________________________________________
dense_194 (Dense)               (None, 1)            101         global_average_pooling1d_101[0][0
__________________________________________________________________________________________________
dense_195 (Dense)               (None, 1)            101         global_average_pooling1d_101[0][0
__________________________________________________________________________________________________
dense_196 (Dense)               (None, 1)            101         global_average_pooling1d_101[0][0
__________________________________________________________________________________________________
dense_197 (Dense)               (None, 1)            101         global_average_pooling1d_101[0][0
__________________________________________________________________________________________________
dense_198 (Dense)               (None, 1)            101         global_average_pooling1d_101[0][0
__________________________________________________________________________________________________
dense_199 (Dense)               (None, 1)            101         global_average_pooling1d_101[0][0
__________________________________________________________________________________________________
dense_200 (Dense)               (None, 1)            101         global_average_pooling1d_101[0][0
==================================================================================================
Total params: 454,710
Trainable params: 454,710
Non-trainable params: 0
__________________________________________________________________________________________________
None
stacking
Fold  2
multi-task
multi-task
Loading Data
Training Model
vocab size 4561, sequence length 45
Building FastText Model
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_102 (InputLayer)          (None, 45)           0                                            
__________________________________________________________________________________________________
embedding_102 (Embedding)       (None, 45, 100)      456100      input_102[0][0]                  
__________________________________________________________________________________________________
global_average_pooling1d_102 (G (None, 100)          0           embedding_102[0][0]              
__________________________________________________________________________________________________
dense_201 (Dense)               (None, 1)            101         global_average_pooling1d_102[0][0
__________________________________________________________________________________________________
dense_202 (Dense)               (None, 1)            101         global_average_pooling1d_102[0][0
__________________________________________________________________________________________________
dense_203 (Dense)               (None, 1)            101         global_average_pooling1d_102[0][0
__________________________________________________________________________________________________
dense_204 (Dense)               (None, 1)            101         global_average_pooling1d_102[0][0
__________________________________________________________________________________________________
dense_205 (Dense)               (None, 1)            101         global_average_pooling1d_102[0][0
__________________________________________________________________________________________________
dense_206 (Dense)               (None, 1)            101         global_average_pooling1d_102[0][0
__________________________________________________________________________________________________
dense_207 (Dense)               (None, 1)            101         global_average_pooling1d_102[0][0
__________________________________________________________________________________________________
dense_208 (Dense)               (None, 1)            101         global_average_pooling1d_102[0][0
__________________________________________________________________________________________________
dense_209 (Dense)               (None, 1)            101         global_average_pooling1d_102[0][0
__________________________________________________________________________________________________
dense_210 (Dense)               (None, 1)            101         global_average_pooling1d_102[0][0
==================================================================================================
Total params: 457,110
Trainable params: 457,110
Non-trainable params: 0
__________________________________________________________________________________________________
None
stacking
Fold  3
multi-task
multi-task
Loading Data
Training Model
vocab size 4569, sequence length 45
Building FastText Model
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_103 (InputLayer)          (None, 45)           0                                            
__________________________________________________________________________________________________
embedding_103 (Embedding)       (None, 45, 100)      456900      input_103[0][0]                  
__________________________________________________________________________________________________
global_average_pooling1d_103 (G (None, 100)          0           embedding_103[0][0]              
__________________________________________________________________________________________________
dense_211 (Dense)               (None, 1)            101         global_average_pooling1d_103[0][0
__________________________________________________________________________________________________
dense_212 (Dense)               (None, 1)            101         global_average_pooling1d_103[0][0
__________________________________________________________________________________________________
dense_213 (Dense)               (None, 1)            101         global_average_pooling1d_103[0][0
__________________________________________________________________________________________________
dense_214 (Dense)               (None, 1)            101         global_average_pooling1d_103[0][0
__________________________________________________________________________________________________
dense_215 (Dense)               (None, 1)            101         global_average_pooling1d_103[0][0
__________________________________________________________________________________________________
dense_216 (Dense)               (None, 1)            101         global_average_pooling1d_103[0][0
__________________________________________________________________________________________________
dense_217 (Dense)               (None, 1)            101         global_average_pooling1d_103[0][0
__________________________________________________________________________________________________
dense_218 (Dense)               (None, 1)            101         global_average_pooling1d_103[0][0
__________________________________________________________________________________________________
dense_219 (Dense)               (None, 1)            101         global_average_pooling1d_103[0][0
__________________________________________________________________________________________________
dense_220 (Dense)               (None, 1)            101         global_average_pooling1d_103[0][0
==================================================================================================
Total params: 457,910
Trainable params: 457,910
Non-trainable params: 0
__________________________________________________________________________________________________
None
stacking
Fold  4
multi-task
multi-task
Loading Data
Training Model
vocab size 4518, sequence length 45
Building FastText Model
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_104 (InputLayer)          (None, 45)           0                                            
__________________________________________________________________________________________________
embedding_104 (Embedding)       (None, 45, 100)      451800      input_104[0][0]                  
__________________________________________________________________________________________________
global_average_pooling1d_104 (G (None, 100)          0           embedding_104[0][0]              
__________________________________________________________________________________________________
dense_221 (Dense)               (None, 1)            101         global_average_pooling1d_104[0][0
__________________________________________________________________________________________________
dense_222 (Dense)               (None, 1)            101         global_average_pooling1d_104[0][0
__________________________________________________________________________________________________
dense_223 (Dense)               (None, 1)            101         global_average_pooling1d_104[0][0
__________________________________________________________________________________________________
dense_224 (Dense)               (None, 1)            101         global_average_pooling1d_104[0][0
__________________________________________________________________________________________________
dense_225 (Dense)               (None, 1)            101         global_average_pooling1d_104[0][0
__________________________________________________________________________________________________
dense_226 (Dense)               (None, 1)            101         global_average_pooling1d_104[0][0
__________________________________________________________________________________________________
dense_227 (Dense)               (None, 1)            101         global_average_pooling1d_104[0][0
__________________________________________________________________________________________________
dense_228 (Dense)               (None, 1)            101         global_average_pooling1d_104[0][0
__________________________________________________________________________________________________
dense_229 (Dense)               (None, 1)            101         global_average_pooling1d_104[0][0
__________________________________________________________________________________________________
dense_230 (Dense)               (None, 1)            101         global_average_pooling1d_104[0][0
==================================================================================================
Total params: 452,810
Trainable params: 452,810
Non-trainable params: 0
__________________________________________________________________________________________________
None
stacking
Fold  5
multi-task
multi-task
Loading Data
Training Model
vocab size 4426, sequence length 45
Building FastText Model
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_105 (InputLayer)          (None, 45)           0                                            
__________________________________________________________________________________________________
embedding_105 (Embedding)       (None, 45, 100)      442600      input_105[0][0]                  
__________________________________________________________________________________________________
global_average_pooling1d_105 (G (None, 100)          0           embedding_105[0][0]              
__________________________________________________________________________________________________
dense_231 (Dense)               (None, 1)            101         global_average_pooling1d_105[0][0
__________________________________________________________________________________________________
dense_232 (Dense)               (None, 1)            101         global_average_pooling1d_105[0][0
__________________________________________________________________________________________________
dense_233 (Dense)               (None, 1)            101         global_average_pooling1d_105[0][0
__________________________________________________________________________________________________
dense_234 (Dense)               (None, 1)            101         global_average_pooling1d_105[0][0
__________________________________________________________________________________________________
dense_235 (Dense)               (None, 1)            101         global_average_pooling1d_105[0][0
__________________________________________________________________________________________________
dense_236 (Dense)               (None, 1)            101         global_average_pooling1d_105[0][0
__________________________________________________________________________________________________
dense_237 (Dense)               (None, 1)            101         global_average_pooling1d_105[0][0
__________________________________________________________________________________________________
dense_238 (Dense)               (None, 1)            101         global_average_pooling1d_105[0][0
__________________________________________________________________________________________________
dense_239 (Dense)               (None, 1)            101         global_average_pooling1d_105[0][0
__________________________________________________________________________________________________
dense_240 (Dense)               (None, 1)            101         global_average_pooling1d_105[0][0
==================================================================================================
Total params: 443,610
Trainable params: 443,610
Non-trainable params: 0
__________________________________________________________________________________________________
None
stacking
time elapsed: 173.21728631499718
Fold  1
multi-task
multi-task
Loading Data
Training Model
vocab size 4537, sequence length 43
Building FastText Model
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_106 (InputLayer)          (None, 43)           0                                            
__________________________________________________________________________________________________
embedding_106 (Embedding)       (None, 43, 100)      453700      input_106[0][0]                  
__________________________________________________________________________________________________
global_average_pooling1d_106 (G (None, 100)          0           embedding_106[0][0]              
__________________________________________________________________________________________________
dense_241 (Dense)               (None, 1)            101         global_average_pooling1d_106[0][0
__________________________________________________________________________________________________
dense_242 (Dense)               (None, 1)            101         global_average_pooling1d_106[0][0
__________________________________________________________________________________________________
dense_243 (Dense)               (None, 1)            101         global_average_pooling1d_106[0][0
__________________________________________________________________________________________________
dense_244 (Dense)               (None, 1)            101         global_average_pooling1d_106[0][0
__________________________________________________________________________________________________
dense_245 (Dense)               (None, 1)            101         global_average_pooling1d_106[0][0
__________________________________________________________________________________________________
dense_246 (Dense)               (None, 1)            101         global_average_pooling1d_106[0][0
__________________________________________________________________________________________________
dense_247 (Dense)               (None, 1)            101         global_average_pooling1d_106[0][0
__________________________________________________________________________________________________
dense_248 (Dense)               (None, 1)            101         global_average_pooling1d_106[0][0
__________________________________________________________________________________________________
dense_249 (Dense)               (None, 1)            101         global_average_pooling1d_106[0][0
__________________________________________________________________________________________________
dense_250 (Dense)               (None, 1)            101         global_average_pooling1d_106[0][0
==================================================================================================
Total params: 454,710
Trainable params: 454,710
Non-trainable params: 0
__________________________________________________________________________________________________
None
stacking
Fold  2
multi-task
multi-task
Loading Data
Training Model
vocab size 4561, sequence length 45
Building FastText Model
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_107 (InputLayer)          (None, 45)           0                                            
__________________________________________________________________________________________________
embedding_107 (Embedding)       (None, 45, 100)      456100      input_107[0][0]                  
__________________________________________________________________________________________________
global_average_pooling1d_107 (G (None, 100)          0           embedding_107[0][0]              
__________________________________________________________________________________________________
dense_251 (Dense)               (None, 1)            101         global_average_pooling1d_107[0][0
__________________________________________________________________________________________________
dense_252 (Dense)               (None, 1)            101         global_average_pooling1d_107[0][0
__________________________________________________________________________________________________
dense_253 (Dense)               (None, 1)            101         global_average_pooling1d_107[0][0
__________________________________________________________________________________________________
dense_254 (Dense)               (None, 1)            101         global_average_pooling1d_107[0][0
__________________________________________________________________________________________________
dense_255 (Dense)               (None, 1)            101         global_average_pooling1d_107[0][0
__________________________________________________________________________________________________
dense_256 (Dense)               (None, 1)            101         global_average_pooling1d_107[0][0
__________________________________________________________________________________________________
dense_257 (Dense)               (None, 1)            101         global_average_pooling1d_107[0][0
__________________________________________________________________________________________________
dense_258 (Dense)               (None, 1)            101         global_average_pooling1d_107[0][0
__________________________________________________________________________________________________
dense_259 (Dense)               (None, 1)            101         global_average_pooling1d_107[0][0
__________________________________________________________________________________________________
dense_260 (Dense)               (None, 1)            101         global_average_pooling1d_107[0][0
==================================================================================================
Total params: 457,110
Trainable params: 457,110
Non-trainable params: 0
__________________________________________________________________________________________________
None
stacking
Fold  3
multi-task
multi-task
Loading Data
Training Model
vocab size 4569, sequence length 45
Building FastText Model
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_108 (InputLayer)          (None, 45)           0                                            
__________________________________________________________________________________________________
embedding_108 (Embedding)       (None, 45, 100)      456900      input_108[0][0]                  
__________________________________________________________________________________________________
global_average_pooling1d_108 (G (None, 100)          0           embedding_108[0][0]              
__________________________________________________________________________________________________
dense_261 (Dense)               (None, 1)            101         global_average_pooling1d_108[0][0
__________________________________________________________________________________________________
dense_262 (Dense)               (None, 1)            101         global_average_pooling1d_108[0][0
__________________________________________________________________________________________________
dense_263 (Dense)               (None, 1)            101         global_average_pooling1d_108[0][0
__________________________________________________________________________________________________
dense_264 (Dense)               (None, 1)            101         global_average_pooling1d_108[0][0
__________________________________________________________________________________________________
dense_265 (Dense)               (None, 1)            101         global_average_pooling1d_108[0][0
__________________________________________________________________________________________________
dense_266 (Dense)               (None, 1)            101         global_average_pooling1d_108[0][0
__________________________________________________________________________________________________
dense_267 (Dense)               (None, 1)            101         global_average_pooling1d_108[0][0
__________________________________________________________________________________________________
dense_268 (Dense)               (None, 1)            101         global_average_pooling1d_108[0][0
__________________________________________________________________________________________________
dense_269 (Dense)               (None, 1)            101         global_average_pooling1d_108[0][0
__________________________________________________________________________________________________
dense_270 (Dense)               (None, 1)            101         global_average_pooling1d_108[0][0
==================================================================================================
Total params: 457,910
Trainable params: 457,910
Non-trainable params: 0
__________________________________________________________________________________________________
None
stacking
Fold  4
multi-task
multi-task
Loading Data
Training Model
vocab size 4518, sequence length 45
Building FastText Model
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_109 (InputLayer)          (None, 45)           0                                            
__________________________________________________________________________________________________
embedding_109 (Embedding)       (None, 45, 100)      451800      input_109[0][0]                  
__________________________________________________________________________________________________
global_average_pooling1d_109 (G (None, 100)          0           embedding_109[0][0]              
__________________________________________________________________________________________________
dense_271 (Dense)               (None, 1)            101         global_average_pooling1d_109[0][0
__________________________________________________________________________________________________
dense_272 (Dense)               (None, 1)            101         global_average_pooling1d_109[0][0
__________________________________________________________________________________________________
dense_273 (Dense)               (None, 1)            101         global_average_pooling1d_109[0][0
__________________________________________________________________________________________________
dense_274 (Dense)               (None, 1)            101         global_average_pooling1d_109[0][0
__________________________________________________________________________________________________
dense_275 (Dense)               (None, 1)            101         global_average_pooling1d_109[0][0
__________________________________________________________________________________________________
dense_276 (Dense)               (None, 1)            101         global_average_pooling1d_109[0][0
__________________________________________________________________________________________________
dense_277 (Dense)               (None, 1)            101         global_average_pooling1d_109[0][0
__________________________________________________________________________________________________
dense_278 (Dense)               (None, 1)            101         global_average_pooling1d_109[0][0
__________________________________________________________________________________________________
dense_279 (Dense)               (None, 1)            101         global_average_pooling1d_109[0][0
__________________________________________________________________________________________________
dense_280 (Dense)               (None, 1)            101         global_average_pooling1d_109[0][0
==================================================================================================
Total params: 452,810
Trainable params: 452,810
Non-trainable params: 0
__________________________________________________________________________________________________
None
stacking
Fold  5
multi-task
multi-task
Loading Data
Training Model
vocab size 4426, sequence length 45
Building FastText Model
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_110 (InputLayer)          (None, 45)           0                                            
__________________________________________________________________________________________________
embedding_110 (Embedding)       (None, 45, 100)      442600      input_110[0][0]                  
__________________________________________________________________________________________________
global_average_pooling1d_110 (G (None, 100)          0           embedding_110[0][0]              
__________________________________________________________________________________________________
dense_281 (Dense)               (None, 1)            101         global_average_pooling1d_110[0][0
__________________________________________________________________________________________________
dense_282 (Dense)               (None, 1)            101         global_average_pooling1d_110[0][0
__________________________________________________________________________________________________
dense_283 (Dense)               (None, 1)            101         global_average_pooling1d_110[0][0
__________________________________________________________________________________________________
dense_284 (Dense)               (None, 1)            101         global_average_pooling1d_110[0][0
__________________________________________________________________________________________________
dense_285 (Dense)               (None, 1)            101         global_average_pooling1d_110[0][0
__________________________________________________________________________________________________
dense_286 (Dense)               (None, 1)            101         global_average_pooling1d_110[0][0
__________________________________________________________________________________________________
dense_287 (Dense)               (None, 1)            101         global_average_pooling1d_110[0][0
__________________________________________________________________________________________________
dense_288 (Dense)               (None, 1)            101         global_average_pooling1d_110[0][0
__________________________________________________________________________________________________
dense_289 (Dense)               (None, 1)            101         global_average_pooling1d_110[0][0
__________________________________________________________________________________________________
dense_290 (Dense)               (None, 1)            101         global_average_pooling1d_110[0][0
==================================================================================================
Total params: 443,610
Trainable params: 443,610
Non-trainable params: 0
__________________________________________________________________________________________________
None
stacking
time elapsed: 251.97504750900407
Fold  1
multi-task
multi-task
Loading Data
Training Model
vocab size 4537, sequence length 43
Building FastText Model
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_111 (InputLayer)          (None, 43)           0                                            
__________________________________________________________________________________________________
embedding_111 (Embedding)       (None, 43, 100)      453700      input_111[0][0]                  
__________________________________________________________________________________________________
global_average_pooling1d_111 (G (None, 100)          0           embedding_111[0][0]              
__________________________________________________________________________________________________
dense_291 (Dense)               (None, 1)            101         global_average_pooling1d_111[0][0
__________________________________________________________________________________________________
dense_292 (Dense)               (None, 1)            101         global_average_pooling1d_111[0][0
__________________________________________________________________________________________________
dense_293 (Dense)               (None, 1)            101         global_average_pooling1d_111[0][0
__________________________________________________________________________________________________
dense_294 (Dense)               (None, 1)            101         global_average_pooling1d_111[0][0
__________________________________________________________________________________________________
dense_295 (Dense)               (None, 1)            101         global_average_pooling1d_111[0][0
__________________________________________________________________________________________________
dense_296 (Dense)               (None, 1)            101         global_average_pooling1d_111[0][0
__________________________________________________________________________________________________
dense_297 (Dense)               (None, 1)            101         global_average_pooling1d_111[0][0
__________________________________________________________________________________________________
dense_298 (Dense)               (None, 1)            101         global_average_pooling1d_111[0][0
__________________________________________________________________________________________________
dense_299 (Dense)               (None, 1)            101         global_average_pooling1d_111[0][0
__________________________________________________________________________________________________
dense_300 (Dense)               (None, 1)            101         global_average_pooling1d_111[0][0
==================================================================================================
Total params: 454,710
Trainable params: 454,710
Non-trainable params: 0
__________________________________________________________________________________________________
None
stacking
Fold  2
multi-task
multi-task
Loading Data
Training Model
vocab size 4561, sequence length 45
Building FastText Model
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_112 (InputLayer)          (None, 45)           0                                            
__________________________________________________________________________________________________
embedding_112 (Embedding)       (None, 45, 100)      456100      input_112[0][0]                  
__________________________________________________________________________________________________
global_average_pooling1d_112 (G (None, 100)          0           embedding_112[0][0]              
__________________________________________________________________________________________________
dense_301 (Dense)               (None, 1)            101         global_average_pooling1d_112[0][0
__________________________________________________________________________________________________
dense_302 (Dense)               (None, 1)            101         global_average_pooling1d_112[0][0
__________________________________________________________________________________________________
dense_303 (Dense)               (None, 1)            101         global_average_pooling1d_112[0][0
__________________________________________________________________________________________________
dense_304 (Dense)               (None, 1)            101         global_average_pooling1d_112[0][0
__________________________________________________________________________________________________
dense_305 (Dense)               (None, 1)            101         global_average_pooling1d_112[0][0
__________________________________________________________________________________________________
dense_306 (Dense)               (None, 1)            101         global_average_pooling1d_112[0][0
__________________________________________________________________________________________________
dense_307 (Dense)               (None, 1)            101         global_average_pooling1d_112[0][0
__________________________________________________________________________________________________
dense_308 (Dense)               (None, 1)            101         global_average_pooling1d_112[0][0
__________________________________________________________________________________________________
dense_309 (Dense)               (None, 1)            101         global_average_pooling1d_112[0][0
__________________________________________________________________________________________________
dense_310 (Dense)               (None, 1)            101         global_average_pooling1d_112[0][0
==================================================================================================
Total params: 457,110
Trainable params: 457,110
Non-trainable params: 0
__________________________________________________________________________________________________
None
stacking
Fold  3
multi-task
multi-task
Loading Data
Training Model
vocab size 4569, sequence length 45
Building FastText Model
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_113 (InputLayer)          (None, 45)           0                                            
__________________________________________________________________________________________________
embedding_113 (Embedding)       (None, 45, 100)      456900      input_113[0][0]                  
__________________________________________________________________________________________________
global_average_pooling1d_113 (G (None, 100)          0           embedding_113[0][0]              
__________________________________________________________________________________________________
dense_311 (Dense)               (None, 1)            101         global_average_pooling1d_113[0][0
__________________________________________________________________________________________________
dense_312 (Dense)               (None, 1)            101         global_average_pooling1d_113[0][0
__________________________________________________________________________________________________
dense_313 (Dense)               (None, 1)            101         global_average_pooling1d_113[0][0
__________________________________________________________________________________________________
dense_314 (Dense)               (None, 1)            101         global_average_pooling1d_113[0][0
__________________________________________________________________________________________________
dense_315 (Dense)               (None, 1)            101         global_average_pooling1d_113[0][0
__________________________________________________________________________________________________
dense_316 (Dense)               (None, 1)            101         global_average_pooling1d_113[0][0
__________________________________________________________________________________________________
dense_317 (Dense)               (None, 1)            101         global_average_pooling1d_113[0][0
__________________________________________________________________________________________________
dense_318 (Dense)               (None, 1)            101         global_average_pooling1d_113[0][0
__________________________________________________________________________________________________
dense_319 (Dense)               (None, 1)            101         global_average_pooling1d_113[0][0
__________________________________________________________________________________________________
dense_320 (Dense)               (None, 1)            101         global_average_pooling1d_113[0][0
==================================================================================================
Total params: 457,910
Trainable params: 457,910
Non-trainable params: 0
__________________________________________________________________________________________________
None
stacking
Fold  4
multi-task
multi-task
Loading Data
Training Model
vocab size 4518, sequence length 45
Building FastText Model
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_114 (InputLayer)          (None, 45)           0                                            
__________________________________________________________________________________________________
embedding_114 (Embedding)       (None, 45, 100)      451800      input_114[0][0]                  
__________________________________________________________________________________________________
global_average_pooling1d_114 (G (None, 100)          0           embedding_114[0][0]              
__________________________________________________________________________________________________
dense_321 (Dense)               (None, 1)            101         global_average_pooling1d_114[0][0
__________________________________________________________________________________________________
dense_322 (Dense)               (None, 1)            101         global_average_pooling1d_114[0][0
__________________________________________________________________________________________________
dense_323 (Dense)               (None, 1)            101         global_average_pooling1d_114[0][0
__________________________________________________________________________________________________
dense_324 (Dense)               (None, 1)            101         global_average_pooling1d_114[0][0
__________________________________________________________________________________________________
dense_325 (Dense)               (None, 1)            101         global_average_pooling1d_114[0][0
__________________________________________________________________________________________________
dense_326 (Dense)               (None, 1)            101         global_average_pooling1d_114[0][0
__________________________________________________________________________________________________
dense_327 (Dense)               (None, 1)            101         global_average_pooling1d_114[0][0
__________________________________________________________________________________________________
dense_328 (Dense)               (None, 1)            101         global_average_pooling1d_114[0][0
__________________________________________________________________________________________________
dense_329 (Dense)               (None, 1)            101         global_average_pooling1d_114[0][0
__________________________________________________________________________________________________
dense_330 (Dense)               (None, 1)            101         global_average_pooling1d_114[0][0
==================================================================================================
Total params: 452,810
Trainable params: 452,810
Non-trainable params: 0
__________________________________________________________________________________________________
None
stacking
Fold  5
multi-task
multi-task
Loading Data
Training Model
vocab size 4426, sequence length 45
Building FastText Model
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_115 (InputLayer)          (None, 45)           0                                            
__________________________________________________________________________________________________
embedding_115 (Embedding)       (None, 45, 100)      442600      input_115[0][0]                  
__________________________________________________________________________________________________
global_average_pooling1d_115 (G (None, 100)          0           embedding_115[0][0]              
__________________________________________________________________________________________________
dense_331 (Dense)               (None, 1)            101         global_average_pooling1d_115[0][0
__________________________________________________________________________________________________
dense_332 (Dense)               (None, 1)            101         global_average_pooling1d_115[0][0
__________________________________________________________________________________________________
dense_333 (Dense)               (None, 1)            101         global_average_pooling1d_115[0][0
__________________________________________________________________________________________________
dense_334 (Dense)               (None, 1)            101         global_average_pooling1d_115[0][0
__________________________________________________________________________________________________
dense_335 (Dense)               (None, 1)            101         global_average_pooling1d_115[0][0
__________________________________________________________________________________________________
dense_336 (Dense)               (None, 1)            101         global_average_pooling1d_115[0][0
__________________________________________________________________________________________________
dense_337 (Dense)               (None, 1)            101         global_average_pooling1d_115[0][0
__________________________________________________________________________________________________
dense_338 (Dense)               (None, 1)            101         global_average_pooling1d_115[0][0
__________________________________________________________________________________________________
dense_339 (Dense)               (None, 1)            101         global_average_pooling1d_115[0][0
__________________________________________________________________________________________________
dense_340 (Dense)               (None, 1)            101         global_average_pooling1d_115[0][0
==================================================================================================
Total params: 443,610
Trainable params: 443,610
Non-trainable params: 0
__________________________________________________________________________________________________
None
stacking
time elapsed: 336.35486623900215
Fold  1
multi-task
multi-task
Loading Data
Training Model
vocab size 4537, sequence length 43
Building FastText Model
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_116 (InputLayer)          (None, 43)           0                                            
__________________________________________________________________________________________________
embedding_116 (Embedding)       (None, 43, 100)      453700      input_116[0][0]                  
__________________________________________________________________________________________________
global_average_pooling1d_116 (G (None, 100)          0           embedding_116[0][0]              
__________________________________________________________________________________________________
dense_341 (Dense)               (None, 1)            101         global_average_pooling1d_116[0][0
__________________________________________________________________________________________________
dense_342 (Dense)               (None, 1)            101         global_average_pooling1d_116[0][0
__________________________________________________________________________________________________
dense_343 (Dense)               (None, 1)            101         global_average_pooling1d_116[0][0
__________________________________________________________________________________________________
dense_344 (Dense)               (None, 1)            101         global_average_pooling1d_116[0][0
__________________________________________________________________________________________________
dense_345 (Dense)               (None, 1)            101         global_average_pooling1d_116[0][0
__________________________________________________________________________________________________
dense_346 (Dense)               (None, 1)            101         global_average_pooling1d_116[0][0
__________________________________________________________________________________________________
dense_347 (Dense)               (None, 1)            101         global_average_pooling1d_116[0][0
__________________________________________________________________________________________________
dense_348 (Dense)               (None, 1)            101         global_average_pooling1d_116[0][0
__________________________________________________________________________________________________
dense_349 (Dense)               (None, 1)            101         global_average_pooling1d_116[0][0
__________________________________________________________________________________________________
dense_350 (Dense)               (None, 1)            101         global_average_pooling1d_116[0][0
==================================================================================================
Total params: 454,710
Trainable params: 454,710
Non-trainable params: 0
__________________________________________________________________________________________________
None
stacking
Fold  2
multi-task
multi-task
Loading Data
Training Model
vocab size 4561, sequence length 45
Building FastText Model
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_117 (InputLayer)          (None, 45)           0                                            
__________________________________________________________________________________________________
embedding_117 (Embedding)       (None, 45, 100)      456100      input_117[0][0]                  
__________________________________________________________________________________________________
global_average_pooling1d_117 (G (None, 100)          0           embedding_117[0][0]              
__________________________________________________________________________________________________
dense_351 (Dense)               (None, 1)            101         global_average_pooling1d_117[0][0
__________________________________________________________________________________________________
dense_352 (Dense)               (None, 1)            101         global_average_pooling1d_117[0][0
__________________________________________________________________________________________________
dense_353 (Dense)               (None, 1)            101         global_average_pooling1d_117[0][0
__________________________________________________________________________________________________
dense_354 (Dense)               (None, 1)            101         global_average_pooling1d_117[0][0
__________________________________________________________________________________________________
dense_355 (Dense)               (None, 1)            101         global_average_pooling1d_117[0][0
__________________________________________________________________________________________________
dense_356 (Dense)               (None, 1)            101         global_average_pooling1d_117[0][0
__________________________________________________________________________________________________
dense_357 (Dense)               (None, 1)            101         global_average_pooling1d_117[0][0
__________________________________________________________________________________________________
dense_358 (Dense)               (None, 1)            101         global_average_pooling1d_117[0][0
__________________________________________________________________________________________________
dense_359 (Dense)               (None, 1)            101         global_average_pooling1d_117[0][0
__________________________________________________________________________________________________
dense_360 (Dense)               (None, 1)            101         global_average_pooling1d_117[0][0
==================================================================================================
Total params: 457,110
Trainable params: 457,110
Non-trainable params: 0
__________________________________________________________________________________________________
None
stacking
Fold  3
multi-task
multi-task
Loading Data
Training Model
vocab size 4569, sequence length 45
Building FastText Model
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_118 (InputLayer)          (None, 45)           0                                            
__________________________________________________________________________________________________
embedding_118 (Embedding)       (None, 45, 100)      456900      input_118[0][0]                  
__________________________________________________________________________________________________
global_average_pooling1d_118 (G (None, 100)          0           embedding_118[0][0]              
__________________________________________________________________________________________________
dense_361 (Dense)               (None, 1)            101         global_average_pooling1d_118[0][0
__________________________________________________________________________________________________
dense_362 (Dense)               (None, 1)            101         global_average_pooling1d_118[0][0
__________________________________________________________________________________________________
dense_363 (Dense)               (None, 1)            101         global_average_pooling1d_118[0][0
__________________________________________________________________________________________________
dense_364 (Dense)               (None, 1)            101         global_average_pooling1d_118[0][0
__________________________________________________________________________________________________
dense_365 (Dense)               (None, 1)            101         global_average_pooling1d_118[0][0
__________________________________________________________________________________________________
dense_366 (Dense)               (None, 1)            101         global_average_pooling1d_118[0][0
__________________________________________________________________________________________________
dense_367 (Dense)               (None, 1)            101         global_average_pooling1d_118[0][0
__________________________________________________________________________________________________
dense_368 (Dense)               (None, 1)            101         global_average_pooling1d_118[0][0
__________________________________________________________________________________________________
dense_369 (Dense)               (None, 1)            101         global_average_pooling1d_118[0][0
__________________________________________________________________________________________________
dense_370 (Dense)               (None, 1)            101         global_average_pooling1d_118[0][0
==================================================================================================
Total params: 457,910
Trainable params: 457,910
Non-trainable params: 0
__________________________________________________________________________________________________
None
stacking
Fold  4
multi-task
multi-task
Loading Data
Training Model
vocab size 4518, sequence length 45
Building FastText Model
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_119 (InputLayer)          (None, 45)           0                                            
__________________________________________________________________________________________________
embedding_119 (Embedding)       (None, 45, 100)      451800      input_119[0][0]                  
__________________________________________________________________________________________________
global_average_pooling1d_119 (G (None, 100)          0           embedding_119[0][0]              
__________________________________________________________________________________________________
dense_371 (Dense)               (None, 1)            101         global_average_pooling1d_119[0][0
__________________________________________________________________________________________________
dense_372 (Dense)               (None, 1)            101         global_average_pooling1d_119[0][0
__________________________________________________________________________________________________
dense_373 (Dense)               (None, 1)            101         global_average_pooling1d_119[0][0
__________________________________________________________________________________________________
dense_374 (Dense)               (None, 1)            101         global_average_pooling1d_119[0][0
__________________________________________________________________________________________________
dense_375 (Dense)               (None, 1)            101         global_average_pooling1d_119[0][0
__________________________________________________________________________________________________
dense_376 (Dense)               (None, 1)            101         global_average_pooling1d_119[0][0
__________________________________________________________________________________________________
dense_377 (Dense)               (None, 1)            101         global_average_pooling1d_119[0][0
__________________________________________________________________________________________________
dense_378 (Dense)               (None, 1)            101         global_average_pooling1d_119[0][0
__________________________________________________________________________________________________
dense_379 (Dense)               (None, 1)            101         global_average_pooling1d_119[0][0
__________________________________________________________________________________________________
dense_380 (Dense)               (None, 1)            101         global_average_pooling1d_119[0][0
==================================================================================================
Total params: 452,810
Trainable params: 452,810
Non-trainable params: 0
__________________________________________________________________________________________________
None
stacking
Fold  5
multi-task
multi-task
Loading Data
Training Model
vocab size 4426, sequence length 45
Building FastText Model
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_120 (InputLayer)          (None, 45)           0                                            
__________________________________________________________________________________________________
embedding_120 (Embedding)       (None, 45, 100)      442600      input_120[0][0]                  
__________________________________________________________________________________________________
global_average_pooling1d_120 (G (None, 100)          0           embedding_120[0][0]              
__________________________________________________________________________________________________
dense_381 (Dense)               (None, 1)            101         global_average_pooling1d_120[0][0
__________________________________________________________________________________________________
dense_382 (Dense)               (None, 1)            101         global_average_pooling1d_120[0][0
__________________________________________________________________________________________________
dense_383 (Dense)               (None, 1)            101         global_average_pooling1d_120[0][0
__________________________________________________________________________________________________
dense_384 (Dense)               (None, 1)            101         global_average_pooling1d_120[0][0
__________________________________________________________________________________________________
dense_385 (Dense)               (None, 1)            101         global_average_pooling1d_120[0][0
__________________________________________________________________________________________________
dense_386 (Dense)               (None, 1)            101         global_average_pooling1d_120[0][0
__________________________________________________________________________________________________
dense_387 (Dense)               (None, 1)            101         global_average_pooling1d_120[0][0
__________________________________________________________________________________________________
dense_388 (Dense)               (None, 1)            101         global_average_pooling1d_120[0][0
__________________________________________________________________________________________________
dense_389 (Dense)               (None, 1)            101         global_average_pooling1d_120[0][0
__________________________________________________________________________________________________
dense_390 (Dense)               (None, 1)            101         global_average_pooling1d_120[0][0
==================================================================================================
Total params: 443,610
Trainable params: 443,610
Non-trainable params: 0
__________________________________________________________________________________________________
None
stacking
time elapsed: 428.15217606500664
Fold  1
multi-task
multi-task
Loading Data
Training Model
vocab size 4537, sequence length 43
Building FastText Model
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_121 (InputLayer)          (None, 43)           0                                            
__________________________________________________________________________________________________
embedding_121 (Embedding)       (None, 43, 100)      453700      input_121[0][0]                  
__________________________________________________________________________________________________
global_average_pooling1d_121 (G (None, 100)          0           embedding_121[0][0]              
__________________________________________________________________________________________________
dense_391 (Dense)               (None, 1)            101         global_average_pooling1d_121[0][0
__________________________________________________________________________________________________
dense_392 (Dense)               (None, 1)            101         global_average_pooling1d_121[0][0
__________________________________________________________________________________________________
dense_393 (Dense)               (None, 1)            101         global_average_pooling1d_121[0][0
__________________________________________________________________________________________________
dense_394 (Dense)               (None, 1)            101         global_average_pooling1d_121[0][0
__________________________________________________________________________________________________
dense_395 (Dense)               (None, 1)            101         global_average_pooling1d_121[0][0
__________________________________________________________________________________________________
dense_396 (Dense)               (None, 1)            101         global_average_pooling1d_121[0][0
__________________________________________________________________________________________________
dense_397 (Dense)               (None, 1)            101         global_average_pooling1d_121[0][0
__________________________________________________________________________________________________
dense_398 (Dense)               (None, 1)            101         global_average_pooling1d_121[0][0
__________________________________________________________________________________________________
dense_399 (Dense)               (None, 1)            101         global_average_pooling1d_121[0][0
__________________________________________________________________________________________________
dense_400 (Dense)               (None, 1)            101         global_average_pooling1d_121[0][0
==================================================================================================
Total params: 454,710
Trainable params: 454,710
Non-trainable params: 0
__________________________________________________________________________________________________
None
stacking
Fold  2
multi-task
multi-task
Loading Data
Training Model
vocab size 4561, sequence length 45
Building FastText Model
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_122 (InputLayer)          (None, 45)           0                                            
__________________________________________________________________________________________________
embedding_122 (Embedding)       (None, 45, 100)      456100      input_122[0][0]                  
__________________________________________________________________________________________________
global_average_pooling1d_122 (G (None, 100)          0           embedding_122[0][0]              
__________________________________________________________________________________________________
dense_401 (Dense)               (None, 1)            101         global_average_pooling1d_122[0][0
__________________________________________________________________________________________________
dense_402 (Dense)               (None, 1)            101         global_average_pooling1d_122[0][0
__________________________________________________________________________________________________
dense_403 (Dense)               (None, 1)            101         global_average_pooling1d_122[0][0
__________________________________________________________________________________________________
dense_404 (Dense)               (None, 1)            101         global_average_pooling1d_122[0][0
__________________________________________________________________________________________________
dense_405 (Dense)               (None, 1)            101         global_average_pooling1d_122[0][0
__________________________________________________________________________________________________
dense_406 (Dense)               (None, 1)            101         global_average_pooling1d_122[0][0
__________________________________________________________________________________________________
dense_407 (Dense)               (None, 1)            101         global_average_pooling1d_122[0][0
__________________________________________________________________________________________________
dense_408 (Dense)               (None, 1)            101         global_average_pooling1d_122[0][0
__________________________________________________________________________________________________
dense_409 (Dense)               (None, 1)            101         global_average_pooling1d_122[0][0
__________________________________________________________________________________________________
dense_410 (Dense)               (None, 1)            101         global_average_pooling1d_122[0][0
==================================================================================================
Total params: 457,110
Trainable params: 457,110
Non-trainable params: 0
__________________________________________________________________________________________________
None
stacking
Fold  3
multi-task
multi-task
Loading Data
Training Model
vocab size 4569, sequence length 45
Building FastText Model
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_123 (InputLayer)          (None, 45)           0                                            
__________________________________________________________________________________________________
embedding_123 (Embedding)       (None, 45, 100)      456900      input_123[0][0]                  
__________________________________________________________________________________________________
global_average_pooling1d_123 (G (None, 100)          0           embedding_123[0][0]              
__________________________________________________________________________________________________
dense_411 (Dense)               (None, 1)            101         global_average_pooling1d_123[0][0
__________________________________________________________________________________________________
dense_412 (Dense)               (None, 1)            101         global_average_pooling1d_123[0][0
__________________________________________________________________________________________________
dense_413 (Dense)               (None, 1)            101         global_average_pooling1d_123[0][0
__________________________________________________________________________________________________
dense_414 (Dense)               (None, 1)            101         global_average_pooling1d_123[0][0
__________________________________________________________________________________________________
dense_415 (Dense)               (None, 1)            101         global_average_pooling1d_123[0][0
__________________________________________________________________________________________________
dense_416 (Dense)               (None, 1)            101         global_average_pooling1d_123[0][0
__________________________________________________________________________________________________
dense_417 (Dense)               (None, 1)            101         global_average_pooling1d_123[0][0
__________________________________________________________________________________________________
dense_418 (Dense)               (None, 1)            101         global_average_pooling1d_123[0][0
__________________________________________________________________________________________________
dense_419 (Dense)               (None, 1)            101         global_average_pooling1d_123[0][0
__________________________________________________________________________________________________
dense_420 (Dense)               (None, 1)            101         global_average_pooling1d_123[0][0
==================================================================================================
Total params: 457,910
Trainable params: 457,910
Non-trainable params: 0
__________________________________________________________________________________________________
None
stacking
Fold  4
multi-task
multi-task
Loading Data
Training Model
vocab size 4518, sequence length 45
Building FastText Model
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_124 (InputLayer)          (None, 45)           0                                            
__________________________________________________________________________________________________
embedding_124 (Embedding)       (None, 45, 100)      451800      input_124[0][0]                  
__________________________________________________________________________________________________
global_average_pooling1d_124 (G (None, 100)          0           embedding_124[0][0]              
__________________________________________________________________________________________________
dense_421 (Dense)               (None, 1)            101         global_average_pooling1d_124[0][0
__________________________________________________________________________________________________
dense_422 (Dense)               (None, 1)            101         global_average_pooling1d_124[0][0
__________________________________________________________________________________________________
dense_423 (Dense)               (None, 1)            101         global_average_pooling1d_124[0][0
__________________________________________________________________________________________________
dense_424 (Dense)               (None, 1)            101         global_average_pooling1d_124[0][0
__________________________________________________________________________________________________
dense_425 (Dense)               (None, 1)            101         global_average_pooling1d_124[0][0
__________________________________________________________________________________________________
dense_426 (Dense)               (None, 1)            101         global_average_pooling1d_124[0][0
__________________________________________________________________________________________________
dense_427 (Dense)               (None, 1)            101         global_average_pooling1d_124[0][0
__________________________________________________________________________________________________
dense_428 (Dense)               (None, 1)            101         global_average_pooling1d_124[0][0
__________________________________________________________________________________________________
dense_429 (Dense)               (None, 1)            101         global_average_pooling1d_124[0][0
__________________________________________________________________________________________________
dense_430 (Dense)               (None, 1)            101         global_average_pooling1d_124[0][0
==================================================================================================
Total params: 452,810
Trainable params: 452,810
Non-trainable params: 0
__________________________________________________________________________________________________
None
stacking
Fold  5
multi-task
multi-task
Loading Data
Training Model
vocab size 4426, sequence length 45
Building FastText Model
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_125 (InputLayer)          (None, 45)           0                                            
__________________________________________________________________________________________________
embedding_125 (Embedding)       (None, 45, 100)      442600      input_125[0][0]                  
__________________________________________________________________________________________________
global_average_pooling1d_125 (G (None, 100)          0           embedding_125[0][0]              
__________________________________________________________________________________________________
dense_431 (Dense)               (None, 1)            101         global_average_pooling1d_125[0][0
__________________________________________________________________________________________________
dense_432 (Dense)               (None, 1)            101         global_average_pooling1d_125[0][0
__________________________________________________________________________________________________
dense_433 (Dense)               (None, 1)            101         global_average_pooling1d_125[0][0
__________________________________________________________________________________________________
dense_434 (Dense)               (None, 1)            101         global_average_pooling1d_125[0][0
__________________________________________________________________________________________________
dense_435 (Dense)               (None, 1)            101         global_average_pooling1d_125[0][0
__________________________________________________________________________________________________
dense_436 (Dense)               (None, 1)            101         global_average_pooling1d_125[0][0
__________________________________________________________________________________________________
dense_437 (Dense)               (None, 1)            101         global_average_pooling1d_125[0][0
__________________________________________________________________________________________________
dense_438 (Dense)               (None, 1)            101         global_average_pooling1d_125[0][0
__________________________________________________________________________________________________
dense_439 (Dense)               (None, 1)            101         global_average_pooling1d_125[0][0
__________________________________________________________________________________________________
dense_440 (Dense)               (None, 1)            101         global_average_pooling1d_125[0][0
==================================================================================================
Total params: 443,610
Trainable params: 443,610
Non-trainable params: 0
__________________________________________________________________________________________________
None
stacking
time elapsed: 527.7112458709962
Fold  1
multi-task
multi-task
Loading Data
Training Model
vocab size 4537, sequence length 43
Building FastText Model
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_126 (InputLayer)          (None, 43)           0                                            
__________________________________________________________________________________________________
embedding_126 (Embedding)       (None, 43, 100)      453700      input_126[0][0]                  
__________________________________________________________________________________________________
global_average_pooling1d_126 (G (None, 100)          0           embedding_126[0][0]              
__________________________________________________________________________________________________
dense_441 (Dense)               (None, 1)            101         global_average_pooling1d_126[0][0
__________________________________________________________________________________________________
dense_442 (Dense)               (None, 1)            101         global_average_pooling1d_126[0][0
__________________________________________________________________________________________________
dense_443 (Dense)               (None, 1)            101         global_average_pooling1d_126[0][0
__________________________________________________________________________________________________
dense_444 (Dense)               (None, 1)            101         global_average_pooling1d_126[0][0
__________________________________________________________________________________________________
dense_445 (Dense)               (None, 1)            101         global_average_pooling1d_126[0][0
__________________________________________________________________________________________________
dense_446 (Dense)               (None, 1)            101         global_average_pooling1d_126[0][0
__________________________________________________________________________________________________
dense_447 (Dense)               (None, 1)            101         global_average_pooling1d_126[0][0
__________________________________________________________________________________________________
dense_448 (Dense)               (None, 1)            101         global_average_pooling1d_126[0][0
__________________________________________________________________________________________________
dense_449 (Dense)               (None, 1)            101         global_average_pooling1d_126[0][0
__________________________________________________________________________________________________
dense_450 (Dense)               (None, 1)            101         global_average_pooling1d_126[0][0
==================================================================================================
Total params: 454,710
Trainable params: 454,710
Non-trainable params: 0
__________________________________________________________________________________________________
None
stacking
Fold  2
multi-task
multi-task
Loading Data
Training Model
vocab size 4561, sequence length 45
Building FastText Model
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_127 (InputLayer)          (None, 45)           0                                            
__________________________________________________________________________________________________
embedding_127 (Embedding)       (None, 45, 100)      456100      input_127[0][0]                  
__________________________________________________________________________________________________
global_average_pooling1d_127 (G (None, 100)          0           embedding_127[0][0]              
__________________________________________________________________________________________________
dense_451 (Dense)               (None, 1)            101         global_average_pooling1d_127[0][0
__________________________________________________________________________________________________
dense_452 (Dense)               (None, 1)            101         global_average_pooling1d_127[0][0
__________________________________________________________________________________________________
dense_453 (Dense)               (None, 1)            101         global_average_pooling1d_127[0][0
__________________________________________________________________________________________________
dense_454 (Dense)               (None, 1)            101         global_average_pooling1d_127[0][0
__________________________________________________________________________________________________
dense_455 (Dense)               (None, 1)            101         global_average_pooling1d_127[0][0
__________________________________________________________________________________________________
dense_456 (Dense)               (None, 1)            101         global_average_pooling1d_127[0][0
__________________________________________________________________________________________________
dense_457 (Dense)               (None, 1)            101         global_average_pooling1d_127[0][0
__________________________________________________________________________________________________
dense_458 (Dense)               (None, 1)            101         global_average_pooling1d_127[0][0
__________________________________________________________________________________________________
dense_459 (Dense)               (None, 1)            101         global_average_pooling1d_127[0][0
__________________________________________________________________________________________________
dense_460 (Dense)               (None, 1)            101         global_average_pooling1d_127[0][0
==================================================================================================
Total params: 457,110
Trainable params: 457,110
Non-trainable params: 0
__________________________________________________________________________________________________
None
stacking
Fold  3
multi-task
multi-task
Loading Data
Training Model
vocab size 4569, sequence length 45
Building FastText Model
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_128 (InputLayer)          (None, 45)           0                                            
__________________________________________________________________________________________________
embedding_128 (Embedding)       (None, 45, 100)      456900      input_128[0][0]                  
__________________________________________________________________________________________________
global_average_pooling1d_128 (G (None, 100)          0           embedding_128[0][0]              
__________________________________________________________________________________________________
dense_461 (Dense)               (None, 1)            101         global_average_pooling1d_128[0][0
__________________________________________________________________________________________________
dense_462 (Dense)               (None, 1)            101         global_average_pooling1d_128[0][0
__________________________________________________________________________________________________
dense_463 (Dense)               (None, 1)            101         global_average_pooling1d_128[0][0
__________________________________________________________________________________________________
dense_464 (Dense)               (None, 1)            101         global_average_pooling1d_128[0][0
__________________________________________________________________________________________________
dense_465 (Dense)               (None, 1)            101         global_average_pooling1d_128[0][0
__________________________________________________________________________________________________
dense_466 (Dense)               (None, 1)            101         global_average_pooling1d_128[0][0
__________________________________________________________________________________________________
dense_467 (Dense)               (None, 1)            101         global_average_pooling1d_128[0][0
__________________________________________________________________________________________________
dense_468 (Dense)               (None, 1)            101         global_average_pooling1d_128[0][0
__________________________________________________________________________________________________
dense_469 (Dense)               (None, 1)            101         global_average_pooling1d_128[0][0
__________________________________________________________________________________________________
dense_470 (Dense)               (None, 1)            101         global_average_pooling1d_128[0][0
==================================================================================================
Total params: 457,910
Trainable params: 457,910
Non-trainable params: 0
__________________________________________________________________________________________________
None
stacking
Fold  4
multi-task
multi-task
Loading Data
Training Model
vocab size 4518, sequence length 45
Building FastText Model
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_129 (InputLayer)          (None, 45)           0                                            
__________________________________________________________________________________________________
embedding_129 (Embedding)       (None, 45, 100)      451800      input_129[0][0]                  
__________________________________________________________________________________________________
global_average_pooling1d_129 (G (None, 100)          0           embedding_129[0][0]              
__________________________________________________________________________________________________
dense_471 (Dense)               (None, 1)            101         global_average_pooling1d_129[0][0
__________________________________________________________________________________________________
dense_472 (Dense)               (None, 1)            101         global_average_pooling1d_129[0][0
__________________________________________________________________________________________________
dense_473 (Dense)               (None, 1)            101         global_average_pooling1d_129[0][0
__________________________________________________________________________________________________
dense_474 (Dense)               (None, 1)            101         global_average_pooling1d_129[0][0
__________________________________________________________________________________________________
dense_475 (Dense)               (None, 1)            101         global_average_pooling1d_129[0][0
__________________________________________________________________________________________________
dense_476 (Dense)               (None, 1)            101         global_average_pooling1d_129[0][0
__________________________________________________________________________________________________
dense_477 (Dense)               (None, 1)            101         global_average_pooling1d_129[0][0
__________________________________________________________________________________________________
dense_478 (Dense)               (None, 1)            101         global_average_pooling1d_129[0][0
__________________________________________________________________________________________________
dense_479 (Dense)               (None, 1)            101         global_average_pooling1d_129[0][0
__________________________________________________________________________________________________
dense_480 (Dense)               (None, 1)            101         global_average_pooling1d_129[0][0
==================================================================================================
Total params: 452,810
Trainable params: 452,810
Non-trainable params: 0
__________________________________________________________________________________________________
None
stacking
Fold  5
multi-task
multi-task
Loading Data
Training Model
vocab size 4426, sequence length 45
Building FastText Model
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_130 (InputLayer)          (None, 45)           0                                            
__________________________________________________________________________________________________
embedding_130 (Embedding)       (None, 45, 100)      442600      input_130[0][0]                  
__________________________________________________________________________________________________
global_average_pooling1d_130 (G (None, 100)          0           embedding_130[0][0]              
__________________________________________________________________________________________________
dense_481 (Dense)               (None, 1)            101         global_average_pooling1d_130[0][0
__________________________________________________________________________________________________
dense_482 (Dense)               (None, 1)            101         global_average_pooling1d_130[0][0
__________________________________________________________________________________________________
dense_483 (Dense)               (None, 1)            101         global_average_pooling1d_130[0][0
__________________________________________________________________________________________________
dense_484 (Dense)               (None, 1)            101         global_average_pooling1d_130[0][0
__________________________________________________________________________________________________
dense_485 (Dense)               (None, 1)            101         global_average_pooling1d_130[0][0
__________________________________________________________________________________________________
dense_486 (Dense)               (None, 1)            101         global_average_pooling1d_130[0][0
__________________________________________________________________________________________________
dense_487 (Dense)               (None, 1)            101         global_average_pooling1d_130[0][0
__________________________________________________________________________________________________
dense_488 (Dense)               (None, 1)            101         global_average_pooling1d_130[0][0
__________________________________________________________________________________________________
dense_489 (Dense)               (None, 1)            101         global_average_pooling1d_130[0][0
__________________________________________________________________________________________________
dense_490 (Dense)               (None, 1)            101         global_average_pooling1d_130[0][0
==================================================================================================
Total params: 443,610
Trainable params: 443,610
Non-trainable params: 0
__________________________________________________________________________________________________
None
stacking
time elapsed: 632.3486694439998
Fold  1
multi-task
multi-task
Loading Data
Training Model
vocab size 4537, sequence length 43
Building FastText Model
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_131 (InputLayer)          (None, 43)           0                                            
__________________________________________________________________________________________________
embedding_131 (Embedding)       (None, 43, 100)      453700      input_131[0][0]                  
__________________________________________________________________________________________________
global_average_pooling1d_131 (G (None, 100)          0           embedding_131[0][0]              
__________________________________________________________________________________________________
dense_491 (Dense)               (None, 1)            101         global_average_pooling1d_131[0][0
__________________________________________________________________________________________________
dense_492 (Dense)               (None, 1)            101         global_average_pooling1d_131[0][0
__________________________________________________________________________________________________
dense_493 (Dense)               (None, 1)            101         global_average_pooling1d_131[0][0
__________________________________________________________________________________________________
dense_494 (Dense)               (None, 1)            101         global_average_pooling1d_131[0][0
__________________________________________________________________________________________________
dense_495 (Dense)               (None, 1)            101         global_average_pooling1d_131[0][0
__________________________________________________________________________________________________
dense_496 (Dense)               (None, 1)            101         global_average_pooling1d_131[0][0
__________________________________________________________________________________________________
dense_497 (Dense)               (None, 1)            101         global_average_pooling1d_131[0][0
__________________________________________________________________________________________________
dense_498 (Dense)               (None, 1)            101         global_average_pooling1d_131[0][0
__________________________________________________________________________________________________
dense_499 (Dense)               (None, 1)            101         global_average_pooling1d_131[0][0
__________________________________________________________________________________________________
dense_500 (Dense)               (None, 1)            101         global_average_pooling1d_131[0][0
==================================================================================================
Total params: 454,710
Trainable params: 454,710
Non-trainable params: 0
__________________________________________________________________________________________________
None
stacking
Fold  2
multi-task
multi-task
Loading Data
Training Model
vocab size 4561, sequence length 45
Building FastText Model
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_132 (InputLayer)          (None, 45)           0                                            
__________________________________________________________________________________________________
embedding_132 (Embedding)       (None, 45, 100)      456100      input_132[0][0]                  
__________________________________________________________________________________________________
global_average_pooling1d_132 (G (None, 100)          0           embedding_132[0][0]              
__________________________________________________________________________________________________
dense_501 (Dense)               (None, 1)            101         global_average_pooling1d_132[0][0
__________________________________________________________________________________________________
dense_502 (Dense)               (None, 1)            101         global_average_pooling1d_132[0][0
__________________________________________________________________________________________________
dense_503 (Dense)               (None, 1)            101         global_average_pooling1d_132[0][0
__________________________________________________________________________________________________
dense_504 (Dense)               (None, 1)            101         global_average_pooling1d_132[0][0
__________________________________________________________________________________________________
dense_505 (Dense)               (None, 1)            101         global_average_pooling1d_132[0][0
__________________________________________________________________________________________________
dense_506 (Dense)               (None, 1)            101         global_average_pooling1d_132[0][0
__________________________________________________________________________________________________
dense_507 (Dense)               (None, 1)            101         global_average_pooling1d_132[0][0
__________________________________________________________________________________________________
dense_508 (Dense)               (None, 1)            101         global_average_pooling1d_132[0][0
__________________________________________________________________________________________________
dense_509 (Dense)               (None, 1)            101         global_average_pooling1d_132[0][0
__________________________________________________________________________________________________
dense_510 (Dense)               (None, 1)            101         global_average_pooling1d_132[0][0
==================================================================================================
Total params: 457,110
Trainable params: 457,110
Non-trainable params: 0
__________________________________________________________________________________________________
None
stacking
Fold  3
multi-task
multi-task
Loading Data
Training Model
vocab size 4569, sequence length 45
Building FastText Model
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_133 (InputLayer)          (None, 45)           0                                            
__________________________________________________________________________________________________
embedding_133 (Embedding)       (None, 45, 100)      456900      input_133[0][0]                  
__________________________________________________________________________________________________
global_average_pooling1d_133 (G (None, 100)          0           embedding_133[0][0]              
__________________________________________________________________________________________________
dense_511 (Dense)               (None, 1)            101         global_average_pooling1d_133[0][0
__________________________________________________________________________________________________
dense_512 (Dense)               (None, 1)            101         global_average_pooling1d_133[0][0
__________________________________________________________________________________________________
dense_513 (Dense)               (None, 1)            101         global_average_pooling1d_133[0][0
__________________________________________________________________________________________________
dense_514 (Dense)               (None, 1)            101         global_average_pooling1d_133[0][0
__________________________________________________________________________________________________
dense_515 (Dense)               (None, 1)            101         global_average_pooling1d_133[0][0
__________________________________________________________________________________________________
dense_516 (Dense)               (None, 1)            101         global_average_pooling1d_133[0][0
__________________________________________________________________________________________________
dense_517 (Dense)               (None, 1)            101         global_average_pooling1d_133[0][0
__________________________________________________________________________________________________
dense_518 (Dense)               (None, 1)            101         global_average_pooling1d_133[0][0
__________________________________________________________________________________________________
dense_519 (Dense)               (None, 1)            101         global_average_pooling1d_133[0][0
__________________________________________________________________________________________________
dense_520 (Dense)               (None, 1)            101         global_average_pooling1d_133[0][0
==================================================================================================
Total params: 457,910
Trainable params: 457,910
Non-trainable params: 0
__________________________________________________________________________________________________
None
stacking
Fold  4
multi-task
multi-task
Loading Data
Training Model
vocab size 4518, sequence length 45
Building FastText Model
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_134 (InputLayer)          (None, 45)           0                                            
__________________________________________________________________________________________________
embedding_134 (Embedding)       (None, 45, 100)      451800      input_134[0][0]                  
__________________________________________________________________________________________________
global_average_pooling1d_134 (G (None, 100)          0           embedding_134[0][0]              
__________________________________________________________________________________________________
dense_521 (Dense)               (None, 1)            101         global_average_pooling1d_134[0][0
__________________________________________________________________________________________________
dense_522 (Dense)               (None, 1)            101         global_average_pooling1d_134[0][0
__________________________________________________________________________________________________
dense_523 (Dense)               (None, 1)            101         global_average_pooling1d_134[0][0
__________________________________________________________________________________________________
dense_524 (Dense)               (None, 1)            101         global_average_pooling1d_134[0][0
__________________________________________________________________________________________________
dense_525 (Dense)               (None, 1)            101         global_average_pooling1d_134[0][0
__________________________________________________________________________________________________
dense_526 (Dense)               (None, 1)            101         global_average_pooling1d_134[0][0
__________________________________________________________________________________________________
dense_527 (Dense)               (None, 1)            101         global_average_pooling1d_134[0][0
__________________________________________________________________________________________________
dense_528 (Dense)               (None, 1)            101         global_average_pooling1d_134[0][0
__________________________________________________________________________________________________
dense_529 (Dense)               (None, 1)            101         global_average_pooling1d_134[0][0
__________________________________________________________________________________________________
dense_530 (Dense)               (None, 1)            101         global_average_pooling1d_134[0][0
==================================================================================================
Total params: 452,810
Trainable params: 452,810
Non-trainable params: 0
__________________________________________________________________________________________________
None
stacking
Fold  5
multi-task
multi-task
Loading Data
Training Model
vocab size 4426, sequence length 45
Building FastText Model
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_135 (InputLayer)          (None, 45)           0                                            
__________________________________________________________________________________________________
embedding_135 (Embedding)       (None, 45, 100)      442600      input_135[0][0]                  
__________________________________________________________________________________________________
global_average_pooling1d_135 (G (None, 100)          0           embedding_135[0][0]              
__________________________________________________________________________________________________
dense_531 (Dense)               (None, 1)            101         global_average_pooling1d_135[0][0
__________________________________________________________________________________________________
dense_532 (Dense)               (None, 1)            101         global_average_pooling1d_135[0][0
__________________________________________________________________________________________________
dense_533 (Dense)               (None, 1)            101         global_average_pooling1d_135[0][0
__________________________________________________________________________________________________
dense_534 (Dense)               (None, 1)            101         global_average_pooling1d_135[0][0
__________________________________________________________________________________________________
dense_535 (Dense)               (None, 1)            101         global_average_pooling1d_135[0][0
__________________________________________________________________________________________________
dense_536 (Dense)               (None, 1)            101         global_average_pooling1d_135[0][0
__________________________________________________________________________________________________
dense_537 (Dense)               (None, 1)            101         global_average_pooling1d_135[0][0
__________________________________________________________________________________________________
dense_538 (Dense)               (None, 1)            101         global_average_pooling1d_135[0][0
__________________________________________________________________________________________________
dense_539 (Dense)               (None, 1)            101         global_average_pooling1d_135[0][0
__________________________________________________________________________________________________
dense_540 (Dense)               (None, 1)            101         global_average_pooling1d_135[0][0
==================================================================================================
Total params: 443,610
Trainable params: 443,610
Non-trainable params: 0
__________________________________________________________________________________________________
None
stacking
time elapsed: 743.5301994879992


Epochs: 10
/home/dan/.local/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
/home/dan/.local/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.
  'precision', 'predicted', average, warn_for)

Hamming Loss:                 0.171

f1 scores 
 -----------
Agreement/disagreement:       0.000        13
Certainty:                    0.000        29
Contrariety:                  0.000       109
Hypotheticality:              0.000        48
Necessity:                    0.000        56
Prediction:                   0.000        88
Source of knowledge:          0.000        95
Tact/rudeness:                0.000        24
Uncertainty:                  0.000        83
Volition:                     0.000        13

Micro-f1 score:               0.000
Macro-f1 score:               0.000

Accuracy                      0.000
['FastText', 'Multi-task', 10, 0.0, 0.0, 0.0]


Epochs: 50

Hamming Loss:                 0.092

f1 scores 
 -----------
Agreement/disagreement:       0.090        13
Certainty:                    0.280        29
Contrariety:                  0.781       109
Hypotheticality:              0.609        48
Necessity:                    0.490        56
Prediction:                   0.764        88
Source of knowledge:          0.599        95
Tact/rudeness:                0.055        24
Uncertainty:                  0.781        83
Volition:                     0.137        13

Micro-f1 score:               0.649
Macro-f1 score:               0.459

Accuracy                      0.272
['FastText', 'Multi-task', 50, 0.45864286808346877, 0.6487056500221512, 0.27167938391974]


Epochs: 100

Hamming Loss:                 0.063

f1 scores 
 -----------
Agreement/disagreement:       0.697        13
Certainty:                    0.821        29
Contrariety:                  0.810       109
Hypotheticality:              0.739        48
Necessity:                    0.742        56
Prediction:                   0.845        88
Source of knowledge:          0.715        95
Tact/rudeness:                0.658        24
Uncertainty:                  0.872        83
Volition:                     0.706        13

Micro-f1 score:               0.789
Macro-f1 score:               0.761

Accuracy                      0.515
['FastText', 'Multi-task', 100, 0.7606136481196175, 0.7894057236272675, 0.5154320333474637]


Epochs: 150

Hamming Loss:                 0.062

f1 scores 
 -----------
Agreement/disagreement:       0.818        13
Certainty:                    0.836        29
Contrariety:                  0.801       109
Hypotheticality:              0.748        48
Necessity:                    0.747        56
Prediction:                   0.836        88
Source of knowledge:          0.726        95
Tact/rudeness:                0.773        24
Uncertainty:                  0.867        83
Volition:                     0.765        13

Micro-f1 score:               0.796
Macro-f1 score:               0.792

Accuracy                      0.536
['FastText', 'Multi-task', 150, 0.7916020315428857, 0.795851674532053, 0.53624063868871]


Epochs: 200

Hamming Loss:                 0.061

f1 scores 
 -----------
Agreement/disagreement:       0.824        13
Certainty:                    0.845        29
Contrariety:                  0.807       109
Hypotheticality:              0.756        48
Necessity:                    0.749        56
Prediction:                   0.838        88
Source of knowledge:          0.729        95
Tact/rudeness:                0.791        24
Uncertainty:                  0.868        83
Volition:                     0.765        13

Micro-f1 score:               0.800
Macro-f1 score:               0.797

Accuracy                      0.546
['FastText', 'Multi-task', 200, 0.7971648397936713, 0.8003244907037491, 0.546347322311714]


Epochs: 250

Hamming Loss:                 0.061

f1 scores 
 -----------
Agreement/disagreement:       0.826        13
Certainty:                    0.845        29
Contrariety:                  0.803       109
Hypotheticality:              0.755        48
Necessity:                    0.751        56
Prediction:                   0.841        88
Source of knowledge:          0.731        95
Tact/rudeness:                0.801        24
Uncertainty:                  0.871        83
Volition:                     0.765        13

Micro-f1 score:               0.801
Macro-f1 score:               0.799

Accuracy                      0.546
['FastText', 'Multi-task', 250, 0.7988310960123525, 0.801201382328958, 0.5457503179313268]


Epochs: 300

Hamming Loss:                 0.062

f1 scores 
 -----------
Agreement/disagreement:       0.813        13
Certainty:                    0.849        29
Contrariety:                  0.795       109
Hypotheticality:              0.759        48
Necessity:                    0.745        56
Prediction:                   0.841        88
Source of knowledge:          0.725        95
Tact/rudeness:                0.801        24
Uncertainty:                  0.870        83
Volition:                     0.777        13

Micro-f1 score:               0.798
Macro-f1 score:               0.797

Accuracy                      0.543
['FastText', 'Multi-task', 300, 0.7974592373777828, 0.7983966279561653, 0.5433799632612689]


Epochs: 350

Hamming Loss:                 0.063

f1 scores 
 -----------
Agreement/disagreement:       0.819        13
Certainty:                    0.861        29
Contrariety:                  0.794       109
Hypotheticality:              0.754        48
Necessity:                    0.742        56
Prediction:                   0.837        88
Source of knowledge:          0.727        95
Tact/rudeness:                0.801        24
Uncertainty:                  0.869        83
Volition:                     0.777        13

Micro-f1 score:               0.798
Macro-f1 score:               0.798

Accuracy                      0.545
['FastText', 'Multi-task', 350, 0.7980754401593477, 0.7978154082507116, 0.5445598417408506]


Epochs: 400

Hamming Loss:                 0.063

f1 scores 
 -----------
Agreement/disagreement:       0.819        13
Certainty:                    0.854        29
Contrariety:                  0.794       109
Hypotheticality:              0.754        48
Necessity:                    0.739        56
Prediction:                   0.842        88
Source of knowledge:          0.727        95
Tact/rudeness:                0.801        24
Uncertainty:                  0.868        83
Volition:                     0.777        13

Micro-f1 score:               0.798
Macro-f1 score:               0.797

Accuracy                      0.544
['FastText', 'Multi-task', 400, 0.7974574838970809, 0.7978745610290631, 0.5439663699307616]
Fold  1
0
multi-class
Loading Data
Training Model
Building Multilayer Perceptron
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_136 (InputLayer)       (None, 18886)             0         
_________________________________________________________________
dense_541 (Dense)            (None, 25)                472175    
_________________________________________________________________
dropout_1 (Dropout)          (None, 25)                0         
_________________________________________________________________
dense_542 (Dense)            (None, 25)                650       
_________________________________________________________________
dropout_2 (Dropout)          (None, 25)                0         
_________________________________________________________________
dense_543 (Dense)            (None, 637)               16562     
=================================================================
Total params: 489,387
Trainable params: 489,387
Non-trainable params: 0
_________________________________________________________________
None
Fold  2
0
multi-class
Loading Data
Training Model
Building Multilayer Perceptron
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_137 (InputLayer)       (None, 18908)             0         
_________________________________________________________________
dense_544 (Dense)            (None, 25)                472725    
_________________________________________________________________
dropout_3 (Dropout)          (None, 25)                0         
_________________________________________________________________
dense_545 (Dense)            (None, 25)                650       
_________________________________________________________________
dropout_4 (Dropout)          (None, 25)                0         
_________________________________________________________________
dense_546 (Dense)            (None, 637)               16562     
=================================================================
Total params: 489,937
Trainable params: 489,937
Non-trainable params: 0
_________________________________________________________________
None
Fold  3
0
multi-class
Loading Data
Training Model
Building Multilayer Perceptron
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_138 (InputLayer)       (None, 19048)             0         
_________________________________________________________________
dense_547 (Dense)            (None, 25)                476225    
_________________________________________________________________
dropout_5 (Dropout)          (None, 25)                0         
_________________________________________________________________
dense_548 (Dense)            (None, 25)                650       
_________________________________________________________________
dropout_6 (Dropout)          (None, 25)                0         
_________________________________________________________________
dense_549 (Dense)            (None, 637)               16562     
=================================================================
Total params: 493,437
Trainable params: 493,437
Non-trainable params: 0
_________________________________________________________________
None
Fold  4
0
multi-class
Loading Data
Training Model
Building Multilayer Perceptron
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_139 (InputLayer)       (None, 18673)             0         
_________________________________________________________________
dense_550 (Dense)            (None, 25)                466850    
_________________________________________________________________
dropout_7 (Dropout)          (None, 25)                0         
_________________________________________________________________
dense_551 (Dense)            (None, 25)                650       
_________________________________________________________________
dropout_8 (Dropout)          (None, 25)                0         
_________________________________________________________________
dense_552 (Dense)            (None, 637)               16562     
=================================================================
Total params: 484,062
Trainable params: 484,062
Non-trainable params: 0
_________________________________________________________________
None
Fold  5
0
multi-class
Loading Data
Training Model
Building Multilayer Perceptron
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_140 (InputLayer)       (None, 18390)             0         
_________________________________________________________________
dense_553 (Dense)            (None, 25)                459775    
_________________________________________________________________
dropout_9 (Dropout)          (None, 25)                0         
_________________________________________________________________
dense_554 (Dense)            (None, 25)                650       
_________________________________________________________________
dropout_10 (Dropout)         (None, 25)                0         
_________________________________________________________________
dense_555 (Dense)            (None, 637)               16562     
=================================================================
Total params: 476,987
Trainable params: 476,987
Non-trainable params: 0
_________________________________________________________________
None
time elapsed: 114.74981561899767
Fold  1
0
multi-class
Loading Data
Training Model
Building Multilayer Perceptron
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_141 (InputLayer)       (None, 18886)             0         
_________________________________________________________________
dense_556 (Dense)            (None, 25)                472175    
_________________________________________________________________
dropout_11 (Dropout)         (None, 25)                0         
_________________________________________________________________
dense_557 (Dense)            (None, 25)                650       
_________________________________________________________________
dropout_12 (Dropout)         (None, 25)                0         
_________________________________________________________________
dense_558 (Dense)            (None, 637)               16562     
=================================================================
Total params: 489,387
Trainable params: 489,387
Non-trainable params: 0
_________________________________________________________________
None
Fold  2
0
multi-class
Loading Data
Training Model
Building Multilayer Perceptron
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_142 (InputLayer)       (None, 18908)             0         
_________________________________________________________________
dense_559 (Dense)            (None, 25)                472725    
_________________________________________________________________
dropout_13 (Dropout)         (None, 25)                0         
_________________________________________________________________
dense_560 (Dense)            (None, 25)                650       
_________________________________________________________________
dropout_14 (Dropout)         (None, 25)                0         
_________________________________________________________________
dense_561 (Dense)            (None, 637)               16562     
=================================================================
Total params: 489,937
Trainable params: 489,937
Non-trainable params: 0
_________________________________________________________________
None
Fold  3
0
multi-class
Loading Data
Training Model
Building Multilayer Perceptron
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_143 (InputLayer)       (None, 19048)             0         
_________________________________________________________________
dense_562 (Dense)            (None, 25)                476225    
_________________________________________________________________
dropout_15 (Dropout)         (None, 25)                0         
_________________________________________________________________
dense_563 (Dense)            (None, 25)                650       
_________________________________________________________________
dropout_16 (Dropout)         (None, 25)                0         
_________________________________________________________________
dense_564 (Dense)            (None, 637)               16562     
=================================================================
Total params: 493,437
Trainable params: 493,437
Non-trainable params: 0
_________________________________________________________________
None
Fold  4
0
multi-class
Loading Data
Training Model
Building Multilayer Perceptron
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_144 (InputLayer)       (None, 18673)             0         
_________________________________________________________________
dense_565 (Dense)            (None, 25)                466850    
_________________________________________________________________
dropout_17 (Dropout)         (None, 25)                0         
_________________________________________________________________
dense_566 (Dense)            (None, 25)                650       
_________________________________________________________________
dropout_18 (Dropout)         (None, 25)                0         
_________________________________________________________________
dense_567 (Dense)            (None, 637)               16562     
=================================================================
Total params: 484,062
Trainable params: 484,062
Non-trainable params: 0
_________________________________________________________________
None
Fold  5
0
multi-class
Loading Data
Training Model
Building Multilayer Perceptron
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_145 (InputLayer)       (None, 18390)             0         
_________________________________________________________________
dense_568 (Dense)            (None, 25)                459775    
_________________________________________________________________
dropout_19 (Dropout)         (None, 25)                0         
_________________________________________________________________
dense_569 (Dense)            (None, 25)                650       
_________________________________________________________________
dropout_20 (Dropout)         (None, 25)                0         
_________________________________________________________________
dense_570 (Dense)            (None, 637)               16562     
=================================================================
Total params: 476,987
Trainable params: 476,987
Non-trainable params: 0
_________________________________________________________________
None
time elapsed: 239.4207884839998
Fold  1
0
multi-class
Loading Data
Training Model
Building Multilayer Perceptron
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_146 (InputLayer)       (None, 18886)             0         
_________________________________________________________________
dense_571 (Dense)            (None, 25)                472175    
_________________________________________________________________
dropout_21 (Dropout)         (None, 25)                0         
_________________________________________________________________
dense_572 (Dense)            (None, 25)                650       
_________________________________________________________________
dropout_22 (Dropout)         (None, 25)                0         
_________________________________________________________________
dense_573 (Dense)            (None, 637)               16562     
=================================================================
Total params: 489,387
Trainable params: 489,387
Non-trainable params: 0
_________________________________________________________________
None
Fold  2
0
multi-class
Loading Data
Training Model
Building Multilayer Perceptron
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_147 (InputLayer)       (None, 18908)             0         
_________________________________________________________________
dense_574 (Dense)            (None, 25)                472725    
_________________________________________________________________
dropout_23 (Dropout)         (None, 25)                0         
_________________________________________________________________
dense_575 (Dense)            (None, 25)                650       
_________________________________________________________________
dropout_24 (Dropout)         (None, 25)                0         
_________________________________________________________________
dense_576 (Dense)            (None, 637)               16562     
=================================================================
Total params: 489,937
Trainable params: 489,937
Non-trainable params: 0
_________________________________________________________________
None
Fold  3
0
multi-class
Loading Data
Training Model
Building Multilayer Perceptron
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_148 (InputLayer)       (None, 19048)             0         
_________________________________________________________________
dense_577 (Dense)            (None, 25)                476225    
_________________________________________________________________
dropout_25 (Dropout)         (None, 25)                0         
_________________________________________________________________
dense_578 (Dense)            (None, 25)                650       
_________________________________________________________________
dropout_26 (Dropout)         (None, 25)                0         
_________________________________________________________________
dense_579 (Dense)            (None, 637)               16562     
=================================================================
Total params: 493,437
Trainable params: 493,437
Non-trainable params: 0
_________________________________________________________________
None
Fold  4
0
multi-class
Loading Data
Training Model
Building Multilayer Perceptron
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_149 (InputLayer)       (None, 18673)             0         
_________________________________________________________________
dense_580 (Dense)            (None, 25)                466850    
_________________________________________________________________
dropout_27 (Dropout)         (None, 25)                0         
_________________________________________________________________
dense_581 (Dense)            (None, 25)                650       
_________________________________________________________________
dropout_28 (Dropout)         (None, 25)                0         
_________________________________________________________________
dense_582 (Dense)            (None, 637)               16562     
=================================================================
Total params: 484,062
Trainable params: 484,062
Non-trainable params: 0
_________________________________________________________________
None
Fold  5
0
multi-class
Loading Data
Training Model
Building Multilayer Perceptron
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_150 (InputLayer)       (None, 18390)             0         
_________________________________________________________________
dense_583 (Dense)            (None, 25)                459775    
_________________________________________________________________
dropout_29 (Dropout)         (None, 25)                0         
_________________________________________________________________
dense_584 (Dense)            (None, 25)                650       
_________________________________________________________________
dropout_30 (Dropout)         (None, 25)                0         
_________________________________________________________________
dense_585 (Dense)            (None, 637)               16562     
=================================================================
Total params: 476,987
Trainable params: 476,987
Non-trainable params: 0
_________________________________________________________________
None
time elapsed: 399.2336078169974
Fold  1
0
multi-class
Loading Data
Training Model
Building Multilayer Perceptron
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_151 (InputLayer)       (None, 18886)             0         
_________________________________________________________________
dense_586 (Dense)            (None, 25)                472175    
_________________________________________________________________
dropout_31 (Dropout)         (None, 25)                0         
_________________________________________________________________
dense_587 (Dense)            (None, 25)                650       
_________________________________________________________________
dropout_32 (Dropout)         (None, 25)                0         
_________________________________________________________________
dense_588 (Dense)            (None, 637)               16562     
=================================================================
Total params: 489,387
Trainable params: 489,387
Non-trainable params: 0
_________________________________________________________________
None
Fold  2
0
multi-class
Loading Data
Training Model
Building Multilayer Perceptron
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_152 (InputLayer)       (None, 18908)             0         
_________________________________________________________________
dense_589 (Dense)            (None, 25)                472725    
_________________________________________________________________
dropout_33 (Dropout)         (None, 25)                0         
_________________________________________________________________
dense_590 (Dense)            (None, 25)                650       
_________________________________________________________________
dropout_34 (Dropout)         (None, 25)                0         
_________________________________________________________________
dense_591 (Dense)            (None, 637)               16562     
=================================================================
Total params: 489,937
Trainable params: 489,937
Non-trainable params: 0
_________________________________________________________________
None
Fold  3
0
multi-class
Loading Data
Training Model
Building Multilayer Perceptron
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_153 (InputLayer)       (None, 19048)             0         
_________________________________________________________________
dense_592 (Dense)            (None, 25)                476225    
_________________________________________________________________
dropout_35 (Dropout)         (None, 25)                0         
_________________________________________________________________
dense_593 (Dense)            (None, 25)                650       
_________________________________________________________________
dropout_36 (Dropout)         (None, 25)                0         
_________________________________________________________________
dense_594 (Dense)            (None, 637)               16562     
=================================================================
Total params: 493,437
Trainable params: 493,437
Non-trainable params: 0
_________________________________________________________________
None
Fold  4
0
multi-class
Loading Data
Training Model
Building Multilayer Perceptron
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_154 (InputLayer)       (None, 18673)             0         
_________________________________________________________________
dense_595 (Dense)            (None, 25)                466850    
_________________________________________________________________
dropout_37 (Dropout)         (None, 25)                0         
_________________________________________________________________
dense_596 (Dense)            (None, 25)                650       
_________________________________________________________________
dropout_38 (Dropout)         (None, 25)                0         
_________________________________________________________________
dense_597 (Dense)            (None, 637)               16562     
=================================================================
Total params: 484,062
Trainable params: 484,062
Non-trainable params: 0
_________________________________________________________________
None
Fold  5
0
multi-class
Loading Data
Training Model
Building Multilayer Perceptron
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_155 (InputLayer)       (None, 18390)             0         
_________________________________________________________________
dense_598 (Dense)            (None, 25)                459775    
_________________________________________________________________
dropout_39 (Dropout)         (None, 25)                0         
_________________________________________________________________
dense_599 (Dense)            (None, 25)                650       
_________________________________________________________________
dropout_40 (Dropout)         (None, 25)                0         
_________________________________________________________________
dense_600 (Dense)            (None, 637)               16562     
=================================================================
Total params: 476,987
Trainable params: 476,987
Non-trainable params: 0
_________________________________________________________________
None
time elapsed: 560.0694794019946
Fold  1
0
multi-class
Loading Data
Training Model
Building Multilayer Perceptron
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_156 (InputLayer)       (None, 18886)             0         
_________________________________________________________________
dense_601 (Dense)            (None, 25)                472175    
_________________________________________________________________
dropout_41 (Dropout)         (None, 25)                0         
_________________________________________________________________
dense_602 (Dense)            (None, 25)                650       
_________________________________________________________________
dropout_42 (Dropout)         (None, 25)                0         
_________________________________________________________________
dense_603 (Dense)            (None, 637)               16562     
=================================================================
Total params: 489,387
Trainable params: 489,387
Non-trainable params: 0
_________________________________________________________________
None
Fold  2
0
multi-class
Loading Data
Training Model
Building Multilayer Perceptron
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_157 (InputLayer)       (None, 18908)             0         
_________________________________________________________________
dense_604 (Dense)            (None, 25)                472725    
_________________________________________________________________
dropout_43 (Dropout)         (None, 25)                0         
_________________________________________________________________
dense_605 (Dense)            (None, 25)                650       
_________________________________________________________________
dropout_44 (Dropout)         (None, 25)                0         
_________________________________________________________________
dense_606 (Dense)            (None, 637)               16562     
=================================================================
Total params: 489,937
Trainable params: 489,937
Non-trainable params: 0
_________________________________________________________________
None
Fold  3
0
multi-class
Loading Data
Training Model
Building Multilayer Perceptron
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_158 (InputLayer)       (None, 19048)             0         
_________________________________________________________________
dense_607 (Dense)            (None, 25)                476225    
_________________________________________________________________
dropout_45 (Dropout)         (None, 25)                0         
_________________________________________________________________
dense_608 (Dense)            (None, 25)                650       
_________________________________________________________________
dropout_46 (Dropout)         (None, 25)                0         
_________________________________________________________________
dense_609 (Dense)            (None, 637)               16562     
=================================================================
Total params: 493,437
Trainable params: 493,437
Non-trainable params: 0
_________________________________________________________________
None
Fold  4
0
multi-class
Loading Data
Training Model
Building Multilayer Perceptron
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_159 (InputLayer)       (None, 18673)             0         
_________________________________________________________________
dense_610 (Dense)            (None, 25)                466850    
_________________________________________________________________
dropout_47 (Dropout)         (None, 25)                0         
_________________________________________________________________
dense_611 (Dense)            (None, 25)                650       
_________________________________________________________________
dropout_48 (Dropout)         (None, 25)                0         
_________________________________________________________________
dense_612 (Dense)            (None, 637)               16562     
=================================================================
Total params: 484,062
Trainable params: 484,062
Non-trainable params: 0
_________________________________________________________________
None
Fold  5
0
multi-class
Loading Data
Training Model
Building Multilayer Perceptron
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_160 (InputLayer)       (None, 18390)             0         
_________________________________________________________________
dense_613 (Dense)            (None, 25)                459775    
_________________________________________________________________
dropout_49 (Dropout)         (None, 25)                0         
_________________________________________________________________
dense_614 (Dense)            (None, 25)                650       
_________________________________________________________________
dropout_50 (Dropout)         (None, 25)                0         
_________________________________________________________________
dense_615 (Dense)            (None, 637)               16562     
=================================================================
Total params: 476,987
Trainable params: 476,987
Non-trainable params: 0
_________________________________________________________________
None
time elapsed: 728.0367201620102
Fold  1
0
multi-class
Loading Data
Training Model
Building Multilayer Perceptron
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_161 (InputLayer)       (None, 18886)             0         
_________________________________________________________________
dense_616 (Dense)            (None, 25)                472175    
_________________________________________________________________
dropout_51 (Dropout)         (None, 25)                0         
_________________________________________________________________
dense_617 (Dense)            (None, 25)                650       
_________________________________________________________________
dropout_52 (Dropout)         (None, 25)                0         
_________________________________________________________________
dense_618 (Dense)            (None, 637)               16562     
=================================================================
Total params: 489,387
Trainable params: 489,387
Non-trainable params: 0
_________________________________________________________________
None
Fold  2
0
multi-class
Loading Data
Training Model
Building Multilayer Perceptron
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_162 (InputLayer)       (None, 18908)             0         
_________________________________________________________________
dense_619 (Dense)            (None, 25)                472725    
_________________________________________________________________
dropout_53 (Dropout)         (None, 25)                0         
_________________________________________________________________
dense_620 (Dense)            (None, 25)                650       
_________________________________________________________________
dropout_54 (Dropout)         (None, 25)                0         
_________________________________________________________________
dense_621 (Dense)            (None, 637)               16562     
=================================================================
Total params: 489,937
Trainable params: 489,937
Non-trainable params: 0
_________________________________________________________________
None
Fold  3
0
multi-class
Loading Data
Training Model
Building Multilayer Perceptron
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_163 (InputLayer)       (None, 19048)             0         
_________________________________________________________________
dense_622 (Dense)            (None, 25)                476225    
_________________________________________________________________
dropout_55 (Dropout)         (None, 25)                0         
_________________________________________________________________
dense_623 (Dense)            (None, 25)                650       
_________________________________________________________________
dropout_56 (Dropout)         (None, 25)                0         
_________________________________________________________________
dense_624 (Dense)            (None, 637)               16562     
=================================================================
Total params: 493,437
Trainable params: 493,437
Non-trainable params: 0
_________________________________________________________________
None
Fold  4
0
multi-class
Loading Data
Training Model
Building Multilayer Perceptron
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_164 (InputLayer)       (None, 18673)             0         
_________________________________________________________________
dense_625 (Dense)            (None, 25)                466850    
_________________________________________________________________
dropout_57 (Dropout)         (None, 25)                0         
_________________________________________________________________
dense_626 (Dense)            (None, 25)                650       
_________________________________________________________________
dropout_58 (Dropout)         (None, 25)                0         
_________________________________________________________________
dense_627 (Dense)            (None, 637)               16562     
=================================================================
Total params: 484,062
Trainable params: 484,062
Non-trainable params: 0
_________________________________________________________________
None
Fold  5
0
multi-class
Loading Data
Training Model
Building Multilayer Perceptron
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_165 (InputLayer)       (None, 18390)             0         
_________________________________________________________________
dense_628 (Dense)            (None, 25)                459775    
_________________________________________________________________
dropout_59 (Dropout)         (None, 25)                0         
_________________________________________________________________
dense_629 (Dense)            (None, 25)                650       
_________________________________________________________________
dropout_60 (Dropout)         (None, 25)                0         
_________________________________________________________________
dense_630 (Dense)            (None, 637)               16562     
=================================================================
Total params: 476,987
Trainable params: 476,987
Non-trainable params: 0
_________________________________________________________________
None
time elapsed: 896.5857174410048
Fold  1
0
multi-class
Loading Data
Training Model
Building Multilayer Perceptron
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_166 (InputLayer)       (None, 18886)             0         
_________________________________________________________________
dense_631 (Dense)            (None, 25)                472175    
_________________________________________________________________
dropout_61 (Dropout)         (None, 25)                0         
_________________________________________________________________
dense_632 (Dense)            (None, 25)                650       
_________________________________________________________________
dropout_62 (Dropout)         (None, 25)                0         
_________________________________________________________________
dense_633 (Dense)            (None, 637)               16562     
=================================================================
Total params: 489,387
Trainable params: 489,387
Non-trainable params: 0
_________________________________________________________________
None
Fold  2
0
multi-class
Loading Data
Training Model
Building Multilayer Perceptron
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_167 (InputLayer)       (None, 18908)             0         
_________________________________________________________________
dense_634 (Dense)            (None, 25)                472725    
_________________________________________________________________
dropout_63 (Dropout)         (None, 25)                0         
_________________________________________________________________
dense_635 (Dense)            (None, 25)                650       
_________________________________________________________________
dropout_64 (Dropout)         (None, 25)                0         
_________________________________________________________________
dense_636 (Dense)            (None, 637)               16562     
=================================================================
Total params: 489,937
Trainable params: 489,937
Non-trainable params: 0
_________________________________________________________________
None
Fold  3
0
multi-class
Loading Data
Training Model
Building Multilayer Perceptron
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_168 (InputLayer)       (None, 19048)             0         
_________________________________________________________________
dense_637 (Dense)            (None, 25)                476225    
_________________________________________________________________
dropout_65 (Dropout)         (None, 25)                0         
_________________________________________________________________
dense_638 (Dense)            (None, 25)                650       
_________________________________________________________________
dropout_66 (Dropout)         (None, 25)                0         
_________________________________________________________________
dense_639 (Dense)            (None, 637)               16562     
=================================================================
Total params: 493,437
Trainable params: 493,437
Non-trainable params: 0
_________________________________________________________________
None
Fold  4
0
multi-class
Loading Data
Training Model
Building Multilayer Perceptron
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_169 (InputLayer)       (None, 18673)             0         
_________________________________________________________________
dense_640 (Dense)            (None, 25)                466850    
_________________________________________________________________
dropout_67 (Dropout)         (None, 25)                0         
_________________________________________________________________
dense_641 (Dense)            (None, 25)                650       
_________________________________________________________________
dropout_68 (Dropout)         (None, 25)                0         
_________________________________________________________________
dense_642 (Dense)            (None, 637)               16562     
=================================================================
Total params: 484,062
Trainable params: 484,062
Non-trainable params: 0
_________________________________________________________________
None
Fold  5
0
multi-class
Loading Data
Training Model
Building Multilayer Perceptron
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_170 (InputLayer)       (None, 18390)             0         
_________________________________________________________________
dense_643 (Dense)            (None, 25)                459775    
_________________________________________________________________
dropout_69 (Dropout)         (None, 25)                0         
_________________________________________________________________
dense_644 (Dense)            (None, 25)                650       
_________________________________________________________________
dropout_70 (Dropout)         (None, 25)                0         
_________________________________________________________________
dense_645 (Dense)            (None, 637)               16562     
=================================================================
Total params: 476,987
Trainable params: 476,987
Non-trainable params: 0
_________________________________________________________________
None
time elapsed: 1058.3938227790059
Fold  1
0
multi-class
Loading Data
Training Model
Building Multilayer Perceptron
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_171 (InputLayer)       (None, 18886)             0         
_________________________________________________________________
dense_646 (Dense)            (None, 25)                472175    
_________________________________________________________________
dropout_71 (Dropout)         (None, 25)                0         
_________________________________________________________________
dense_647 (Dense)            (None, 25)                650       
_________________________________________________________________
dropout_72 (Dropout)         (None, 25)                0         
_________________________________________________________________
dense_648 (Dense)            (None, 637)               16562     
=================================================================
Total params: 489,387
Trainable params: 489,387
Non-trainable params: 0
_________________________________________________________________
None
Fold  2
0
multi-class
Loading Data
Training Model
Building Multilayer Perceptron
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_172 (InputLayer)       (None, 18908)             0         
_________________________________________________________________
dense_649 (Dense)            (None, 25)                472725    
_________________________________________________________________
dropout_73 (Dropout)         (None, 25)                0         
_________________________________________________________________
dense_650 (Dense)            (None, 25)                650       
_________________________________________________________________
dropout_74 (Dropout)         (None, 25)                0         
_________________________________________________________________
dense_651 (Dense)            (None, 637)               16562     
=================================================================
Total params: 489,937
Trainable params: 489,937
Non-trainable params: 0
_________________________________________________________________
None
Fold  3
0
multi-class
Loading Data
Training Model
Building Multilayer Perceptron
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_173 (InputLayer)       (None, 19048)             0         
_________________________________________________________________
dense_652 (Dense)            (None, 25)                476225    
_________________________________________________________________
dropout_75 (Dropout)         (None, 25)                0         
_________________________________________________________________
dense_653 (Dense)            (None, 25)                650       
_________________________________________________________________
dropout_76 (Dropout)         (None, 25)                0         
_________________________________________________________________
dense_654 (Dense)            (None, 637)               16562     
=================================================================
Total params: 493,437
Trainable params: 493,437
Non-trainable params: 0
_________________________________________________________________
None
Fold  4
0
multi-class
Loading Data
Training Model
Building Multilayer Perceptron
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_174 (InputLayer)       (None, 18673)             0         
_________________________________________________________________
dense_655 (Dense)            (None, 25)                466850    
_________________________________________________________________
dropout_77 (Dropout)         (None, 25)                0         
_________________________________________________________________
dense_656 (Dense)            (None, 25)                650       
_________________________________________________________________
dropout_78 (Dropout)         (None, 25)                0         
_________________________________________________________________
dense_657 (Dense)            (None, 637)               16562     
=================================================================
Total params: 484,062
Trainable params: 484,062
Non-trainable params: 0
_________________________________________________________________
None
Fold  5
0
multi-class
Loading Data
Training Model
Building Multilayer Perceptron
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_175 (InputLayer)       (None, 18390)             0         
_________________________________________________________________
dense_658 (Dense)            (None, 25)                459775    
_________________________________________________________________
dropout_79 (Dropout)         (None, 25)                0         
_________________________________________________________________
dense_659 (Dense)            (None, 25)                650       
_________________________________________________________________
dropout_80 (Dropout)         (None, 25)                0         
_________________________________________________________________
dense_660 (Dense)            (None, 637)               16562     
=================================================================
Total params: 476,987
Trainable params: 476,987
Non-trainable params: 0
_________________________________________________________________
None
time elapsed: 1229.5351955369988
Fold  1
0
multi-class
Loading Data
Training Model
Building Multilayer Perceptron
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_176 (InputLayer)       (None, 18886)             0         
_________________________________________________________________
dense_661 (Dense)            (None, 25)                472175    
_________________________________________________________________
dropout_81 (Dropout)         (None, 25)                0         
_________________________________________________________________
dense_662 (Dense)            (None, 25)                650       
_________________________________________________________________
dropout_82 (Dropout)         (None, 25)                0         
_________________________________________________________________
dense_663 (Dense)            (None, 637)               16562     
=================================================================
Total params: 489,387
Trainable params: 489,387
Non-trainable params: 0
_________________________________________________________________
None
Fold  2
0
multi-class
Loading Data
Training Model
Building Multilayer Perceptron
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_177 (InputLayer)       (None, 18908)             0         
_________________________________________________________________
dense_664 (Dense)            (None, 25)                472725    
_________________________________________________________________
dropout_83 (Dropout)         (None, 25)                0         
_________________________________________________________________
dense_665 (Dense)            (None, 25)                650       
_________________________________________________________________
dropout_84 (Dropout)         (None, 25)                0         
_________________________________________________________________
dense_666 (Dense)            (None, 637)               16562     
=================================================================
Total params: 489,937
Trainable params: 489,937
Non-trainable params: 0
_________________________________________________________________
None
Fold  3
0
multi-class
Loading Data
Training Model
Building Multilayer Perceptron
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_178 (InputLayer)       (None, 19048)             0         
_________________________________________________________________
dense_667 (Dense)            (None, 25)                476225    
_________________________________________________________________
dropout_85 (Dropout)         (None, 25)                0         
_________________________________________________________________
dense_668 (Dense)            (None, 25)                650       
_________________________________________________________________
dropout_86 (Dropout)         (None, 25)                0         
_________________________________________________________________
dense_669 (Dense)            (None, 637)               16562     
=================================================================
Total params: 493,437
Trainable params: 493,437
Non-trainable params: 0
_________________________________________________________________
None
Fold  4
0
multi-class
Loading Data
Training Model
Building Multilayer Perceptron
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_179 (InputLayer)       (None, 18673)             0         
_________________________________________________________________
dense_670 (Dense)            (None, 25)                466850    
_________________________________________________________________
dropout_87 (Dropout)         (None, 25)                0         
_________________________________________________________________
dense_671 (Dense)            (None, 25)                650       
_________________________________________________________________
dropout_88 (Dropout)         (None, 25)                0         
_________________________________________________________________
dense_672 (Dense)            (None, 637)               16562     
=================================================================
Total params: 484,062
Trainable params: 484,062
Non-trainable params: 0
_________________________________________________________________
None
Fold  5
0
multi-class
Loading Data
Training Model
Building Multilayer Perceptron
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_180 (InputLayer)       (None, 18390)             0         
_________________________________________________________________
dense_673 (Dense)            (None, 25)                459775    
_________________________________________________________________
dropout_89 (Dropout)         (None, 25)                0         
_________________________________________________________________
dense_674 (Dense)            (None, 25)                650       
_________________________________________________________________
dropout_90 (Dropout)         (None, 25)                0         
_________________________________________________________________
dense_675 (Dense)            (None, 637)               16562     
=================================================================
Total params: 476,987
Trainable params: 476,987
Non-trainable params: 0
_________________________________________________________________
None
time elapsed: 1414.5381737660064


Epochs: 10
/home/dan/.local/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
/home/dan/.local/lib/python3.6/site-packages/sklearn/metrics/classification.py:1137: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true samples.
  'recall', 'true', average, warn_for)

Hamming Loss:                 0.483


Micro-f1 score:               0.517
Macro-f1 score:               0.585

Accuracy                      0.517
['MLP', 'Multi-class', 10, 0.5846620908188291, 0.5166331072488342, 0.5166331072488342]


Epochs: 50

Hamming Loss:                 0.414


Micro-f1 score:               0.586
Macro-f1 score:               0.753

Accuracy                      0.586
['MLP', 'Multi-class', 50, 0.7532415217066001, 0.5861823512787904, 0.5861823512787904]


Epochs: 100

Hamming Loss:                 0.431


Micro-f1 score:               0.569
Macro-f1 score:               0.745

Accuracy                      0.569
['MLP', 'Multi-class', 100, 0.7449500176084394, 0.5689487070792708, 0.5689487070792708]


Epochs: 150

Hamming Loss:                 0.422


Micro-f1 score:               0.578
Macro-f1 score:               0.743

Accuracy                      0.578
['MLP', 'Multi-class', 150, 0.7425758926689393, 0.5784601526070368, 0.5784601526070368]


Epochs: 200

Hamming Loss:                 0.427


Micro-f1 score:               0.573
Macro-f1 score:               0.730

Accuracy                      0.573
['MLP', 'Multi-class', 200, 0.7298819441841247, 0.5731047760350431, 0.5731047760350431]


Epochs: 250

Hamming Loss:                 0.426


Micro-f1 score:               0.574
Macro-f1 score:               0.744

Accuracy                      0.574
['MLP', 'Multi-class', 250, 0.7438428807103978, 0.5737106118411756, 0.5737106118411756]


Epochs: 300

Hamming Loss:                 0.434


Micro-f1 score:               0.566
Macro-f1 score:               0.741

Accuracy                      0.566
['MLP', 'Multi-class', 300, 0.7410465975027846, 0.5659778154585277, 0.5659778154585277]


Epochs: 350

Hamming Loss:                 0.419


Micro-f1 score:               0.581
Macro-f1 score:               0.755

Accuracy                      0.581
['MLP', 'Multi-class', 350, 0.7550083314302622, 0.580835806132542, 0.580835806132542]


Epochs: 400

Hamming Loss:                 0.433


Micro-f1 score:               0.567
Macro-f1 score:               0.745

Accuracy                      0.567
['MLP', 'Multi-class', 400, 0.744819065155707, 0.5671771230747492, 0.5671771230747492]
Fold  1
0
multi-label
Loading Data
Training Model
Building Multilayer Perceptron
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_181 (InputLayer)       (None, 18886)             0         
_________________________________________________________________
dense_676 (Dense)            (None, 25)                472175    
_________________________________________________________________
dropout_91 (Dropout)         (None, 25)                0         
_________________________________________________________________
dense_677 (Dense)            (None, 25)                650       
_________________________________________________________________
dropout_92 (Dropout)         (None, 25)                0         
_________________________________________________________________
dense_678 (Dense)            (None, 10)                260       
=================================================================
Total params: 473,085
Trainable params: 473,085
Non-trainable params: 0
_________________________________________________________________
None
Fold  2
0
multi-label
Loading Data
Training Model
Building Multilayer Perceptron
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_182 (InputLayer)       (None, 18908)             0         
_________________________________________________________________
dense_679 (Dense)            (None, 25)                472725    
_________________________________________________________________
dropout_93 (Dropout)         (None, 25)                0         
_________________________________________________________________
dense_680 (Dense)            (None, 25)                650       
_________________________________________________________________
dropout_94 (Dropout)         (None, 25)                0         
_________________________________________________________________
dense_681 (Dense)            (None, 10)                260       
=================================================================
Total params: 473,635
Trainable params: 473,635
Non-trainable params: 0
_________________________________________________________________
None
Fold  3
0
multi-label
Loading Data
Training Model
Building Multilayer Perceptron
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_183 (InputLayer)       (None, 19048)             0         
_________________________________________________________________
dense_682 (Dense)            (None, 25)                476225    
_________________________________________________________________
dropout_95 (Dropout)         (None, 25)                0         
_________________________________________________________________
dense_683 (Dense)            (None, 25)                650       
_________________________________________________________________
dropout_96 (Dropout)         (None, 25)                0         
_________________________________________________________________
dense_684 (Dense)            (None, 10)                260       
=================================================================
Total params: 477,135
Trainable params: 477,135
Non-trainable params: 0
_________________________________________________________________
None
Fold  4
0
multi-label
Loading Data
Training Model
Building Multilayer Perceptron
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_184 (InputLayer)       (None, 18673)             0         
_________________________________________________________________
dense_685 (Dense)            (None, 25)                466850    
_________________________________________________________________
dropout_97 (Dropout)         (None, 25)                0         
_________________________________________________________________
dense_686 (Dense)            (None, 25)                650       
_________________________________________________________________
dropout_98 (Dropout)         (None, 25)                0         
_________________________________________________________________
dense_687 (Dense)            (None, 10)                260       
=================================================================
Total params: 467,760
Trainable params: 467,760
Non-trainable params: 0
_________________________________________________________________
None
Fold  5
0
multi-label
Loading Data
Training Model
Building Multilayer Perceptron
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_185 (InputLayer)       (None, 18390)             0         
_________________________________________________________________
dense_688 (Dense)            (None, 25)                459775    
_________________________________________________________________
dropout_99 (Dropout)         (None, 25)                0         
_________________________________________________________________
dense_689 (Dense)            (None, 25)                650       
_________________________________________________________________
dropout_100 (Dropout)        (None, 25)                0         
_________________________________________________________________
dense_690 (Dense)            (None, 10)                260       
=================================================================
Total params: 460,685
Trainable params: 460,685
Non-trainable params: 0
_________________________________________________________________
None
time elapsed: 130.20483322998916
Fold  1
0
multi-label
Loading Data
Training Model
Building Multilayer Perceptron
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_186 (InputLayer)       (None, 18886)             0         
_________________________________________________________________
dense_691 (Dense)            (None, 25)                472175    
_________________________________________________________________
dropout_101 (Dropout)        (None, 25)                0         
_________________________________________________________________
dense_692 (Dense)            (None, 25)                650       
_________________________________________________________________
dropout_102 (Dropout)        (None, 25)                0         
_________________________________________________________________
dense_693 (Dense)            (None, 10)                260       
=================================================================
Total params: 473,085
Trainable params: 473,085
Non-trainable params: 0
_________________________________________________________________
None
Fold  2
0
multi-label
Loading Data
Training Model
Building Multilayer Perceptron
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_187 (InputLayer)       (None, 18908)             0         
_________________________________________________________________
dense_694 (Dense)            (None, 25)                472725    
_________________________________________________________________
dropout_103 (Dropout)        (None, 25)                0         
_________________________________________________________________
dense_695 (Dense)            (None, 25)                650       
_________________________________________________________________
dropout_104 (Dropout)        (None, 25)                0         
_________________________________________________________________
dense_696 (Dense)            (None, 10)                260       
=================================================================
Total params: 473,635
Trainable params: 473,635
Non-trainable params: 0
_________________________________________________________________
None
Fold  3
0
multi-label
Loading Data
Training Model
Building Multilayer Perceptron
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_188 (InputLayer)       (None, 19048)             0         
_________________________________________________________________
dense_697 (Dense)            (None, 25)                476225    
_________________________________________________________________
dropout_105 (Dropout)        (None, 25)                0         
_________________________________________________________________
dense_698 (Dense)            (None, 25)                650       
_________________________________________________________________
dropout_106 (Dropout)        (None, 25)                0         
_________________________________________________________________
dense_699 (Dense)            (None, 10)                260       
=================================================================
Total params: 477,135
Trainable params: 477,135
Non-trainable params: 0
_________________________________________________________________
None
Fold  4
0
multi-label
Loading Data
Training Model
Building Multilayer Perceptron
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_189 (InputLayer)       (None, 18673)             0         
_________________________________________________________________
dense_700 (Dense)            (None, 25)                466850    
_________________________________________________________________
dropout_107 (Dropout)        (None, 25)                0         
_________________________________________________________________
dense_701 (Dense)            (None, 25)                650       
_________________________________________________________________
dropout_108 (Dropout)        (None, 25)                0         
_________________________________________________________________
dense_702 (Dense)            (None, 10)                260       
=================================================================
Total params: 467,760
Trainable params: 467,760
Non-trainable params: 0
_________________________________________________________________
None
Fold  5
0
multi-label
Loading Data
Training Model
Building Multilayer Perceptron
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_190 (InputLayer)       (None, 18390)             0         
_________________________________________________________________
dense_703 (Dense)            (None, 25)                459775    
_________________________________________________________________
dropout_109 (Dropout)        (None, 25)                0         
_________________________________________________________________
dense_704 (Dense)            (None, 25)                650       
_________________________________________________________________
dropout_110 (Dropout)        (None, 25)                0         
_________________________________________________________________
dense_705 (Dense)            (None, 10)                260       
=================================================================
Total params: 460,685
Trainable params: 460,685
Non-trainable params: 0
_________________________________________________________________
None
time elapsed: 257.9121646620042
Fold  1
0
multi-label
Loading Data
Training Model
Building Multilayer Perceptron
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_191 (InputLayer)       (None, 18886)             0         
_________________________________________________________________
dense_706 (Dense)            (None, 25)                472175    
_________________________________________________________________
dropout_111 (Dropout)        (None, 25)                0         
_________________________________________________________________
dense_707 (Dense)            (None, 25)                650       
_________________________________________________________________
dropout_112 (Dropout)        (None, 25)                0         
_________________________________________________________________
dense_708 (Dense)            (None, 10)                260       
=================================================================
Total params: 473,085
Trainable params: 473,085
Non-trainable params: 0
_________________________________________________________________
None
Fold  2
0
multi-label
Loading Data
Training Model
Building Multilayer Perceptron
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_192 (InputLayer)       (None, 18908)             0         
_________________________________________________________________
dense_709 (Dense)            (None, 25)                472725    
_________________________________________________________________
dropout_113 (Dropout)        (None, 25)                0         
_________________________________________________________________
dense_710 (Dense)            (None, 25)                650       
_________________________________________________________________
dropout_114 (Dropout)        (None, 25)                0         
_________________________________________________________________
dense_711 (Dense)            (None, 10)                260       
=================================================================
Total params: 473,635
Trainable params: 473,635
Non-trainable params: 0
_________________________________________________________________
None
Fold  3
0
multi-label
Loading Data
Training Model
Building Multilayer Perceptron
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_193 (InputLayer)       (None, 19048)             0         
_________________________________________________________________
dense_712 (Dense)            (None, 25)                476225    
_________________________________________________________________
dropout_115 (Dropout)        (None, 25)                0         
_________________________________________________________________
dense_713 (Dense)            (None, 25)                650       
_________________________________________________________________
dropout_116 (Dropout)        (None, 25)                0         
_________________________________________________________________
dense_714 (Dense)            (None, 10)                260       
=================================================================
Total params: 477,135
Trainable params: 477,135
Non-trainable params: 0
_________________________________________________________________
None
Fold  4
0
multi-label
Loading Data
Training Model
Building Multilayer Perceptron
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_194 (InputLayer)       (None, 18673)             0         
_________________________________________________________________
dense_715 (Dense)            (None, 25)                466850    
_________________________________________________________________
dropout_117 (Dropout)        (None, 25)                0         
_________________________________________________________________
dense_716 (Dense)            (None, 25)                650       
_________________________________________________________________
dropout_118 (Dropout)        (None, 25)                0         
_________________________________________________________________
dense_717 (Dense)            (None, 10)                260       
=================================================================
Total params: 467,760
Trainable params: 467,760
Non-trainable params: 0
_________________________________________________________________
None
Fold  5
0
multi-label
Loading Data
Training Model
Building Multilayer Perceptron
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_195 (InputLayer)       (None, 18390)             0         
_________________________________________________________________
dense_718 (Dense)            (None, 25)                459775    
_________________________________________________________________
dropout_119 (Dropout)        (None, 25)                0         
_________________________________________________________________
dense_719 (Dense)            (None, 25)                650       
_________________________________________________________________
dropout_120 (Dropout)        (None, 25)                0         
_________________________________________________________________
dense_720 (Dense)            (None, 10)                260       
=================================================================
Total params: 460,685
Trainable params: 460,685
Non-trainable params: 0
_________________________________________________________________
None
time elapsed: 421.4894369620015
Fold  1
0
multi-label
Loading Data
Training Model
Building Multilayer Perceptron
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_196 (InputLayer)       (None, 18886)             0         
_________________________________________________________________
dense_721 (Dense)            (None, 25)                472175    
_________________________________________________________________
dropout_121 (Dropout)        (None, 25)                0         
_________________________________________________________________
dense_722 (Dense)            (None, 25)                650       
_________________________________________________________________
dropout_122 (Dropout)        (None, 25)                0         
_________________________________________________________________
dense_723 (Dense)            (None, 10)                260       
=================================================================
Total params: 473,085
Trainable params: 473,085
Non-trainable params: 0
_________________________________________________________________
None
Fold  2
0
multi-label
Loading Data
Training Model
Building Multilayer Perceptron
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_197 (InputLayer)       (None, 18908)             0         
_________________________________________________________________
dense_724 (Dense)            (None, 25)                472725    
_________________________________________________________________
dropout_123 (Dropout)        (None, 25)                0         
_________________________________________________________________
dense_725 (Dense)            (None, 25)                650       
_________________________________________________________________
dropout_124 (Dropout)        (None, 25)                0         
_________________________________________________________________
dense_726 (Dense)            (None, 10)                260       
=================================================================
Total params: 473,635
Trainable params: 473,635
Non-trainable params: 0
_________________________________________________________________
None
Fold  3
0
multi-label
Loading Data
Training Model
Building Multilayer Perceptron
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_198 (InputLayer)       (None, 19048)             0         
_________________________________________________________________
dense_727 (Dense)            (None, 25)                476225    
_________________________________________________________________
dropout_125 (Dropout)        (None, 25)                0         
_________________________________________________________________
dense_728 (Dense)            (None, 25)                650       
_________________________________________________________________
dropout_126 (Dropout)        (None, 25)                0         
_________________________________________________________________
dense_729 (Dense)            (None, 10)                260       
=================================================================
Total params: 477,135
Trainable params: 477,135
Non-trainable params: 0
_________________________________________________________________
None
Fold  4
0
multi-label
Loading Data
Training Model
Building Multilayer Perceptron
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_199 (InputLayer)       (None, 18673)             0         
_________________________________________________________________
dense_730 (Dense)            (None, 25)                466850    
_________________________________________________________________
dropout_127 (Dropout)        (None, 25)                0         
_________________________________________________________________
dense_731 (Dense)            (None, 25)                650       
_________________________________________________________________
dropout_128 (Dropout)        (None, 25)                0         
_________________________________________________________________
dense_732 (Dense)            (None, 10)                260       
=================================================================
Total params: 467,760
Trainable params: 467,760
Non-trainable params: 0
_________________________________________________________________
None
Fold  5
0
multi-label
Loading Data
Training Model
Building Multilayer Perceptron
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_200 (InputLayer)       (None, 18390)             0         
_________________________________________________________________
dense_733 (Dense)            (None, 25)                459775    
_________________________________________________________________
dropout_129 (Dropout)        (None, 25)                0         
_________________________________________________________________
dense_734 (Dense)            (None, 25)                650       
_________________________________________________________________
dropout_130 (Dropout)        (None, 25)                0         
_________________________________________________________________
dense_735 (Dense)            (None, 10)                260       
=================================================================
Total params: 460,685
Trainable params: 460,685
Non-trainable params: 0
_________________________________________________________________
None
time elapsed: 583.3457361239998
Fold  1
0
multi-label
Loading Data
Training Model
Building Multilayer Perceptron
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_201 (InputLayer)       (None, 18886)             0         
_________________________________________________________________
dense_736 (Dense)            (None, 25)                472175    
_________________________________________________________________
dropout_131 (Dropout)        (None, 25)                0         
_________________________________________________________________
dense_737 (Dense)            (None, 25)                650       
_________________________________________________________________
dropout_132 (Dropout)        (None, 25)                0         
_________________________________________________________________
dense_738 (Dense)            (None, 10)                260       
=================================================================
Total params: 473,085
Trainable params: 473,085
Non-trainable params: 0
_________________________________________________________________
None
Fold  2
0
multi-label
Loading Data
Training Model
Building Multilayer Perceptron
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_202 (InputLayer)       (None, 18908)             0         
_________________________________________________________________
dense_739 (Dense)            (None, 25)                472725    
_________________________________________________________________
dropout_133 (Dropout)        (None, 25)                0         
_________________________________________________________________
dense_740 (Dense)            (None, 25)                650       
_________________________________________________________________
dropout_134 (Dropout)        (None, 25)                0         
_________________________________________________________________
dense_741 (Dense)            (None, 10)                260       
=================================================================
Total params: 473,635
Trainable params: 473,635
Non-trainable params: 0
_________________________________________________________________
None
Fold  3
0
multi-label
Loading Data
Training Model
Building Multilayer Perceptron
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_203 (InputLayer)       (None, 19048)             0         
_________________________________________________________________
dense_742 (Dense)            (None, 25)                476225    
_________________________________________________________________
dropout_135 (Dropout)        (None, 25)                0         
_________________________________________________________________
dense_743 (Dense)            (None, 25)                650       
_________________________________________________________________
dropout_136 (Dropout)        (None, 25)                0         
_________________________________________________________________
dense_744 (Dense)            (None, 10)                260       
=================================================================
Total params: 477,135
Trainable params: 477,135
Non-trainable params: 0
_________________________________________________________________
None
Fold  4
0
multi-label
Loading Data
Training Model
Building Multilayer Perceptron
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_204 (InputLayer)       (None, 18673)             0         
_________________________________________________________________
dense_745 (Dense)            (None, 25)                466850    
_________________________________________________________________
dropout_137 (Dropout)        (None, 25)                0         
_________________________________________________________________
dense_746 (Dense)            (None, 25)                650       
_________________________________________________________________
dropout_138 (Dropout)        (None, 25)                0         
_________________________________________________________________
dense_747 (Dense)            (None, 10)                260       
=================================================================
Total params: 467,760
Trainable params: 467,760
Non-trainable params: 0
_________________________________________________________________
None
Fold  5
0
multi-label
Loading Data
Training Model
Building Multilayer Perceptron
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_205 (InputLayer)       (None, 18390)             0         
_________________________________________________________________
dense_748 (Dense)            (None, 25)                459775    
_________________________________________________________________
dropout_139 (Dropout)        (None, 25)                0         
_________________________________________________________________
dense_749 (Dense)            (None, 25)                650       
_________________________________________________________________
dropout_140 (Dropout)        (None, 25)                0         
_________________________________________________________________
dense_750 (Dense)            (None, 10)                260       
=================================================================
Total params: 460,685
Trainable params: 460,685
Non-trainable params: 0
_________________________________________________________________
None
time elapsed: 754.6675921239948
Fold  1
0
multi-label
Loading Data
Training Model
Building Multilayer Perceptron
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_206 (InputLayer)       (None, 18886)             0         
_________________________________________________________________
dense_751 (Dense)            (None, 25)                472175    
_________________________________________________________________
dropout_141 (Dropout)        (None, 25)                0         
_________________________________________________________________
dense_752 (Dense)            (None, 25)                650       
_________________________________________________________________
dropout_142 (Dropout)        (None, 25)                0         
_________________________________________________________________
dense_753 (Dense)            (None, 10)                260       
=================================================================
Total params: 473,085
Trainable params: 473,085
Non-trainable params: 0
_________________________________________________________________
None
Fold  2
0
multi-label
Loading Data
Training Model
Building Multilayer Perceptron
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_207 (InputLayer)       (None, 18908)             0         
_________________________________________________________________
dense_754 (Dense)            (None, 25)                472725    
_________________________________________________________________
dropout_143 (Dropout)        (None, 25)                0         
_________________________________________________________________
dense_755 (Dense)            (None, 25)                650       
_________________________________________________________________
dropout_144 (Dropout)        (None, 25)                0         
_________________________________________________________________
dense_756 (Dense)            (None, 10)                260       
=================================================================
Total params: 473,635
Trainable params: 473,635
Non-trainable params: 0
_________________________________________________________________
None
Fold  3
0
multi-label
Loading Data
Training Model
Building Multilayer Perceptron
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_208 (InputLayer)       (None, 19048)             0         
_________________________________________________________________
dense_757 (Dense)            (None, 25)                476225    
_________________________________________________________________
dropout_145 (Dropout)        (None, 25)                0         
_________________________________________________________________
dense_758 (Dense)            (None, 25)                650       
_________________________________________________________________
dropout_146 (Dropout)        (None, 25)                0         
_________________________________________________________________
dense_759 (Dense)            (None, 10)                260       
=================================================================
Total params: 477,135
Trainable params: 477,135
Non-trainable params: 0
_________________________________________________________________
None
Fold  4
0
multi-label
Loading Data
Training Model
Building Multilayer Perceptron
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_209 (InputLayer)       (None, 18673)             0         
_________________________________________________________________
dense_760 (Dense)            (None, 25)                466850    
_________________________________________________________________
dropout_147 (Dropout)        (None, 25)                0         
_________________________________________________________________
dense_761 (Dense)            (None, 25)                650       
_________________________________________________________________
dropout_148 (Dropout)        (None, 25)                0         
_________________________________________________________________
dense_762 (Dense)            (None, 10)                260       
=================================================================
Total params: 467,760
Trainable params: 467,760
Non-trainable params: 0
_________________________________________________________________
None
Fold  5
0
multi-label
Loading Data
Training Model
Building Multilayer Perceptron
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_210 (InputLayer)       (None, 18390)             0         
_________________________________________________________________
dense_763 (Dense)            (None, 25)                459775    
_________________________________________________________________
dropout_149 (Dropout)        (None, 25)                0         
_________________________________________________________________
dense_764 (Dense)            (None, 25)                650       
_________________________________________________________________
dropout_150 (Dropout)        (None, 25)                0         
_________________________________________________________________
dense_765 (Dense)            (None, 10)                260       
=================================================================
Total params: 460,685
Trainable params: 460,685
Non-trainable params: 0
_________________________________________________________________
None
time elapsed: 921.5088662599883
Fold  1
0
multi-label
Loading Data
Training Model
Building Multilayer Perceptron
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_211 (InputLayer)       (None, 18886)             0         
_________________________________________________________________
dense_766 (Dense)            (None, 25)                472175    
_________________________________________________________________
dropout_151 (Dropout)        (None, 25)                0         
_________________________________________________________________
dense_767 (Dense)            (None, 25)                650       
_________________________________________________________________
dropout_152 (Dropout)        (None, 25)                0         
_________________________________________________________________
dense_768 (Dense)            (None, 10)                260       
=================================================================
Total params: 473,085
Trainable params: 473,085
Non-trainable params: 0
_________________________________________________________________
None
Fold  2
0
multi-label
Loading Data
Training Model
Building Multilayer Perceptron
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_212 (InputLayer)       (None, 18908)             0         
_________________________________________________________________
dense_769 (Dense)            (None, 25)                472725    
_________________________________________________________________
dropout_153 (Dropout)        (None, 25)                0         
_________________________________________________________________
dense_770 (Dense)            (None, 25)                650       
_________________________________________________________________
dropout_154 (Dropout)        (None, 25)                0         
_________________________________________________________________
dense_771 (Dense)            (None, 10)                260       
=================================================================
Total params: 473,635
Trainable params: 473,635
Non-trainable params: 0
_________________________________________________________________
None
Fold  3
0
multi-label
Loading Data
Training Model
Building Multilayer Perceptron
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_213 (InputLayer)       (None, 19048)             0         
_________________________________________________________________
dense_772 (Dense)            (None, 25)                476225    
_________________________________________________________________
dropout_155 (Dropout)        (None, 25)                0         
_________________________________________________________________
dense_773 (Dense)            (None, 25)                650       
_________________________________________________________________
dropout_156 (Dropout)        (None, 25)                0         
_________________________________________________________________
dense_774 (Dense)            (None, 10)                260       
=================================================================
Total params: 477,135
Trainable params: 477,135
Non-trainable params: 0
_________________________________________________________________
None
Fold  4
0
multi-label
Loading Data
Training Model
Building Multilayer Perceptron
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_214 (InputLayer)       (None, 18673)             0         
_________________________________________________________________
dense_775 (Dense)            (None, 25)                466850    
_________________________________________________________________
dropout_157 (Dropout)        (None, 25)                0         
_________________________________________________________________
dense_776 (Dense)            (None, 25)                650       
_________________________________________________________________
dropout_158 (Dropout)        (None, 25)                0         
_________________________________________________________________
dense_777 (Dense)            (None, 10)                260       
=================================================================
Total params: 467,760
Trainable params: 467,760
Non-trainable params: 0
_________________________________________________________________
None
Fold  5
0
multi-label
Loading Data
Training Model
Building Multilayer Perceptron
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_215 (InputLayer)       (None, 18390)             0         
_________________________________________________________________
dense_778 (Dense)            (None, 25)                459775    
_________________________________________________________________
dropout_159 (Dropout)        (None, 25)                0         
_________________________________________________________________
dense_779 (Dense)            (None, 25)                650       
_________________________________________________________________
dropout_160 (Dropout)        (None, 25)                0         
_________________________________________________________________
dense_780 (Dense)            (None, 10)                260       
=================================================================
Total params: 460,685
Trainable params: 460,685
Non-trainable params: 0
_________________________________________________________________
None
time elapsed: 1100.3766963560047
Fold  1
0
multi-label
Loading Data
Training Model
Building Multilayer Perceptron
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_216 (InputLayer)       (None, 18886)             0         
_________________________________________________________________
dense_781 (Dense)            (None, 25)                472175    
_________________________________________________________________
dropout_161 (Dropout)        (None, 25)                0         
_________________________________________________________________
dense_782 (Dense)            (None, 25)                650       
_________________________________________________________________
dropout_162 (Dropout)        (None, 25)                0         
_________________________________________________________________
dense_783 (Dense)            (None, 10)                260       
=================================================================
Total params: 473,085
Trainable params: 473,085
Non-trainable params: 0
_________________________________________________________________
None
Fold  2
0
multi-label
Loading Data
Training Model
Building Multilayer Perceptron
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_217 (InputLayer)       (None, 18908)             0         
_________________________________________________________________
dense_784 (Dense)            (None, 25)                472725    
_________________________________________________________________
dropout_163 (Dropout)        (None, 25)                0         
_________________________________________________________________
dense_785 (Dense)            (None, 25)                650       
_________________________________________________________________
dropout_164 (Dropout)        (None, 25)                0         
_________________________________________________________________
dense_786 (Dense)            (None, 10)                260       
=================================================================
Total params: 473,635
Trainable params: 473,635
Non-trainable params: 0
_________________________________________________________________
None
Fold  3
0
multi-label
Loading Data
Training Model
Building Multilayer Perceptron
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_218 (InputLayer)       (None, 19048)             0         
_________________________________________________________________
dense_787 (Dense)            (None, 25)                476225    
_________________________________________________________________
dropout_165 (Dropout)        (None, 25)                0         
_________________________________________________________________
dense_788 (Dense)            (None, 25)                650       
_________________________________________________________________
dropout_166 (Dropout)        (None, 25)                0         
_________________________________________________________________
dense_789 (Dense)            (None, 10)                260       
=================================================================
Total params: 477,135
Trainable params: 477,135
Non-trainable params: 0
_________________________________________________________________
None
Fold  4
0
multi-label
Loading Data
Training Model
Building Multilayer Perceptron
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_219 (InputLayer)       (None, 18673)             0         
_________________________________________________________________
dense_790 (Dense)            (None, 25)                466850    
_________________________________________________________________
dropout_167 (Dropout)        (None, 25)                0         
_________________________________________________________________
dense_791 (Dense)            (None, 25)                650       
_________________________________________________________________
dropout_168 (Dropout)        (None, 25)                0         
_________________________________________________________________
dense_792 (Dense)            (None, 10)                260       
=================================================================
Total params: 467,760
Trainable params: 467,760
Non-trainable params: 0
_________________________________________________________________
None
Fold  5
0
multi-label
Loading Data
Training Model
Building Multilayer Perceptron
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_220 (InputLayer)       (None, 18390)             0         
_________________________________________________________________
dense_793 (Dense)            (None, 25)                459775    
_________________________________________________________________
dropout_169 (Dropout)        (None, 25)                0         
_________________________________________________________________
dense_794 (Dense)            (None, 25)                650       
_________________________________________________________________
dropout_170 (Dropout)        (None, 25)                0         
_________________________________________________________________
dense_795 (Dense)            (None, 10)                260       
=================================================================
Total params: 460,685
Trainable params: 460,685
Non-trainable params: 0
_________________________________________________________________
None
time elapsed: 1293.6147992960032
Fold  1
0
multi-label
Loading Data
Training Model
Building Multilayer Perceptron
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_221 (InputLayer)       (None, 18886)             0         
_________________________________________________________________
dense_796 (Dense)            (None, 25)                472175    
_________________________________________________________________
dropout_171 (Dropout)        (None, 25)                0         
_________________________________________________________________
dense_797 (Dense)            (None, 25)                650       
_________________________________________________________________
dropout_172 (Dropout)        (None, 25)                0         
_________________________________________________________________
dense_798 (Dense)            (None, 10)                260       
=================================================================
Total params: 473,085
Trainable params: 473,085
Non-trainable params: 0
_________________________________________________________________
None
Fold  2
0
multi-label
Loading Data
Training Model
Building Multilayer Perceptron
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_222 (InputLayer)       (None, 18908)             0         
_________________________________________________________________
dense_799 (Dense)            (None, 25)                472725    
_________________________________________________________________
dropout_173 (Dropout)        (None, 25)                0         
_________________________________________________________________
dense_800 (Dense)            (None, 25)                650       
_________________________________________________________________
dropout_174 (Dropout)        (None, 25)                0         
_________________________________________________________________
dense_801 (Dense)            (None, 10)                260       
=================================================================
Total params: 473,635
Trainable params: 473,635
Non-trainable params: 0
_________________________________________________________________
None
Fold  3
0
multi-label
Loading Data
Training Model
Building Multilayer Perceptron
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_223 (InputLayer)       (None, 19048)             0         
_________________________________________________________________
dense_802 (Dense)            (None, 25)                476225    
_________________________________________________________________
dropout_175 (Dropout)        (None, 25)                0         
_________________________________________________________________
dense_803 (Dense)            (None, 25)                650       
_________________________________________________________________
dropout_176 (Dropout)        (None, 25)                0         
_________________________________________________________________
dense_804 (Dense)            (None, 10)                260       
=================================================================
Total params: 477,135
Trainable params: 477,135
Non-trainable params: 0
_________________________________________________________________
None
Fold  4
0
multi-label
Loading Data
Training Model
Building Multilayer Perceptron
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_224 (InputLayer)       (None, 18673)             0         
_________________________________________________________________
dense_805 (Dense)            (None, 25)                466850    
_________________________________________________________________
dropout_177 (Dropout)        (None, 25)                0         
_________________________________________________________________
dense_806 (Dense)            (None, 25)                650       
_________________________________________________________________
dropout_178 (Dropout)        (None, 25)                0         
_________________________________________________________________
dense_807 (Dense)            (None, 10)                260       
=================================================================
Total params: 467,760
Trainable params: 467,760
Non-trainable params: 0
_________________________________________________________________
None
Fold  5
0
multi-label
Loading Data
Training Model
Building Multilayer Perceptron
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_225 (InputLayer)       (None, 18390)             0         
_________________________________________________________________
dense_808 (Dense)            (None, 25)                459775    
_________________________________________________________________
dropout_179 (Dropout)        (None, 25)                0         
_________________________________________________________________
dense_809 (Dense)            (None, 25)                650       
_________________________________________________________________
dropout_180 (Dropout)        (None, 25)                0         
_________________________________________________________________
dense_810 (Dense)            (None, 10)                260       
=================================================================
Total params: 460,685
Trainable params: 460,685
Non-trainable params: 0
_________________________________________________________________
None
time elapsed: 1456.5933372049913


Epochs: 10
/home/dan/.local/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)

Hamming Loss:                 0.130

f1 scores 
 -----------
Agreement/disagreement:       0.102        13
Certainty:                    0.197        29
Contrariety:                  0.529       109
Hypotheticality:              0.315        48
Necessity:                    0.317        56
Prediction:                   0.609        88
Source of knowledge:          0.481        95
Tact/rudeness:                0.000        24
Uncertainty:                  0.657        83
Volition:                     0.067        13

Micro-f1 score:               0.481
Macro-f1 score:               0.327

Accuracy                      0.170
['MLP', 'Multi-label', 10, 0.3271046657848136, 0.4811596032410506, 0.1700597004380387]


Epochs: 50

Hamming Loss:                 0.119

f1 scores 
 -----------
Agreement/disagreement:       0.154        13
Certainty:                    0.296        29
Contrariety:                  0.622       109
Hypotheticality:              0.420        48
Necessity:                    0.414        56
Prediction:                   0.662        88
Source of knowledge:          0.617        95
Tact/rudeness:                0.192        24
Uncertainty:                  0.687        83
Volition:                     0.166        13

Micro-f1 score:               0.564
Macro-f1 score:               0.423

Accuracy                      0.305
['MLP', 'Multi-label', 50, 0.42304289620519875, 0.5644210278170751, 0.3049685601243465]


Epochs: 100

Hamming Loss:                 0.117

f1 scores 
 -----------
Agreement/disagreement:       0.177        13
Certainty:                    0.348        29
Contrariety:                  0.623       109
Hypotheticality:              0.473        48
Necessity:                    0.450        56
Prediction:                   0.706        88
Source of knowledge:          0.616        95
Tact/rudeness:                0.193        24
Uncertainty:                  0.725        83
Volition:                     0.228        13

Micro-f1 score:               0.588
Macro-f1 score:               0.454

Accuracy                      0.321
['MLP', 'Multi-label', 100, 0.45383975318474323, 0.5883010909273789, 0.3210594178324149]


Epochs: 150

Hamming Loss:                 0.108

f1 scores 
 -----------
Agreement/disagreement:       0.261        13
Certainty:                    0.469        29
Contrariety:                  0.657       109
Hypotheticality:              0.449        48
Necessity:                    0.509        56
Prediction:                   0.730        88
Source of knowledge:          0.632        95
Tact/rudeness:                0.429        24
Uncertainty:                  0.750        83
Volition:                     0.218        13

Micro-f1 score:               0.621
Macro-f1 score:               0.510

Accuracy                      0.348
['MLP', 'Multi-label', 150, 0.5103914722834724, 0.6208262743758276, 0.3483803165182987]


Epochs: 200

Hamming Loss:                 0.118

f1 scores 
 -----------
Agreement/disagreement:       0.292        13
Certainty:                    0.427        29
Contrariety:                  0.628       109
Hypotheticality:              0.510        48
Necessity:                    0.471        56
Prediction:                   0.675        88
Source of knowledge:          0.660        95
Tact/rudeness:                0.355        24
Uncertainty:                  0.699        83
Volition:                     0.272        13

Micro-f1 score:               0.599
Macro-f1 score:               0.499

Accuracy                      0.320
['MLP', 'Multi-label', 200, 0.49888576179000116, 0.5993070764696106, 0.3198936696340257]


Epochs: 250

Hamming Loss:                 0.122

f1 scores 
 -----------
Agreement/disagreement:       0.373        13
Certainty:                    0.434        29
Contrariety:                  0.601       109
Hypotheticality:              0.518        48
Necessity:                    0.499        56
Prediction:                   0.682        88
Source of knowledge:          0.561        95
Tact/rudeness:                0.426        24
Uncertainty:                  0.717        83
Volition:                     0.275        13

Micro-f1 score:               0.583
Macro-f1 score:               0.509

Accuracy                      0.329
['MLP', 'Multi-label', 250, 0.5086018671290471, 0.5827978334173033, 0.3293521266073195]


Epochs: 300

Hamming Loss:                 0.117

f1 scores 
 -----------
Agreement/disagreement:       0.414        13
Certainty:                    0.512        29
Contrariety:                  0.614       109
Hypotheticality:              0.508        48
Necessity:                    0.541        56
Prediction:                   0.701        88
Source of knowledge:          0.648        95
Tact/rudeness:                0.474        24
Uncertainty:                  0.731        83
Volition:                     0.425        13

Micro-f1 score:               0.619
Macro-f1 score:               0.557

Accuracy                      0.372
['MLP', 'Multi-label', 300, 0.5565779698030795, 0.6187256233158221, 0.3721562809099901]


Epochs: 350

Hamming Loss:                 0.117

f1 scores 
 -----------
Agreement/disagreement:       0.427        13
Certainty:                    0.534        29
Contrariety:                  0.630       109
Hypotheticality:              0.519        48
Necessity:                    0.538        56
Prediction:                   0.704        88
Source of knowledge:          0.655        95
Tact/rudeness:                0.416        24
Uncertainty:                  0.727        83
Volition:                     0.486        13

Micro-f1 score:               0.619
Macro-f1 score:               0.564

Accuracy                      0.359
['MLP', 'Multi-label', 350, 0.5636607131705522, 0.6193457645071818, 0.3590946022325845]


Epochs: 400

Hamming Loss:                 0.118

f1 scores 
 -----------
Agreement/disagreement:       0.374        13
Certainty:                    0.502        29
Contrariety:                  0.663       109
Hypotheticality:              0.496        48
Necessity:                    0.504        56
Prediction:                   0.718        88
Source of knowledge:          0.639        95
Tact/rudeness:                0.367        24
Uncertainty:                  0.749        83
Volition:                     0.354        13

Micro-f1 score:               0.618
Macro-f1 score:               0.537

Accuracy                      0.365
['MLP', 'Multi-label', 400, 0.536587982798631, 0.6178139111390408, 0.36499576091564223]
Fold  1
0
multi-task
Loading Data
Training Model
Building Multilayer Perceptron
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_226 (InputLayer)          (None, 18886)        0                                            
__________________________________________________________________________________________________
dense_811 (Dense)               (None, 25)           472175      input_226[0][0]                  
__________________________________________________________________________________________________
dropout_181 (Dropout)           (None, 25)           0           dense_811[0][0]                  
__________________________________________________________________________________________________
dense_812 (Dense)               (None, 25)           650         dropout_181[0][0]                
__________________________________________________________________________________________________
dropout_182 (Dropout)           (None, 25)           0           dense_812[0][0]                  
__________________________________________________________________________________________________
dense_813 (Dense)               (None, 1)            26          dropout_182[0][0]                
__________________________________________________________________________________________________
dense_814 (Dense)               (None, 1)            26          dropout_182[0][0]                
__________________________________________________________________________________________________
dense_815 (Dense)               (None, 1)            26          dropout_182[0][0]                
__________________________________________________________________________________________________
dense_816 (Dense)               (None, 1)            26          dropout_182[0][0]                
__________________________________________________________________________________________________
dense_817 (Dense)               (None, 1)            26          dropout_182[0][0]                
__________________________________________________________________________________________________
dense_818 (Dense)               (None, 1)            26          dropout_182[0][0]                
__________________________________________________________________________________________________
dense_819 (Dense)               (None, 1)            26          dropout_182[0][0]                
__________________________________________________________________________________________________
dense_820 (Dense)               (None, 1)            26          dropout_182[0][0]                
__________________________________________________________________________________________________
dense_821 (Dense)               (None, 1)            26          dropout_182[0][0]                
__________________________________________________________________________________________________
dense_822 (Dense)               (None, 1)            26          dropout_182[0][0]                
==================================================================================================
Total params: 473,085
Trainable params: 473,085
Non-trainable params: 0
__________________________________________________________________________________________________
None
stacking
Fold  2
0
multi-task
Loading Data
Training Model
Building Multilayer Perceptron
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_227 (InputLayer)          (None, 18908)        0                                            
__________________________________________________________________________________________________
dense_823 (Dense)               (None, 25)           472725      input_227[0][0]                  
__________________________________________________________________________________________________
dropout_183 (Dropout)           (None, 25)           0           dense_823[0][0]                  
__________________________________________________________________________________________________
dense_824 (Dense)               (None, 25)           650         dropout_183[0][0]                
__________________________________________________________________________________________________
dropout_184 (Dropout)           (None, 25)           0           dense_824[0][0]                  
__________________________________________________________________________________________________
dense_825 (Dense)               (None, 1)            26          dropout_184[0][0]                
__________________________________________________________________________________________________
dense_826 (Dense)               (None, 1)            26          dropout_184[0][0]                
__________________________________________________________________________________________________
dense_827 (Dense)               (None, 1)            26          dropout_184[0][0]                
__________________________________________________________________________________________________
dense_828 (Dense)               (None, 1)            26          dropout_184[0][0]                
__________________________________________________________________________________________________
dense_829 (Dense)               (None, 1)            26          dropout_184[0][0]                
__________________________________________________________________________________________________
dense_830 (Dense)               (None, 1)            26          dropout_184[0][0]                
__________________________________________________________________________________________________
dense_831 (Dense)               (None, 1)            26          dropout_184[0][0]                
__________________________________________________________________________________________________
dense_832 (Dense)               (None, 1)            26          dropout_184[0][0]                
__________________________________________________________________________________________________
dense_833 (Dense)               (None, 1)            26          dropout_184[0][0]                
__________________________________________________________________________________________________
dense_834 (Dense)               (None, 1)            26          dropout_184[0][0]                
==================================================================================================
Total params: 473,635
Trainable params: 473,635
Non-trainable params: 0
__________________________________________________________________________________________________
None
stacking
Fold  3
0
multi-task
Loading Data
Training Model
Building Multilayer Perceptron
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_228 (InputLayer)          (None, 19048)        0                                            
__________________________________________________________________________________________________
dense_835 (Dense)               (None, 25)           476225      input_228[0][0]                  
__________________________________________________________________________________________________
dropout_185 (Dropout)           (None, 25)           0           dense_835[0][0]                  
__________________________________________________________________________________________________
dense_836 (Dense)               (None, 25)           650         dropout_185[0][0]                
__________________________________________________________________________________________________
dropout_186 (Dropout)           (None, 25)           0           dense_836[0][0]                  
__________________________________________________________________________________________________
dense_837 (Dense)               (None, 1)            26          dropout_186[0][0]                
__________________________________________________________________________________________________
dense_838 (Dense)               (None, 1)            26          dropout_186[0][0]                
__________________________________________________________________________________________________
dense_839 (Dense)               (None, 1)            26          dropout_186[0][0]                
__________________________________________________________________________________________________
dense_840 (Dense)               (None, 1)            26          dropout_186[0][0]                
__________________________________________________________________________________________________
dense_841 (Dense)               (None, 1)            26          dropout_186[0][0]                
__________________________________________________________________________________________________
dense_842 (Dense)               (None, 1)            26          dropout_186[0][0]                
__________________________________________________________________________________________________
dense_843 (Dense)               (None, 1)            26          dropout_186[0][0]                
__________________________________________________________________________________________________
dense_844 (Dense)               (None, 1)            26          dropout_186[0][0]                
__________________________________________________________________________________________________
dense_845 (Dense)               (None, 1)            26          dropout_186[0][0]                
__________________________________________________________________________________________________
dense_846 (Dense)               (None, 1)            26          dropout_186[0][0]                
==================================================================================================
Total params: 477,135
Trainable params: 477,135
Non-trainable params: 0
__________________________________________________________________________________________________
None
stacking
Fold  4
0
multi-task
Loading Data
Training Model
Building Multilayer Perceptron
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_229 (InputLayer)          (None, 18673)        0                                            
__________________________________________________________________________________________________
dense_847 (Dense)               (None, 25)           466850      input_229[0][0]                  
__________________________________________________________________________________________________
dropout_187 (Dropout)           (None, 25)           0           dense_847[0][0]                  
__________________________________________________________________________________________________
dense_848 (Dense)               (None, 25)           650         dropout_187[0][0]                
__________________________________________________________________________________________________
dropout_188 (Dropout)           (None, 25)           0           dense_848[0][0]                  
__________________________________________________________________________________________________
dense_849 (Dense)               (None, 1)            26          dropout_188[0][0]                
__________________________________________________________________________________________________
dense_850 (Dense)               (None, 1)            26          dropout_188[0][0]                
__________________________________________________________________________________________________
dense_851 (Dense)               (None, 1)            26          dropout_188[0][0]                
__________________________________________________________________________________________________
dense_852 (Dense)               (None, 1)            26          dropout_188[0][0]                
__________________________________________________________________________________________________
dense_853 (Dense)               (None, 1)            26          dropout_188[0][0]                
__________________________________________________________________________________________________
dense_854 (Dense)               (None, 1)            26          dropout_188[0][0]                
__________________________________________________________________________________________________
dense_855 (Dense)               (None, 1)            26          dropout_188[0][0]                
__________________________________________________________________________________________________
dense_856 (Dense)               (None, 1)            26          dropout_188[0][0]                
__________________________________________________________________________________________________
dense_857 (Dense)               (None, 1)            26          dropout_188[0][0]                
__________________________________________________________________________________________________
dense_858 (Dense)               (None, 1)            26          dropout_188[0][0]                
==================================================================================================
Total params: 467,760
Trainable params: 467,760
Non-trainable params: 0
__________________________________________________________________________________________________
None
stacking
Fold  5
0
multi-task
Loading Data
Training Model
Building Multilayer Perceptron
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_230 (InputLayer)          (None, 18390)        0                                            
__________________________________________________________________________________________________
dense_859 (Dense)               (None, 25)           459775      input_230[0][0]                  
__________________________________________________________________________________________________
dropout_189 (Dropout)           (None, 25)           0           dense_859[0][0]                  
__________________________________________________________________________________________________
dense_860 (Dense)               (None, 25)           650         dropout_189[0][0]                
__________________________________________________________________________________________________
dropout_190 (Dropout)           (None, 25)           0           dense_860[0][0]                  
__________________________________________________________________________________________________
dense_861 (Dense)               (None, 1)            26          dropout_190[0][0]                
__________________________________________________________________________________________________
dense_862 (Dense)               (None, 1)            26          dropout_190[0][0]                
__________________________________________________________________________________________________
dense_863 (Dense)               (None, 1)            26          dropout_190[0][0]                
__________________________________________________________________________________________________
dense_864 (Dense)               (None, 1)            26          dropout_190[0][0]                
__________________________________________________________________________________________________
dense_865 (Dense)               (None, 1)            26          dropout_190[0][0]                
__________________________________________________________________________________________________
dense_866 (Dense)               (None, 1)            26          dropout_190[0][0]                
__________________________________________________________________________________________________
dense_867 (Dense)               (None, 1)            26          dropout_190[0][0]                
__________________________________________________________________________________________________
dense_868 (Dense)               (None, 1)            26          dropout_190[0][0]                
__________________________________________________________________________________________________
dense_869 (Dense)               (None, 1)            26          dropout_190[0][0]                
__________________________________________________________________________________________________
dense_870 (Dense)               (None, 1)            26          dropout_190[0][0]                
==================================================================================================
Total params: 460,685
Trainable params: 460,685
Non-trainable params: 0
__________________________________________________________________________________________________
None
stacking
time elapsed: 171.28804322700307
Fold  1
0
multi-task
Loading Data
Training Model
Building Multilayer Perceptron
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_231 (InputLayer)          (None, 18886)        0                                            
__________________________________________________________________________________________________
dense_871 (Dense)               (None, 25)           472175      input_231[0][0]                  
__________________________________________________________________________________________________
dropout_191 (Dropout)           (None, 25)           0           dense_871[0][0]                  
__________________________________________________________________________________________________
dense_872 (Dense)               (None, 25)           650         dropout_191[0][0]                
__________________________________________________________________________________________________
dropout_192 (Dropout)           (None, 25)           0           dense_872[0][0]                  
__________________________________________________________________________________________________
dense_873 (Dense)               (None, 1)            26          dropout_192[0][0]                
__________________________________________________________________________________________________
dense_874 (Dense)               (None, 1)            26          dropout_192[0][0]                
__________________________________________________________________________________________________
dense_875 (Dense)               (None, 1)            26          dropout_192[0][0]                
__________________________________________________________________________________________________
dense_876 (Dense)               (None, 1)            26          dropout_192[0][0]                
__________________________________________________________________________________________________
dense_877 (Dense)               (None, 1)            26          dropout_192[0][0]                
__________________________________________________________________________________________________
dense_878 (Dense)               (None, 1)            26          dropout_192[0][0]                
__________________________________________________________________________________________________
dense_879 (Dense)               (None, 1)            26          dropout_192[0][0]                
__________________________________________________________________________________________________
dense_880 (Dense)               (None, 1)            26          dropout_192[0][0]                
__________________________________________________________________________________________________
dense_881 (Dense)               (None, 1)            26          dropout_192[0][0]                
__________________________________________________________________________________________________
dense_882 (Dense)               (None, 1)            26          dropout_192[0][0]                
==================================================================================================
Total params: 473,085
Trainable params: 473,085
Non-trainable params: 0
__________________________________________________________________________________________________
None
stacking
Fold  2
0
multi-task
Loading Data
Training Model
Building Multilayer Perceptron
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_232 (InputLayer)          (None, 18908)        0                                            
__________________________________________________________________________________________________
dense_883 (Dense)               (None, 25)           472725      input_232[0][0]                  
__________________________________________________________________________________________________
dropout_193 (Dropout)           (None, 25)           0           dense_883[0][0]                  
__________________________________________________________________________________________________
dense_884 (Dense)               (None, 25)           650         dropout_193[0][0]                
__________________________________________________________________________________________________
dropout_194 (Dropout)           (None, 25)           0           dense_884[0][0]                  
__________________________________________________________________________________________________
dense_885 (Dense)               (None, 1)            26          dropout_194[0][0]                
__________________________________________________________________________________________________
dense_886 (Dense)               (None, 1)            26          dropout_194[0][0]                
__________________________________________________________________________________________________
dense_887 (Dense)               (None, 1)            26          dropout_194[0][0]                
__________________________________________________________________________________________________
dense_888 (Dense)               (None, 1)            26          dropout_194[0][0]                
__________________________________________________________________________________________________
dense_889 (Dense)               (None, 1)            26          dropout_194[0][0]                
__________________________________________________________________________________________________
dense_890 (Dense)               (None, 1)            26          dropout_194[0][0]                
__________________________________________________________________________________________________
dense_891 (Dense)               (None, 1)            26          dropout_194[0][0]                
__________________________________________________________________________________________________
dense_892 (Dense)               (None, 1)            26          dropout_194[0][0]                
__________________________________________________________________________________________________
dense_893 (Dense)               (None, 1)            26          dropout_194[0][0]                
__________________________________________________________________________________________________
dense_894 (Dense)               (None, 1)            26          dropout_194[0][0]                
==================================================================================================
Total params: 473,635
Trainable params: 473,635
Non-trainable params: 0
__________________________________________________________________________________________________
None
stacking
Fold  3
0
multi-task
Loading Data
Training Model
Building Multilayer Perceptron
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_233 (InputLayer)          (None, 19048)        0                                            
__________________________________________________________________________________________________
dense_895 (Dense)               (None, 25)           476225      input_233[0][0]                  
__________________________________________________________________________________________________
dropout_195 (Dropout)           (None, 25)           0           dense_895[0][0]                  
__________________________________________________________________________________________________
dense_896 (Dense)               (None, 25)           650         dropout_195[0][0]                
__________________________________________________________________________________________________
dropout_196 (Dropout)           (None, 25)           0           dense_896[0][0]                  
__________________________________________________________________________________________________
dense_897 (Dense)               (None, 1)            26          dropout_196[0][0]                
__________________________________________________________________________________________________
dense_898 (Dense)               (None, 1)            26          dropout_196[0][0]                
__________________________________________________________________________________________________
dense_899 (Dense)               (None, 1)            26          dropout_196[0][0]                
__________________________________________________________________________________________________
dense_900 (Dense)               (None, 1)            26          dropout_196[0][0]                
__________________________________________________________________________________________________
dense_901 (Dense)               (None, 1)            26          dropout_196[0][0]                
__________________________________________________________________________________________________
dense_902 (Dense)               (None, 1)            26          dropout_196[0][0]                
__________________________________________________________________________________________________
dense_903 (Dense)               (None, 1)            26          dropout_196[0][0]                
__________________________________________________________________________________________________
dense_904 (Dense)               (None, 1)            26          dropout_196[0][0]                
__________________________________________________________________________________________________
dense_905 (Dense)               (None, 1)            26          dropout_196[0][0]                
__________________________________________________________________________________________________
dense_906 (Dense)               (None, 1)            26          dropout_196[0][0]                
==================================================================================================
Total params: 477,135
Trainable params: 477,135
Non-trainable params: 0
__________________________________________________________________________________________________
None
stacking
Fold  4
0
multi-task
Loading Data
Training Model
Building Multilayer Perceptron
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_234 (InputLayer)          (None, 18673)        0                                            
__________________________________________________________________________________________________
dense_907 (Dense)               (None, 25)           466850      input_234[0][0]                  
__________________________________________________________________________________________________
dropout_197 (Dropout)           (None, 25)           0           dense_907[0][0]                  
__________________________________________________________________________________________________
dense_908 (Dense)               (None, 25)           650         dropout_197[0][0]                
__________________________________________________________________________________________________
dropout_198 (Dropout)           (None, 25)           0           dense_908[0][0]                  
__________________________________________________________________________________________________
dense_909 (Dense)               (None, 1)            26          dropout_198[0][0]                
__________________________________________________________________________________________________
dense_910 (Dense)               (None, 1)            26          dropout_198[0][0]                
__________________________________________________________________________________________________
dense_911 (Dense)               (None, 1)            26          dropout_198[0][0]                
__________________________________________________________________________________________________
dense_912 (Dense)               (None, 1)            26          dropout_198[0][0]                
__________________________________________________________________________________________________
dense_913 (Dense)               (None, 1)            26          dropout_198[0][0]                
__________________________________________________________________________________________________
dense_914 (Dense)               (None, 1)            26          dropout_198[0][0]                
__________________________________________________________________________________________________
dense_915 (Dense)               (None, 1)            26          dropout_198[0][0]                
__________________________________________________________________________________________________
dense_916 (Dense)               (None, 1)            26          dropout_198[0][0]                
__________________________________________________________________________________________________
dense_917 (Dense)               (None, 1)            26          dropout_198[0][0]                
__________________________________________________________________________________________________
dense_918 (Dense)               (None, 1)            26          dropout_198[0][0]                
==================================================================================================
Total params: 467,760
Trainable params: 467,760
Non-trainable params: 0
__________________________________________________________________________________________________
None
stacking
Fold  5
0
multi-task
Loading Data
Training Model
Building Multilayer Perceptron
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_235 (InputLayer)          (None, 18390)        0                                            
__________________________________________________________________________________________________
dense_919 (Dense)               (None, 25)           459775      input_235[0][0]                  
__________________________________________________________________________________________________
dropout_199 (Dropout)           (None, 25)           0           dense_919[0][0]                  
__________________________________________________________________________________________________
dense_920 (Dense)               (None, 25)           650         dropout_199[0][0]                
__________________________________________________________________________________________________
dropout_200 (Dropout)           (None, 25)           0           dense_920[0][0]                  
__________________________________________________________________________________________________
dense_921 (Dense)               (None, 1)            26          dropout_200[0][0]                
__________________________________________________________________________________________________
dense_922 (Dense)               (None, 1)            26          dropout_200[0][0]                
__________________________________________________________________________________________________
dense_923 (Dense)               (None, 1)            26          dropout_200[0][0]                
__________________________________________________________________________________________________
dense_924 (Dense)               (None, 1)            26          dropout_200[0][0]                
__________________________________________________________________________________________________
dense_925 (Dense)               (None, 1)            26          dropout_200[0][0]                
__________________________________________________________________________________________________
dense_926 (Dense)               (None, 1)            26          dropout_200[0][0]                
__________________________________________________________________________________________________
dense_927 (Dense)               (None, 1)            26          dropout_200[0][0]                
__________________________________________________________________________________________________
dense_928 (Dense)               (None, 1)            26          dropout_200[0][0]                
__________________________________________________________________________________________________
dense_929 (Dense)               (None, 1)            26          dropout_200[0][0]                
__________________________________________________________________________________________________
dense_930 (Dense)               (None, 1)            26          dropout_200[0][0]                
==================================================================================================
Total params: 460,685
Trainable params: 460,685
Non-trainable params: 0
__________________________________________________________________________________________________
None
stacking
time elapsed: 335.38262751398725
Fold  1
0
multi-task
Loading Data
Training Model
Building Multilayer Perceptron
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_236 (InputLayer)          (None, 18886)        0                                            
__________________________________________________________________________________________________
dense_931 (Dense)               (None, 25)           472175      input_236[0][0]                  
__________________________________________________________________________________________________
dropout_201 (Dropout)           (None, 25)           0           dense_931[0][0]                  
__________________________________________________________________________________________________
dense_932 (Dense)               (None, 25)           650         dropout_201[0][0]                
__________________________________________________________________________________________________
dropout_202 (Dropout)           (None, 25)           0           dense_932[0][0]                  
__________________________________________________________________________________________________
dense_933 (Dense)               (None, 1)            26          dropout_202[0][0]                
__________________________________________________________________________________________________
dense_934 (Dense)               (None, 1)            26          dropout_202[0][0]                
__________________________________________________________________________________________________
dense_935 (Dense)               (None, 1)            26          dropout_202[0][0]                
__________________________________________________________________________________________________
dense_936 (Dense)               (None, 1)            26          dropout_202[0][0]                
__________________________________________________________________________________________________
dense_937 (Dense)               (None, 1)            26          dropout_202[0][0]                
__________________________________________________________________________________________________
dense_938 (Dense)               (None, 1)            26          dropout_202[0][0]                
__________________________________________________________________________________________________
dense_939 (Dense)               (None, 1)            26          dropout_202[0][0]                
__________________________________________________________________________________________________
dense_940 (Dense)               (None, 1)            26          dropout_202[0][0]                
__________________________________________________________________________________________________
dense_941 (Dense)               (None, 1)            26          dropout_202[0][0]                
__________________________________________________________________________________________________
dense_942 (Dense)               (None, 1)            26          dropout_202[0][0]                
==================================================================================================
Total params: 473,085
Trainable params: 473,085
Non-trainable params: 0
__________________________________________________________________________________________________
None
stacking
Fold  2
0
multi-task
Loading Data
Training Model
Building Multilayer Perceptron
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_237 (InputLayer)          (None, 18908)        0                                            
__________________________________________________________________________________________________
dense_943 (Dense)               (None, 25)           472725      input_237[0][0]                  
__________________________________________________________________________________________________
dropout_203 (Dropout)           (None, 25)           0           dense_943[0][0]                  
__________________________________________________________________________________________________
dense_944 (Dense)               (None, 25)           650         dropout_203[0][0]                
__________________________________________________________________________________________________
dropout_204 (Dropout)           (None, 25)           0           dense_944[0][0]                  
__________________________________________________________________________________________________
dense_945 (Dense)               (None, 1)            26          dropout_204[0][0]                
__________________________________________________________________________________________________
dense_946 (Dense)               (None, 1)            26          dropout_204[0][0]                
__________________________________________________________________________________________________
dense_947 (Dense)               (None, 1)            26          dropout_204[0][0]                
__________________________________________________________________________________________________
dense_948 (Dense)               (None, 1)            26          dropout_204[0][0]                
__________________________________________________________________________________________________
dense_949 (Dense)               (None, 1)            26          dropout_204[0][0]                
__________________________________________________________________________________________________
dense_950 (Dense)               (None, 1)            26          dropout_204[0][0]                
__________________________________________________________________________________________________
dense_951 (Dense)               (None, 1)            26          dropout_204[0][0]                
__________________________________________________________________________________________________
dense_952 (Dense)               (None, 1)            26          dropout_204[0][0]                
__________________________________________________________________________________________________
dense_953 (Dense)               (None, 1)            26          dropout_204[0][0]                
__________________________________________________________________________________________________
dense_954 (Dense)               (None, 1)            26          dropout_204[0][0]                
==================================================================================================
Total params: 473,635
Trainable params: 473,635
Non-trainable params: 0
__________________________________________________________________________________________________
None
stacking
Fold  3
0
multi-task
Loading Data
Training Model
Building Multilayer Perceptron
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_238 (InputLayer)          (None, 19048)        0                                            
__________________________________________________________________________________________________
dense_955 (Dense)               (None, 25)           476225      input_238[0][0]                  
__________________________________________________________________________________________________
dropout_205 (Dropout)           (None, 25)           0           dense_955[0][0]                  
__________________________________________________________________________________________________
dense_956 (Dense)               (None, 25)           650         dropout_205[0][0]                
__________________________________________________________________________________________________
dropout_206 (Dropout)           (None, 25)           0           dense_956[0][0]                  
__________________________________________________________________________________________________
dense_957 (Dense)               (None, 1)            26          dropout_206[0][0]                
__________________________________________________________________________________________________
dense_958 (Dense)               (None, 1)            26          dropout_206[0][0]                
__________________________________________________________________________________________________
dense_959 (Dense)               (None, 1)            26          dropout_206[0][0]                
__________________________________________________________________________________________________
dense_960 (Dense)               (None, 1)            26          dropout_206[0][0]                
__________________________________________________________________________________________________
dense_961 (Dense)               (None, 1)            26          dropout_206[0][0]                
__________________________________________________________________________________________________
dense_962 (Dense)               (None, 1)            26          dropout_206[0][0]                
__________________________________________________________________________________________________
dense_963 (Dense)               (None, 1)            26          dropout_206[0][0]                
__________________________________________________________________________________________________
dense_964 (Dense)               (None, 1)            26          dropout_206[0][0]                
__________________________________________________________________________________________________
dense_965 (Dense)               (None, 1)            26          dropout_206[0][0]                
__________________________________________________________________________________________________
dense_966 (Dense)               (None, 1)            26          dropout_206[0][0]                
==================================================================================================
Total params: 477,135
Trainable params: 477,135
Non-trainable params: 0
__________________________________________________________________________________________________
None
stacking
Fold  4
0
multi-task
Loading Data
Training Model
Building Multilayer Perceptron
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_239 (InputLayer)          (None, 18673)        0                                            
__________________________________________________________________________________________________
dense_967 (Dense)               (None, 25)           466850      input_239[0][0]                  
__________________________________________________________________________________________________
dropout_207 (Dropout)           (None, 25)           0           dense_967[0][0]                  
__________________________________________________________________________________________________
dense_968 (Dense)               (None, 25)           650         dropout_207[0][0]                
__________________________________________________________________________________________________
dropout_208 (Dropout)           (None, 25)           0           dense_968[0][0]                  
__________________________________________________________________________________________________
dense_969 (Dense)               (None, 1)            26          dropout_208[0][0]                
__________________________________________________________________________________________________
dense_970 (Dense)               (None, 1)            26          dropout_208[0][0]                
__________________________________________________________________________________________________
dense_971 (Dense)               (None, 1)            26          dropout_208[0][0]                
__________________________________________________________________________________________________
dense_972 (Dense)               (None, 1)            26          dropout_208[0][0]                
__________________________________________________________________________________________________
dense_973 (Dense)               (None, 1)            26          dropout_208[0][0]                
__________________________________________________________________________________________________
dense_974 (Dense)               (None, 1)            26          dropout_208[0][0]                
__________________________________________________________________________________________________
dense_975 (Dense)               (None, 1)            26          dropout_208[0][0]                
__________________________________________________________________________________________________
dense_976 (Dense)               (None, 1)            26          dropout_208[0][0]                
__________________________________________________________________________________________________
dense_977 (Dense)               (None, 1)            26          dropout_208[0][0]                
__________________________________________________________________________________________________
dense_978 (Dense)               (None, 1)            26          dropout_208[0][0]                
==================================================================================================
Total params: 467,760
Trainable params: 467,760
Non-trainable params: 0
__________________________________________________________________________________________________
None
stacking
Fold  5
0
multi-task
Loading Data
Training Model
Building Multilayer Perceptron
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_240 (InputLayer)          (None, 18390)        0                                            
__________________________________________________________________________________________________
dense_979 (Dense)               (None, 25)           459775      input_240[0][0]                  
__________________________________________________________________________________________________
dropout_209 (Dropout)           (None, 25)           0           dense_979[0][0]                  
__________________________________________________________________________________________________
dense_980 (Dense)               (None, 25)           650         dropout_209[0][0]                
__________________________________________________________________________________________________
dropout_210 (Dropout)           (None, 25)           0           dense_980[0][0]                  
__________________________________________________________________________________________________
dense_981 (Dense)               (None, 1)            26          dropout_210[0][0]                
__________________________________________________________________________________________________
dense_982 (Dense)               (None, 1)            26          dropout_210[0][0]                
__________________________________________________________________________________________________
dense_983 (Dense)               (None, 1)            26          dropout_210[0][0]                
__________________________________________________________________________________________________
dense_984 (Dense)               (None, 1)            26          dropout_210[0][0]                
__________________________________________________________________________________________________
dense_985 (Dense)               (None, 1)            26          dropout_210[0][0]                
__________________________________________________________________________________________________
dense_986 (Dense)               (None, 1)            26          dropout_210[0][0]                
__________________________________________________________________________________________________
dense_987 (Dense)               (None, 1)            26          dropout_210[0][0]                
__________________________________________________________________________________________________
dense_988 (Dense)               (None, 1)            26          dropout_210[0][0]                
__________________________________________________________________________________________________
dense_989 (Dense)               (None, 1)            26          dropout_210[0][0]                
__________________________________________________________________________________________________
dense_990 (Dense)               (None, 1)            26          dropout_210[0][0]                
==================================================================================================
Total params: 460,685
Trainable params: 460,685
Non-trainable params: 0
__________________________________________________________________________________________________
None
stacking
time elapsed: 555.4207045130024
Fold  1
0
multi-task
Loading Data
Training Model
Building Multilayer Perceptron
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_241 (InputLayer)          (None, 18886)        0                                            
__________________________________________________________________________________________________
dense_991 (Dense)               (None, 25)           472175      input_241[0][0]                  
__________________________________________________________________________________________________
dropout_211 (Dropout)           (None, 25)           0           dense_991[0][0]                  
__________________________________________________________________________________________________
dense_992 (Dense)               (None, 25)           650         dropout_211[0][0]                
__________________________________________________________________________________________________
dropout_212 (Dropout)           (None, 25)           0           dense_992[0][0]                  
__________________________________________________________________________________________________
dense_993 (Dense)               (None, 1)            26          dropout_212[0][0]                
__________________________________________________________________________________________________
dense_994 (Dense)               (None, 1)            26          dropout_212[0][0]                
__________________________________________________________________________________________________
dense_995 (Dense)               (None, 1)            26          dropout_212[0][0]                
__________________________________________________________________________________________________
dense_996 (Dense)               (None, 1)            26          dropout_212[0][0]                
__________________________________________________________________________________________________
dense_997 (Dense)               (None, 1)            26          dropout_212[0][0]                
__________________________________________________________________________________________________
dense_998 (Dense)               (None, 1)            26          dropout_212[0][0]                
__________________________________________________________________________________________________
dense_999 (Dense)               (None, 1)            26          dropout_212[0][0]                
__________________________________________________________________________________________________
dense_1000 (Dense)              (None, 1)            26          dropout_212[0][0]                
__________________________________________________________________________________________________
dense_1001 (Dense)              (None, 1)            26          dropout_212[0][0]                
__________________________________________________________________________________________________
dense_1002 (Dense)              (None, 1)            26          dropout_212[0][0]                
==================================================================================================
Total params: 473,085
Trainable params: 473,085
Non-trainable params: 0
__________________________________________________________________________________________________
None
stacking
Fold  2
0
multi-task
Loading Data
Training Model
Building Multilayer Perceptron
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_242 (InputLayer)          (None, 18908)        0                                            
__________________________________________________________________________________________________
dense_1003 (Dense)              (None, 25)           472725      input_242[0][0]                  
__________________________________________________________________________________________________
dropout_213 (Dropout)           (None, 25)           0           dense_1003[0][0]                 
__________________________________________________________________________________________________
dense_1004 (Dense)              (None, 25)           650         dropout_213[0][0]                
__________________________________________________________________________________________________
dropout_214 (Dropout)           (None, 25)           0           dense_1004[0][0]                 
__________________________________________________________________________________________________
dense_1005 (Dense)              (None, 1)            26          dropout_214[0][0]                
__________________________________________________________________________________________________
dense_1006 (Dense)              (None, 1)            26          dropout_214[0][0]                
__________________________________________________________________________________________________
dense_1007 (Dense)              (None, 1)            26          dropout_214[0][0]                
__________________________________________________________________________________________________
dense_1008 (Dense)              (None, 1)            26          dropout_214[0][0]                
__________________________________________________________________________________________________
dense_1009 (Dense)              (None, 1)            26          dropout_214[0][0]                
__________________________________________________________________________________________________
dense_1010 (Dense)              (None, 1)            26          dropout_214[0][0]                
__________________________________________________________________________________________________
dense_1011 (Dense)              (None, 1)            26          dropout_214[0][0]                
__________________________________________________________________________________________________
dense_1012 (Dense)              (None, 1)            26          dropout_214[0][0]                
__________________________________________________________________________________________________
dense_1013 (Dense)              (None, 1)            26          dropout_214[0][0]                
__________________________________________________________________________________________________
dense_1014 (Dense)              (None, 1)            26          dropout_214[0][0]                
==================================================================================================
Total params: 473,635
Trainable params: 473,635
Non-trainable params: 0
__________________________________________________________________________________________________
None
stacking
Fold  3
0
multi-task
Loading Data
Training Model
Building Multilayer Perceptron
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_243 (InputLayer)          (None, 19048)        0                                            
__________________________________________________________________________________________________
dense_1015 (Dense)              (None, 25)           476225      input_243[0][0]                  
__________________________________________________________________________________________________
dropout_215 (Dropout)           (None, 25)           0           dense_1015[0][0]                 
__________________________________________________________________________________________________
dense_1016 (Dense)              (None, 25)           650         dropout_215[0][0]                
__________________________________________________________________________________________________
dropout_216 (Dropout)           (None, 25)           0           dense_1016[0][0]                 
__________________________________________________________________________________________________
dense_1017 (Dense)              (None, 1)            26          dropout_216[0][0]                
__________________________________________________________________________________________________
dense_1018 (Dense)              (None, 1)            26          dropout_216[0][0]                
__________________________________________________________________________________________________
dense_1019 (Dense)              (None, 1)            26          dropout_216[0][0]                
__________________________________________________________________________________________________
dense_1020 (Dense)              (None, 1)            26          dropout_216[0][0]                
__________________________________________________________________________________________________
dense_1021 (Dense)              (None, 1)            26          dropout_216[0][0]                
__________________________________________________________________________________________________
dense_1022 (Dense)              (None, 1)            26          dropout_216[0][0]                
__________________________________________________________________________________________________
dense_1023 (Dense)              (None, 1)            26          dropout_216[0][0]                
__________________________________________________________________________________________________
dense_1024 (Dense)              (None, 1)            26          dropout_216[0][0]                
__________________________________________________________________________________________________
dense_1025 (Dense)              (None, 1)            26          dropout_216[0][0]                
__________________________________________________________________________________________________
dense_1026 (Dense)              (None, 1)            26          dropout_216[0][0]                
==================================================================================================
Total params: 477,135
Trainable params: 477,135
Non-trainable params: 0
__________________________________________________________________________________________________
None
stacking
Fold  4
0
multi-task
Loading Data
Training Model
Building Multilayer Perceptron
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_244 (InputLayer)          (None, 18673)        0                                            
__________________________________________________________________________________________________
dense_1027 (Dense)              (None, 25)           466850      input_244[0][0]                  
__________________________________________________________________________________________________
dropout_217 (Dropout)           (None, 25)           0           dense_1027[0][0]                 
__________________________________________________________________________________________________
dense_1028 (Dense)              (None, 25)           650         dropout_217[0][0]                
__________________________________________________________________________________________________
dropout_218 (Dropout)           (None, 25)           0           dense_1028[0][0]                 
__________________________________________________________________________________________________
dense_1029 (Dense)              (None, 1)            26          dropout_218[0][0]                
__________________________________________________________________________________________________
dense_1030 (Dense)              (None, 1)            26          dropout_218[0][0]                
__________________________________________________________________________________________________
dense_1031 (Dense)              (None, 1)            26          dropout_218[0][0]                
__________________________________________________________________________________________________
dense_1032 (Dense)              (None, 1)            26          dropout_218[0][0]                
__________________________________________________________________________________________________
dense_1033 (Dense)              (None, 1)            26          dropout_218[0][0]                
__________________________________________________________________________________________________
dense_1034 (Dense)              (None, 1)            26          dropout_218[0][0]                
__________________________________________________________________________________________________
dense_1035 (Dense)              (None, 1)            26          dropout_218[0][0]                
__________________________________________________________________________________________________
dense_1036 (Dense)              (None, 1)            26          dropout_218[0][0]                
__________________________________________________________________________________________________
dense_1037 (Dense)              (None, 1)            26          dropout_218[0][0]                
__________________________________________________________________________________________________
dense_1038 (Dense)              (None, 1)            26          dropout_218[0][0]                
==================================================================================================
Total params: 467,760
Trainable params: 467,760
Non-trainable params: 0
__________________________________________________________________________________________________
None
stacking
Fold  5
0
multi-task
Loading Data
Training Model
Building Multilayer Perceptron
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_245 (InputLayer)          (None, 18390)        0                                            
__________________________________________________________________________________________________
dense_1039 (Dense)              (None, 25)           459775      input_245[0][0]                  
__________________________________________________________________________________________________
dropout_219 (Dropout)           (None, 25)           0           dense_1039[0][0]                 
__________________________________________________________________________________________________
dense_1040 (Dense)              (None, 25)           650         dropout_219[0][0]                
__________________________________________________________________________________________________
dropout_220 (Dropout)           (None, 25)           0           dense_1040[0][0]                 
__________________________________________________________________________________________________
dense_1041 (Dense)              (None, 1)            26          dropout_220[0][0]                
__________________________________________________________________________________________________
dense_1042 (Dense)              (None, 1)            26          dropout_220[0][0]                
__________________________________________________________________________________________________
dense_1043 (Dense)              (None, 1)            26          dropout_220[0][0]                
__________________________________________________________________________________________________
dense_1044 (Dense)              (None, 1)            26          dropout_220[0][0]                
__________________________________________________________________________________________________
dense_1045 (Dense)              (None, 1)            26          dropout_220[0][0]                
__________________________________________________________________________________________________
dense_1046 (Dense)              (None, 1)            26          dropout_220[0][0]                
__________________________________________________________________________________________________
dense_1047 (Dense)              (None, 1)            26          dropout_220[0][0]                
__________________________________________________________________________________________________
dense_1048 (Dense)              (None, 1)            26          dropout_220[0][0]                
__________________________________________________________________________________________________
dense_1049 (Dense)              (None, 1)            26          dropout_220[0][0]                
__________________________________________________________________________________________________
dense_1050 (Dense)              (None, 1)            26          dropout_220[0][0]                
==================================================================================================
Total params: 460,685
Trainable params: 460,685
Non-trainable params: 0
__________________________________________________________________________________________________
None
stacking
time elapsed: 783.4773660869978
Fold  1
0
multi-task
Loading Data
Training Model
Building Multilayer Perceptron
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_246 (InputLayer)          (None, 18886)        0                                            
__________________________________________________________________________________________________
dense_1051 (Dense)              (None, 25)           472175      input_246[0][0]                  
__________________________________________________________________________________________________
dropout_221 (Dropout)           (None, 25)           0           dense_1051[0][0]                 
__________________________________________________________________________________________________
dense_1052 (Dense)              (None, 25)           650         dropout_221[0][0]                
__________________________________________________________________________________________________
dropout_222 (Dropout)           (None, 25)           0           dense_1052[0][0]                 
__________________________________________________________________________________________________
dense_1053 (Dense)              (None, 1)            26          dropout_222[0][0]                
__________________________________________________________________________________________________
dense_1054 (Dense)              (None, 1)            26          dropout_222[0][0]                
__________________________________________________________________________________________________
dense_1055 (Dense)              (None, 1)            26          dropout_222[0][0]                
__________________________________________________________________________________________________
dense_1056 (Dense)              (None, 1)            26          dropout_222[0][0]                
__________________________________________________________________________________________________
dense_1057 (Dense)              (None, 1)            26          dropout_222[0][0]                
__________________________________________________________________________________________________
dense_1058 (Dense)              (None, 1)            26          dropout_222[0][0]                
__________________________________________________________________________________________________
dense_1059 (Dense)              (None, 1)            26          dropout_222[0][0]                
__________________________________________________________________________________________________
dense_1060 (Dense)              (None, 1)            26          dropout_222[0][0]                
__________________________________________________________________________________________________
dense_1061 (Dense)              (None, 1)            26          dropout_222[0][0]                
__________________________________________________________________________________________________
dense_1062 (Dense)              (None, 1)            26          dropout_222[0][0]                
==================================================================================================
Total params: 473,085
Trainable params: 473,085
Non-trainable params: 0
__________________________________________________________________________________________________
None
stacking
Fold  2
0
multi-task
Loading Data
Training Model
Building Multilayer Perceptron
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_247 (InputLayer)          (None, 18908)        0                                            
__________________________________________________________________________________________________
dense_1063 (Dense)              (None, 25)           472725      input_247[0][0]                  
__________________________________________________________________________________________________
dropout_223 (Dropout)           (None, 25)           0           dense_1063[0][0]                 
__________________________________________________________________________________________________
dense_1064 (Dense)              (None, 25)           650         dropout_223[0][0]                
__________________________________________________________________________________________________
dropout_224 (Dropout)           (None, 25)           0           dense_1064[0][0]                 
__________________________________________________________________________________________________
dense_1065 (Dense)              (None, 1)            26          dropout_224[0][0]                
__________________________________________________________________________________________________
dense_1066 (Dense)              (None, 1)            26          dropout_224[0][0]                
__________________________________________________________________________________________________
dense_1067 (Dense)              (None, 1)            26          dropout_224[0][0]                
__________________________________________________________________________________________________
dense_1068 (Dense)              (None, 1)            26          dropout_224[0][0]                
__________________________________________________________________________________________________
dense_1069 (Dense)              (None, 1)            26          dropout_224[0][0]                
__________________________________________________________________________________________________
dense_1070 (Dense)              (None, 1)            26          dropout_224[0][0]                
__________________________________________________________________________________________________
dense_1071 (Dense)              (None, 1)            26          dropout_224[0][0]                
__________________________________________________________________________________________________
dense_1072 (Dense)              (None, 1)            26          dropout_224[0][0]                
__________________________________________________________________________________________________
dense_1073 (Dense)              (None, 1)            26          dropout_224[0][0]                
__________________________________________________________________________________________________
dense_1074 (Dense)              (None, 1)            26          dropout_224[0][0]                
==================================================================================================
Total params: 473,635
Trainable params: 473,635
Non-trainable params: 0
__________________________________________________________________________________________________
None
stacking
Fold  3
0
multi-task
Loading Data
Training Model
Building Multilayer Perceptron
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_248 (InputLayer)          (None, 19048)        0                                            
__________________________________________________________________________________________________
dense_1075 (Dense)              (None, 25)           476225      input_248[0][0]                  
__________________________________________________________________________________________________
dropout_225 (Dropout)           (None, 25)           0           dense_1075[0][0]                 
__________________________________________________________________________________________________
dense_1076 (Dense)              (None, 25)           650         dropout_225[0][0]                
__________________________________________________________________________________________________
dropout_226 (Dropout)           (None, 25)           0           dense_1076[0][0]                 
__________________________________________________________________________________________________
dense_1077 (Dense)              (None, 1)            26          dropout_226[0][0]                
__________________________________________________________________________________________________
dense_1078 (Dense)              (None, 1)            26          dropout_226[0][0]                
__________________________________________________________________________________________________
dense_1079 (Dense)              (None, 1)            26          dropout_226[0][0]                
__________________________________________________________________________________________________
dense_1080 (Dense)              (None, 1)            26          dropout_226[0][0]                
__________________________________________________________________________________________________
dense_1081 (Dense)              (None, 1)            26          dropout_226[0][0]                
__________________________________________________________________________________________________
dense_1082 (Dense)              (None, 1)            26          dropout_226[0][0]                
__________________________________________________________________________________________________
dense_1083 (Dense)              (None, 1)            26          dropout_226[0][0]                
__________________________________________________________________________________________________
dense_1084 (Dense)              (None, 1)            26          dropout_226[0][0]                
__________________________________________________________________________________________________
dense_1085 (Dense)              (None, 1)            26          dropout_226[0][0]                
__________________________________________________________________________________________________
dense_1086 (Dense)              (None, 1)            26          dropout_226[0][0]                
==================================================================================================
Total params: 477,135
Trainable params: 477,135
Non-trainable params: 0
__________________________________________________________________________________________________
None
stacking
Fold  4
0
multi-task
Loading Data
Training Model
Building Multilayer Perceptron
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_249 (InputLayer)          (None, 18673)        0                                            
__________________________________________________________________________________________________
dense_1087 (Dense)              (None, 25)           466850      input_249[0][0]                  
__________________________________________________________________________________________________
dropout_227 (Dropout)           (None, 25)           0           dense_1087[0][0]                 
__________________________________________________________________________________________________
dense_1088 (Dense)              (None, 25)           650         dropout_227[0][0]                
__________________________________________________________________________________________________
dropout_228 (Dropout)           (None, 25)           0           dense_1088[0][0]                 
__________________________________________________________________________________________________
dense_1089 (Dense)              (None, 1)            26          dropout_228[0][0]                
__________________________________________________________________________________________________
dense_1090 (Dense)              (None, 1)            26          dropout_228[0][0]                
__________________________________________________________________________________________________
dense_1091 (Dense)              (None, 1)            26          dropout_228[0][0]                
__________________________________________________________________________________________________
dense_1092 (Dense)              (None, 1)            26          dropout_228[0][0]                
__________________________________________________________________________________________________
dense_1093 (Dense)              (None, 1)            26          dropout_228[0][0]                
__________________________________________________________________________________________________
dense_1094 (Dense)              (None, 1)            26          dropout_228[0][0]                
__________________________________________________________________________________________________
dense_1095 (Dense)              (None, 1)            26          dropout_228[0][0]                
__________________________________________________________________________________________________
dense_1096 (Dense)              (None, 1)            26          dropout_228[0][0]                
__________________________________________________________________________________________________
dense_1097 (Dense)              (None, 1)            26          dropout_228[0][0]                
__________________________________________________________________________________________________
dense_1098 (Dense)              (None, 1)            26          dropout_228[0][0]                
==================================================================================================
Total params: 467,760
Trainable params: 467,760
Non-trainable params: 0
__________________________________________________________________________________________________
None
stacking
Fold  5
0
multi-task
Loading Data
Training Model
Building Multilayer Perceptron
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_250 (InputLayer)          (None, 18390)        0                                            
__________________________________________________________________________________________________
dense_1099 (Dense)              (None, 25)           459775      input_250[0][0]                  
__________________________________________________________________________________________________
dropout_229 (Dropout)           (None, 25)           0           dense_1099[0][0]                 
__________________________________________________________________________________________________
dense_1100 (Dense)              (None, 25)           650         dropout_229[0][0]                
__________________________________________________________________________________________________
dropout_230 (Dropout)           (None, 25)           0           dense_1100[0][0]                 
__________________________________________________________________________________________________
dense_1101 (Dense)              (None, 1)            26          dropout_230[0][0]                
__________________________________________________________________________________________________
dense_1102 (Dense)              (None, 1)            26          dropout_230[0][0]                
__________________________________________________________________________________________________
dense_1103 (Dense)              (None, 1)            26          dropout_230[0][0]                
__________________________________________________________________________________________________
dense_1104 (Dense)              (None, 1)            26          dropout_230[0][0]                
__________________________________________________________________________________________________
dense_1105 (Dense)              (None, 1)            26          dropout_230[0][0]                
__________________________________________________________________________________________________
dense_1106 (Dense)              (None, 1)            26          dropout_230[0][0]                
__________________________________________________________________________________________________
dense_1107 (Dense)              (None, 1)            26          dropout_230[0][0]                
__________________________________________________________________________________________________
dense_1108 (Dense)              (None, 1)            26          dropout_230[0][0]                
__________________________________________________________________________________________________
dense_1109 (Dense)              (None, 1)            26          dropout_230[0][0]                
__________________________________________________________________________________________________
dense_1110 (Dense)              (None, 1)            26          dropout_230[0][0]                
==================================================================================================
Total params: 460,685
Trainable params: 460,685
Non-trainable params: 0
__________________________________________________________________________________________________
None
stacking
time elapsed: 1024.8389913290011
Fold  1
0
multi-task
Loading Data
Training Model
Building Multilayer Perceptron
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_251 (InputLayer)          (None, 18886)        0                                            
__________________________________________________________________________________________________
dense_1111 (Dense)              (None, 25)           472175      input_251[0][0]                  
__________________________________________________________________________________________________
dropout_231 (Dropout)           (None, 25)           0           dense_1111[0][0]                 
__________________________________________________________________________________________________
dense_1112 (Dense)              (None, 25)           650         dropout_231[0][0]                
__________________________________________________________________________________________________
dropout_232 (Dropout)           (None, 25)           0           dense_1112[0][0]                 
__________________________________________________________________________________________________
dense_1113 (Dense)              (None, 1)            26          dropout_232[0][0]                
__________________________________________________________________________________________________
dense_1114 (Dense)              (None, 1)            26          dropout_232[0][0]                
__________________________________________________________________________________________________
dense_1115 (Dense)              (None, 1)            26          dropout_232[0][0]                
__________________________________________________________________________________________________
dense_1116 (Dense)              (None, 1)            26          dropout_232[0][0]                
__________________________________________________________________________________________________
dense_1117 (Dense)              (None, 1)            26          dropout_232[0][0]                
__________________________________________________________________________________________________
dense_1118 (Dense)              (None, 1)            26          dropout_232[0][0]                
__________________________________________________________________________________________________
dense_1119 (Dense)              (None, 1)            26          dropout_232[0][0]                
__________________________________________________________________________________________________
dense_1120 (Dense)              (None, 1)            26          dropout_232[0][0]                
__________________________________________________________________________________________________
dense_1121 (Dense)              (None, 1)            26          dropout_232[0][0]                
__________________________________________________________________________________________________
dense_1122 (Dense)              (None, 1)            26          dropout_232[0][0]                
==================================================================================================
Total params: 473,085
Trainable params: 473,085
Non-trainable params: 0
__________________________________________________________________________________________________
None
stacking
Fold  2
0
multi-task
Loading Data
Training Model
Building Multilayer Perceptron
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_252 (InputLayer)          (None, 18908)        0                                            
__________________________________________________________________________________________________
dense_1123 (Dense)              (None, 25)           472725      input_252[0][0]                  
__________________________________________________________________________________________________
dropout_233 (Dropout)           (None, 25)           0           dense_1123[0][0]                 
__________________________________________________________________________________________________
dense_1124 (Dense)              (None, 25)           650         dropout_233[0][0]                
__________________________________________________________________________________________________
dropout_234 (Dropout)           (None, 25)           0           dense_1124[0][0]                 
__________________________________________________________________________________________________
dense_1125 (Dense)              (None, 1)            26          dropout_234[0][0]                
__________________________________________________________________________________________________
dense_1126 (Dense)              (None, 1)            26          dropout_234[0][0]                
__________________________________________________________________________________________________
dense_1127 (Dense)              (None, 1)            26          dropout_234[0][0]                
__________________________________________________________________________________________________
dense_1128 (Dense)              (None, 1)            26          dropout_234[0][0]                
__________________________________________________________________________________________________
dense_1129 (Dense)              (None, 1)            26          dropout_234[0][0]                
__________________________________________________________________________________________________
dense_1130 (Dense)              (None, 1)            26          dropout_234[0][0]                
__________________________________________________________________________________________________
dense_1131 (Dense)              (None, 1)            26          dropout_234[0][0]                
__________________________________________________________________________________________________
dense_1132 (Dense)              (None, 1)            26          dropout_234[0][0]                
__________________________________________________________________________________________________
dense_1133 (Dense)              (None, 1)            26          dropout_234[0][0]                
__________________________________________________________________________________________________
dense_1134 (Dense)              (None, 1)            26          dropout_234[0][0]                
==================================================================================================
Total params: 473,635
Trainable params: 473,635
Non-trainable params: 0
__________________________________________________________________________________________________
None
stacking
Fold  3
0
multi-task
Loading Data
Training Model
Building Multilayer Perceptron
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_253 (InputLayer)          (None, 19048)        0                                            
__________________________________________________________________________________________________
dense_1135 (Dense)              (None, 25)           476225      input_253[0][0]                  
__________________________________________________________________________________________________
dropout_235 (Dropout)           (None, 25)           0           dense_1135[0][0]                 
__________________________________________________________________________________________________
dense_1136 (Dense)              (None, 25)           650         dropout_235[0][0]                
__________________________________________________________________________________________________
dropout_236 (Dropout)           (None, 25)           0           dense_1136[0][0]                 
__________________________________________________________________________________________________
dense_1137 (Dense)              (None, 1)            26          dropout_236[0][0]                
__________________________________________________________________________________________________
dense_1138 (Dense)              (None, 1)            26          dropout_236[0][0]                
__________________________________________________________________________________________________
dense_1139 (Dense)              (None, 1)            26          dropout_236[0][0]                
__________________________________________________________________________________________________
dense_1140 (Dense)              (None, 1)            26          dropout_236[0][0]                
__________________________________________________________________________________________________
dense_1141 (Dense)              (None, 1)            26          dropout_236[0][0]                
__________________________________________________________________________________________________
dense_1142 (Dense)              (None, 1)            26          dropout_236[0][0]                
__________________________________________________________________________________________________
dense_1143 (Dense)              (None, 1)            26          dropout_236[0][0]                
__________________________________________________________________________________________________
dense_1144 (Dense)              (None, 1)            26          dropout_236[0][0]                
__________________________________________________________________________________________________
dense_1145 (Dense)              (None, 1)            26          dropout_236[0][0]                
__________________________________________________________________________________________________
dense_1146 (Dense)              (None, 1)            26          dropout_236[0][0]                
==================================================================================================
Total params: 477,135
Trainable params: 477,135
Non-trainable params: 0
__________________________________________________________________________________________________
None
stacking
Fold  4
0
multi-task
Loading Data
Training Model
Building Multilayer Perceptron
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_254 (InputLayer)          (None, 18673)        0                                            
__________________________________________________________________________________________________
dense_1147 (Dense)              (None, 25)           466850      input_254[0][0]                  
__________________________________________________________________________________________________
dropout_237 (Dropout)           (None, 25)           0           dense_1147[0][0]                 
__________________________________________________________________________________________________
dense_1148 (Dense)              (None, 25)           650         dropout_237[0][0]                
__________________________________________________________________________________________________
dropout_238 (Dropout)           (None, 25)           0           dense_1148[0][0]                 
__________________________________________________________________________________________________
dense_1149 (Dense)              (None, 1)            26          dropout_238[0][0]                
__________________________________________________________________________________________________
dense_1150 (Dense)              (None, 1)            26          dropout_238[0][0]                
__________________________________________________________________________________________________
dense_1151 (Dense)              (None, 1)            26          dropout_238[0][0]                
__________________________________________________________________________________________________
dense_1152 (Dense)              (None, 1)            26          dropout_238[0][0]                
__________________________________________________________________________________________________
dense_1153 (Dense)              (None, 1)            26          dropout_238[0][0]                
__________________________________________________________________________________________________
dense_1154 (Dense)              (None, 1)            26          dropout_238[0][0]                
__________________________________________________________________________________________________
dense_1155 (Dense)              (None, 1)            26          dropout_238[0][0]                
__________________________________________________________________________________________________
dense_1156 (Dense)              (None, 1)            26          dropout_238[0][0]                
__________________________________________________________________________________________________
dense_1157 (Dense)              (None, 1)            26          dropout_238[0][0]                
__________________________________________________________________________________________________
dense_1158 (Dense)              (None, 1)            26          dropout_238[0][0]                
==================================================================================================
Total params: 467,760
Trainable params: 467,760
Non-trainable params: 0
__________________________________________________________________________________________________
None
stacking
Fold  5
0
multi-task
Loading Data
Training Model
Building Multilayer Perceptron
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_255 (InputLayer)          (None, 18390)        0                                            
__________________________________________________________________________________________________
dense_1159 (Dense)              (None, 25)           459775      input_255[0][0]                  
__________________________________________________________________________________________________
dropout_239 (Dropout)           (None, 25)           0           dense_1159[0][0]                 
__________________________________________________________________________________________________
dense_1160 (Dense)              (None, 25)           650         dropout_239[0][0]                
__________________________________________________________________________________________________
dropout_240 (Dropout)           (None, 25)           0           dense_1160[0][0]                 
__________________________________________________________________________________________________
dense_1161 (Dense)              (None, 1)            26          dropout_240[0][0]                
__________________________________________________________________________________________________
dense_1162 (Dense)              (None, 1)            26          dropout_240[0][0]                
__________________________________________________________________________________________________
dense_1163 (Dense)              (None, 1)            26          dropout_240[0][0]                
__________________________________________________________________________________________________
dense_1164 (Dense)              (None, 1)            26          dropout_240[0][0]                
__________________________________________________________________________________________________
dense_1165 (Dense)              (None, 1)            26          dropout_240[0][0]                
__________________________________________________________________________________________________
dense_1166 (Dense)              (None, 1)            26          dropout_240[0][0]                
__________________________________________________________________________________________________
dense_1167 (Dense)              (None, 1)            26          dropout_240[0][0]                
__________________________________________________________________________________________________
dense_1168 (Dense)              (None, 1)            26          dropout_240[0][0]                
__________________________________________________________________________________________________
dense_1169 (Dense)              (None, 1)            26          dropout_240[0][0]                
__________________________________________________________________________________________________
dense_1170 (Dense)              (None, 1)            26          dropout_240[0][0]                
==================================================================================================
Total params: 460,685
Trainable params: 460,685
Non-trainable params: 0
__________________________________________________________________________________________________
None
stacking
time elapsed: 1301.1644335299934
Fold  1
0
multi-task
Loading Data
Training Model
Building Multilayer Perceptron
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_256 (InputLayer)          (None, 18886)        0                                            
__________________________________________________________________________________________________
dense_1171 (Dense)              (None, 25)           472175      input_256[0][0]                  
__________________________________________________________________________________________________
dropout_241 (Dropout)           (None, 25)           0           dense_1171[0][0]                 
__________________________________________________________________________________________________
dense_1172 (Dense)              (None, 25)           650         dropout_241[0][0]                
__________________________________________________________________________________________________
dropout_242 (Dropout)           (None, 25)           0           dense_1172[0][0]                 
__________________________________________________________________________________________________
dense_1173 (Dense)              (None, 1)            26          dropout_242[0][0]                
__________________________________________________________________________________________________
dense_1174 (Dense)              (None, 1)            26          dropout_242[0][0]                
__________________________________________________________________________________________________
dense_1175 (Dense)              (None, 1)            26          dropout_242[0][0]                
__________________________________________________________________________________________________
dense_1176 (Dense)              (None, 1)            26          dropout_242[0][0]                
__________________________________________________________________________________________________
dense_1177 (Dense)              (None, 1)            26          dropout_242[0][0]                
__________________________________________________________________________________________________
dense_1178 (Dense)              (None, 1)            26          dropout_242[0][0]                
__________________________________________________________________________________________________
dense_1179 (Dense)              (None, 1)            26          dropout_242[0][0]                
__________________________________________________________________________________________________
dense_1180 (Dense)              (None, 1)            26          dropout_242[0][0]                
__________________________________________________________________________________________________
dense_1181 (Dense)              (None, 1)            26          dropout_242[0][0]                
__________________________________________________________________________________________________
dense_1182 (Dense)              (None, 1)            26          dropout_242[0][0]                
==================================================================================================
Total params: 473,085
Trainable params: 473,085
Non-trainable params: 0
__________________________________________________________________________________________________
None
stacking
Fold  2
0
multi-task
Loading Data
Training Model
Building Multilayer Perceptron
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_257 (InputLayer)          (None, 18908)        0                                            
__________________________________________________________________________________________________
dense_1183 (Dense)              (None, 25)           472725      input_257[0][0]                  
__________________________________________________________________________________________________
dropout_243 (Dropout)           (None, 25)           0           dense_1183[0][0]                 
__________________________________________________________________________________________________
dense_1184 (Dense)              (None, 25)           650         dropout_243[0][0]                
__________________________________________________________________________________________________
dropout_244 (Dropout)           (None, 25)           0           dense_1184[0][0]                 
__________________________________________________________________________________________________
dense_1185 (Dense)              (None, 1)            26          dropout_244[0][0]                
__________________________________________________________________________________________________
dense_1186 (Dense)              (None, 1)            26          dropout_244[0][0]                
__________________________________________________________________________________________________
dense_1187 (Dense)              (None, 1)            26          dropout_244[0][0]                
__________________________________________________________________________________________________
dense_1188 (Dense)              (None, 1)            26          dropout_244[0][0]                
__________________________________________________________________________________________________
dense_1189 (Dense)              (None, 1)            26          dropout_244[0][0]                
__________________________________________________________________________________________________
dense_1190 (Dense)              (None, 1)            26          dropout_244[0][0]                
__________________________________________________________________________________________________
dense_1191 (Dense)              (None, 1)            26          dropout_244[0][0]                
__________________________________________________________________________________________________
dense_1192 (Dense)              (None, 1)            26          dropout_244[0][0]                
__________________________________________________________________________________________________
dense_1193 (Dense)              (None, 1)            26          dropout_244[0][0]                
__________________________________________________________________________________________________
dense_1194 (Dense)              (None, 1)            26          dropout_244[0][0]                
==================================================================================================
Total params: 473,635
Trainable params: 473,635
Non-trainable params: 0
__________________________________________________________________________________________________
None
stacking
Fold  3
0
multi-task
Loading Data
Training Model
Building Multilayer Perceptron
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_258 (InputLayer)          (None, 19048)        0                                            
__________________________________________________________________________________________________
dense_1195 (Dense)              (None, 25)           476225      input_258[0][0]                  
__________________________________________________________________________________________________
dropout_245 (Dropout)           (None, 25)           0           dense_1195[0][0]                 
__________________________________________________________________________________________________
dense_1196 (Dense)              (None, 25)           650         dropout_245[0][0]                
__________________________________________________________________________________________________
dropout_246 (Dropout)           (None, 25)           0           dense_1196[0][0]                 
__________________________________________________________________________________________________
dense_1197 (Dense)              (None, 1)            26          dropout_246[0][0]                
__________________________________________________________________________________________________
dense_1198 (Dense)              (None, 1)            26          dropout_246[0][0]                
__________________________________________________________________________________________________
dense_1199 (Dense)              (None, 1)            26          dropout_246[0][0]                
__________________________________________________________________________________________________
dense_1200 (Dense)              (None, 1)            26          dropout_246[0][0]                
__________________________________________________________________________________________________
dense_1201 (Dense)              (None, 1)            26          dropout_246[0][0]                
__________________________________________________________________________________________________
dense_1202 (Dense)              (None, 1)            26          dropout_246[0][0]                
__________________________________________________________________________________________________
dense_1203 (Dense)              (None, 1)            26          dropout_246[0][0]                
__________________________________________________________________________________________________
dense_1204 (Dense)              (None, 1)            26          dropout_246[0][0]                
__________________________________________________________________________________________________
dense_1205 (Dense)              (None, 1)            26          dropout_246[0][0]                
__________________________________________________________________________________________________
dense_1206 (Dense)              (None, 1)            26          dropout_246[0][0]                
==================================================================================================
Total params: 477,135
Trainable params: 477,135
Non-trainable params: 0
__________________________________________________________________________________________________
None
stacking
Fold  4
0
multi-task
Loading Data
Training Model
Building Multilayer Perceptron
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_259 (InputLayer)          (None, 18673)        0                                            
__________________________________________________________________________________________________
dense_1207 (Dense)              (None, 25)           466850      input_259[0][0]                  
__________________________________________________________________________________________________
dropout_247 (Dropout)           (None, 25)           0           dense_1207[0][0]                 
__________________________________________________________________________________________________
dense_1208 (Dense)              (None, 25)           650         dropout_247[0][0]                
__________________________________________________________________________________________________
dropout_248 (Dropout)           (None, 25)           0           dense_1208[0][0]                 
__________________________________________________________________________________________________
dense_1209 (Dense)              (None, 1)            26          dropout_248[0][0]                
__________________________________________________________________________________________________
dense_1210 (Dense)              (None, 1)            26          dropout_248[0][0]                
__________________________________________________________________________________________________
dense_1211 (Dense)              (None, 1)            26          dropout_248[0][0]                
__________________________________________________________________________________________________
dense_1212 (Dense)              (None, 1)            26          dropout_248[0][0]                
__________________________________________________________________________________________________
dense_1213 (Dense)              (None, 1)            26          dropout_248[0][0]                
__________________________________________________________________________________________________
dense_1214 (Dense)              (None, 1)            26          dropout_248[0][0]                
__________________________________________________________________________________________________
dense_1215 (Dense)              (None, 1)            26          dropout_248[0][0]                
__________________________________________________________________________________________________
dense_1216 (Dense)              (None, 1)            26          dropout_248[0][0]                
__________________________________________________________________________________________________
dense_1217 (Dense)              (None, 1)            26          dropout_248[0][0]                
__________________________________________________________________________________________________
dense_1218 (Dense)              (None, 1)            26          dropout_248[0][0]                
==================================================================================================
Total params: 467,760
Trainable params: 467,760
Non-trainable params: 0
__________________________________________________________________________________________________
None
stacking
Fold  5
0
multi-task
Loading Data
Training Model
Building Multilayer Perceptron
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_260 (InputLayer)          (None, 18390)        0                                            
__________________________________________________________________________________________________
dense_1219 (Dense)              (None, 25)           459775      input_260[0][0]                  
__________________________________________________________________________________________________
dropout_249 (Dropout)           (None, 25)           0           dense_1219[0][0]                 
__________________________________________________________________________________________________
dense_1220 (Dense)              (None, 25)           650         dropout_249[0][0]                
__________________________________________________________________________________________________
dropout_250 (Dropout)           (None, 25)           0           dense_1220[0][0]                 
__________________________________________________________________________________________________
dense_1221 (Dense)              (None, 1)            26          dropout_250[0][0]                
__________________________________________________________________________________________________
dense_1222 (Dense)              (None, 1)            26          dropout_250[0][0]                
__________________________________________________________________________________________________
dense_1223 (Dense)              (None, 1)            26          dropout_250[0][0]                
__________________________________________________________________________________________________
dense_1224 (Dense)              (None, 1)            26          dropout_250[0][0]                
__________________________________________________________________________________________________
dense_1225 (Dense)              (None, 1)            26          dropout_250[0][0]                
__________________________________________________________________________________________________
dense_1226 (Dense)              (None, 1)            26          dropout_250[0][0]                
__________________________________________________________________________________________________
dense_1227 (Dense)              (None, 1)            26          dropout_250[0][0]                
__________________________________________________________________________________________________
dense_1228 (Dense)              (None, 1)            26          dropout_250[0][0]                
__________________________________________________________________________________________________
dense_1229 (Dense)              (None, 1)            26          dropout_250[0][0]                
__________________________________________________________________________________________________
dense_1230 (Dense)              (None, 1)            26          dropout_250[0][0]                
==================================================================================================
Total params: 460,685
Trainable params: 460,685
Non-trainable params: 0
__________________________________________________________________________________________________
None
stacking
time elapsed: 1546.695381913989
Fold  1
0
multi-task
Loading Data
Training Model
Building Multilayer Perceptron
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_261 (InputLayer)          (None, 18886)        0                                            
__________________________________________________________________________________________________
dense_1231 (Dense)              (None, 25)           472175      input_261[0][0]                  
__________________________________________________________________________________________________
dropout_251 (Dropout)           (None, 25)           0           dense_1231[0][0]                 
__________________________________________________________________________________________________
dense_1232 (Dense)              (None, 25)           650         dropout_251[0][0]                
__________________________________________________________________________________________________
dropout_252 (Dropout)           (None, 25)           0           dense_1232[0][0]                 
__________________________________________________________________________________________________
dense_1233 (Dense)              (None, 1)            26          dropout_252[0][0]                
__________________________________________________________________________________________________
dense_1234 (Dense)              (None, 1)            26          dropout_252[0][0]                
__________________________________________________________________________________________________
dense_1235 (Dense)              (None, 1)            26          dropout_252[0][0]                
__________________________________________________________________________________________________
dense_1236 (Dense)              (None, 1)            26          dropout_252[0][0]                
__________________________________________________________________________________________________
dense_1237 (Dense)              (None, 1)            26          dropout_252[0][0]                
__________________________________________________________________________________________________
dense_1238 (Dense)              (None, 1)            26          dropout_252[0][0]                
__________________________________________________________________________________________________
dense_1239 (Dense)              (None, 1)            26          dropout_252[0][0]                
__________________________________________________________________________________________________
dense_1240 (Dense)              (None, 1)            26          dropout_252[0][0]                
__________________________________________________________________________________________________
dense_1241 (Dense)              (None, 1)            26          dropout_252[0][0]                
__________________________________________________________________________________________________
dense_1242 (Dense)              (None, 1)            26          dropout_252[0][0]                
==================================================================================================
Total params: 473,085
Trainable params: 473,085
Non-trainable params: 0
__________________________________________________________________________________________________
None
stacking
Fold  2
0
multi-task
Loading Data
Training Model
Building Multilayer Perceptron
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_262 (InputLayer)          (None, 18908)        0                                            
__________________________________________________________________________________________________
dense_1243 (Dense)              (None, 25)           472725      input_262[0][0]                  
__________________________________________________________________________________________________
dropout_253 (Dropout)           (None, 25)           0           dense_1243[0][0]                 
__________________________________________________________________________________________________
dense_1244 (Dense)              (None, 25)           650         dropout_253[0][0]                
__________________________________________________________________________________________________
dropout_254 (Dropout)           (None, 25)           0           dense_1244[0][0]                 
__________________________________________________________________________________________________
dense_1245 (Dense)              (None, 1)            26          dropout_254[0][0]                
__________________________________________________________________________________________________
dense_1246 (Dense)              (None, 1)            26          dropout_254[0][0]                
__________________________________________________________________________________________________
dense_1247 (Dense)              (None, 1)            26          dropout_254[0][0]                
__________________________________________________________________________________________________
dense_1248 (Dense)              (None, 1)            26          dropout_254[0][0]                
__________________________________________________________________________________________________
dense_1249 (Dense)              (None, 1)            26          dropout_254[0][0]                
__________________________________________________________________________________________________
dense_1250 (Dense)              (None, 1)            26          dropout_254[0][0]                
__________________________________________________________________________________________________
dense_1251 (Dense)              (None, 1)            26          dropout_254[0][0]                
__________________________________________________________________________________________________
dense_1252 (Dense)              (None, 1)            26          dropout_254[0][0]                
__________________________________________________________________________________________________
dense_1253 (Dense)              (None, 1)            26          dropout_254[0][0]                
__________________________________________________________________________________________________
dense_1254 (Dense)              (None, 1)            26          dropout_254[0][0]                
==================================================================================================
Total params: 473,635
Trainable params: 473,635
Non-trainable params: 0
__________________________________________________________________________________________________
None
stacking
Fold  3
0
multi-task
Loading Data
Training Model
Building Multilayer Perceptron
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_263 (InputLayer)          (None, 19048)        0                                            
__________________________________________________________________________________________________
dense_1255 (Dense)              (None, 25)           476225      input_263[0][0]                  
__________________________________________________________________________________________________
dropout_255 (Dropout)           (None, 25)           0           dense_1255[0][0]                 
__________________________________________________________________________________________________
dense_1256 (Dense)              (None, 25)           650         dropout_255[0][0]                
__________________________________________________________________________________________________
dropout_256 (Dropout)           (None, 25)           0           dense_1256[0][0]                 
__________________________________________________________________________________________________
dense_1257 (Dense)              (None, 1)            26          dropout_256[0][0]                
__________________________________________________________________________________________________
dense_1258 (Dense)              (None, 1)            26          dropout_256[0][0]                
__________________________________________________________________________________________________
dense_1259 (Dense)              (None, 1)            26          dropout_256[0][0]                
__________________________________________________________________________________________________
dense_1260 (Dense)              (None, 1)            26          dropout_256[0][0]                
__________________________________________________________________________________________________
dense_1261 (Dense)              (None, 1)            26          dropout_256[0][0]                
__________________________________________________________________________________________________
dense_1262 (Dense)              (None, 1)            26          dropout_256[0][0]                
__________________________________________________________________________________________________
dense_1263 (Dense)              (None, 1)            26          dropout_256[0][0]                
__________________________________________________________________________________________________
dense_1264 (Dense)              (None, 1)            26          dropout_256[0][0]                
__________________________________________________________________________________________________
dense_1265 (Dense)              (None, 1)            26          dropout_256[0][0]                
__________________________________________________________________________________________________
dense_1266 (Dense)              (None, 1)            26          dropout_256[0][0]                
==================================================================================================
Total params: 477,135
Trainable params: 477,135
Non-trainable params: 0
__________________________________________________________________________________________________
None
stacking
Fold  4
0
multi-task
Loading Data
Training Model
Building Multilayer Perceptron
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_264 (InputLayer)          (None, 18673)        0                                            
__________________________________________________________________________________________________
dense_1267 (Dense)              (None, 25)           466850      input_264[0][0]                  
__________________________________________________________________________________________________
dropout_257 (Dropout)           (None, 25)           0           dense_1267[0][0]                 
__________________________________________________________________________________________________
dense_1268 (Dense)              (None, 25)           650         dropout_257[0][0]                
__________________________________________________________________________________________________
dropout_258 (Dropout)           (None, 25)           0           dense_1268[0][0]                 
__________________________________________________________________________________________________
dense_1269 (Dense)              (None, 1)            26          dropout_258[0][0]                
__________________________________________________________________________________________________
dense_1270 (Dense)              (None, 1)            26          dropout_258[0][0]                
__________________________________________________________________________________________________
dense_1271 (Dense)              (None, 1)            26          dropout_258[0][0]                
__________________________________________________________________________________________________
dense_1272 (Dense)              (None, 1)            26          dropout_258[0][0]                
__________________________________________________________________________________________________
dense_1273 (Dense)              (None, 1)            26          dropout_258[0][0]                
__________________________________________________________________________________________________
dense_1274 (Dense)              (None, 1)            26          dropout_258[0][0]                
__________________________________________________________________________________________________
dense_1275 (Dense)              (None, 1)            26          dropout_258[0][0]                
__________________________________________________________________________________________________
dense_1276 (Dense)              (None, 1)            26          dropout_258[0][0]                
__________________________________________________________________________________________________
dense_1277 (Dense)              (None, 1)            26          dropout_258[0][0]                
__________________________________________________________________________________________________
dense_1278 (Dense)              (None, 1)            26          dropout_258[0][0]                
==================================================================================================
Total params: 467,760
Trainable params: 467,760
Non-trainable params: 0
__________________________________________________________________________________________________
None
stacking
Fold  5
0
multi-task
Loading Data
Training Model
Building Multilayer Perceptron
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_265 (InputLayer)          (None, 18390)        0                                            
__________________________________________________________________________________________________
dense_1279 (Dense)              (None, 25)           459775      input_265[0][0]                  
__________________________________________________________________________________________________
dropout_259 (Dropout)           (None, 25)           0           dense_1279[0][0]                 
__________________________________________________________________________________________________
dense_1280 (Dense)              (None, 25)           650         dropout_259[0][0]                
__________________________________________________________________________________________________
dropout_260 (Dropout)           (None, 25)           0           dense_1280[0][0]                 
__________________________________________________________________________________________________
dense_1281 (Dense)              (None, 1)            26          dropout_260[0][0]                
__________________________________________________________________________________________________
dense_1282 (Dense)              (None, 1)            26          dropout_260[0][0]                
__________________________________________________________________________________________________
dense_1283 (Dense)              (None, 1)            26          dropout_260[0][0]                
__________________________________________________________________________________________________
dense_1284 (Dense)              (None, 1)            26          dropout_260[0][0]                
__________________________________________________________________________________________________
dense_1285 (Dense)              (None, 1)            26          dropout_260[0][0]                
__________________________________________________________________________________________________
dense_1286 (Dense)              (None, 1)            26          dropout_260[0][0]                
__________________________________________________________________________________________________
dense_1287 (Dense)              (None, 1)            26          dropout_260[0][0]                
__________________________________________________________________________________________________
dense_1288 (Dense)              (None, 1)            26          dropout_260[0][0]                
__________________________________________________________________________________________________
dense_1289 (Dense)              (None, 1)            26          dropout_260[0][0]                
__________________________________________________________________________________________________
dense_1290 (Dense)              (None, 1)            26          dropout_260[0][0]                
==================================================================================================
Total params: 460,685
Trainable params: 460,685
Non-trainable params: 0
__________________________________________________________________________________________________
None
stacking
time elapsed: 1810.3174066350039
Fold  1
0
multi-task
Loading Data
Training Model
Building Multilayer Perceptron
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_266 (InputLayer)          (None, 18886)        0                                            
__________________________________________________________________________________________________
dense_1291 (Dense)              (None, 25)           472175      input_266[0][0]                  
__________________________________________________________________________________________________
dropout_261 (Dropout)           (None, 25)           0           dense_1291[0][0]                 
__________________________________________________________________________________________________
dense_1292 (Dense)              (None, 25)           650         dropout_261[0][0]                
__________________________________________________________________________________________________
dropout_262 (Dropout)           (None, 25)           0           dense_1292[0][0]                 
__________________________________________________________________________________________________
dense_1293 (Dense)              (None, 1)            26          dropout_262[0][0]                
__________________________________________________________________________________________________
dense_1294 (Dense)              (None, 1)            26          dropout_262[0][0]                
__________________________________________________________________________________________________
dense_1295 (Dense)              (None, 1)            26          dropout_262[0][0]                
__________________________________________________________________________________________________
dense_1296 (Dense)              (None, 1)            26          dropout_262[0][0]                
__________________________________________________________________________________________________
dense_1297 (Dense)              (None, 1)            26          dropout_262[0][0]                
__________________________________________________________________________________________________
dense_1298 (Dense)              (None, 1)            26          dropout_262[0][0]                
__________________________________________________________________________________________________
dense_1299 (Dense)              (None, 1)            26          dropout_262[0][0]                
__________________________________________________________________________________________________
dense_1300 (Dense)              (None, 1)            26          dropout_262[0][0]                
__________________________________________________________________________________________________
dense_1301 (Dense)              (None, 1)            26          dropout_262[0][0]                
__________________________________________________________________________________________________
dense_1302 (Dense)              (None, 1)            26          dropout_262[0][0]                
==================================================================================================
Total params: 473,085
Trainable params: 473,085
Non-trainable params: 0
__________________________________________________________________________________________________
None
stacking
Fold  2
0
multi-task
Loading Data
Training Model
Building Multilayer Perceptron
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_267 (InputLayer)          (None, 18908)        0                                            
__________________________________________________________________________________________________
dense_1303 (Dense)              (None, 25)           472725      input_267[0][0]                  
__________________________________________________________________________________________________
dropout_263 (Dropout)           (None, 25)           0           dense_1303[0][0]                 
__________________________________________________________________________________________________
dense_1304 (Dense)              (None, 25)           650         dropout_263[0][0]                
__________________________________________________________________________________________________
dropout_264 (Dropout)           (None, 25)           0           dense_1304[0][0]                 
__________________________________________________________________________________________________
dense_1305 (Dense)              (None, 1)            26          dropout_264[0][0]                
__________________________________________________________________________________________________
dense_1306 (Dense)              (None, 1)            26          dropout_264[0][0]                
__________________________________________________________________________________________________
dense_1307 (Dense)              (None, 1)            26          dropout_264[0][0]                
__________________________________________________________________________________________________
dense_1308 (Dense)              (None, 1)            26          dropout_264[0][0]                
__________________________________________________________________________________________________
dense_1309 (Dense)              (None, 1)            26          dropout_264[0][0]                
__________________________________________________________________________________________________
dense_1310 (Dense)              (None, 1)            26          dropout_264[0][0]                
__________________________________________________________________________________________________
dense_1311 (Dense)              (None, 1)            26          dropout_264[0][0]                
__________________________________________________________________________________________________
dense_1312 (Dense)              (None, 1)            26          dropout_264[0][0]                
__________________________________________________________________________________________________
dense_1313 (Dense)              (None, 1)            26          dropout_264[0][0]                
__________________________________________________________________________________________________
dense_1314 (Dense)              (None, 1)            26          dropout_264[0][0]                
==================================================================================================
Total params: 473,635
Trainable params: 473,635
Non-trainable params: 0
__________________________________________________________________________________________________
None
stacking
Fold  3
0
multi-task
Loading Data
Training Model
Building Multilayer Perceptron
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_268 (InputLayer)          (None, 19048)        0                                            
__________________________________________________________________________________________________
dense_1315 (Dense)              (None, 25)           476225      input_268[0][0]                  
__________________________________________________________________________________________________
dropout_265 (Dropout)           (None, 25)           0           dense_1315[0][0]                 
__________________________________________________________________________________________________
dense_1316 (Dense)              (None, 25)           650         dropout_265[0][0]                
__________________________________________________________________________________________________
dropout_266 (Dropout)           (None, 25)           0           dense_1316[0][0]                 
__________________________________________________________________________________________________
dense_1317 (Dense)              (None, 1)            26          dropout_266[0][0]                
__________________________________________________________________________________________________
dense_1318 (Dense)              (None, 1)            26          dropout_266[0][0]                
__________________________________________________________________________________________________
dense_1319 (Dense)              (None, 1)            26          dropout_266[0][0]                
__________________________________________________________________________________________________
dense_1320 (Dense)              (None, 1)            26          dropout_266[0][0]                
__________________________________________________________________________________________________
dense_1321 (Dense)              (None, 1)            26          dropout_266[0][0]                
__________________________________________________________________________________________________
dense_1322 (Dense)              (None, 1)            26          dropout_266[0][0]                
__________________________________________________________________________________________________
dense_1323 (Dense)              (None, 1)            26          dropout_266[0][0]                
__________________________________________________________________________________________________
dense_1324 (Dense)              (None, 1)            26          dropout_266[0][0]                
__________________________________________________________________________________________________
dense_1325 (Dense)              (None, 1)            26          dropout_266[0][0]                
__________________________________________________________________________________________________
dense_1326 (Dense)              (None, 1)            26          dropout_266[0][0]                
==================================================================================================
Total params: 477,135
Trainable params: 477,135
Non-trainable params: 0
__________________________________________________________________________________________________
None
stacking
Fold  4
0
multi-task
Loading Data
Training Model
Building Multilayer Perceptron
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_269 (InputLayer)          (None, 18673)        0                                            
__________________________________________________________________________________________________
dense_1327 (Dense)              (None, 25)           466850      input_269[0][0]                  
__________________________________________________________________________________________________
dropout_267 (Dropout)           (None, 25)           0           dense_1327[0][0]                 
__________________________________________________________________________________________________
dense_1328 (Dense)              (None, 25)           650         dropout_267[0][0]                
__________________________________________________________________________________________________
dropout_268 (Dropout)           (None, 25)           0           dense_1328[0][0]                 
__________________________________________________________________________________________________
dense_1329 (Dense)              (None, 1)            26          dropout_268[0][0]                
__________________________________________________________________________________________________
dense_1330 (Dense)              (None, 1)            26          dropout_268[0][0]                
__________________________________________________________________________________________________
dense_1331 (Dense)              (None, 1)            26          dropout_268[0][0]                
__________________________________________________________________________________________________
dense_1332 (Dense)              (None, 1)            26          dropout_268[0][0]                
__________________________________________________________________________________________________
dense_1333 (Dense)              (None, 1)            26          dropout_268[0][0]                
__________________________________________________________________________________________________
dense_1334 (Dense)              (None, 1)            26          dropout_268[0][0]                
__________________________________________________________________________________________________
dense_1335 (Dense)              (None, 1)            26          dropout_268[0][0]                
__________________________________________________________________________________________________
dense_1336 (Dense)              (None, 1)            26          dropout_268[0][0]                
__________________________________________________________________________________________________
dense_1337 (Dense)              (None, 1)            26          dropout_268[0][0]                
__________________________________________________________________________________________________
dense_1338 (Dense)              (None, 1)            26          dropout_268[0][0]                
==================================================================================================
Total params: 467,760
Trainable params: 467,760
Non-trainable params: 0
__________________________________________________________________________________________________
None
stacking
Fold  5
0
multi-task
Loading Data
Training Model
Building Multilayer Perceptron
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_270 (InputLayer)          (None, 18390)        0                                            
__________________________________________________________________________________________________
dense_1339 (Dense)              (None, 25)           459775      input_270[0][0]                  
__________________________________________________________________________________________________
dropout_269 (Dropout)           (None, 25)           0           dense_1339[0][0]                 
__________________________________________________________________________________________________
dense_1340 (Dense)              (None, 25)           650         dropout_269[0][0]                
__________________________________________________________________________________________________
dropout_270 (Dropout)           (None, 25)           0           dense_1340[0][0]                 
__________________________________________________________________________________________________
dense_1341 (Dense)              (None, 1)            26          dropout_270[0][0]                
__________________________________________________________________________________________________
dense_1342 (Dense)              (None, 1)            26          dropout_270[0][0]                
__________________________________________________________________________________________________
dense_1343 (Dense)              (None, 1)            26          dropout_270[0][0]                
__________________________________________________________________________________________________
dense_1344 (Dense)              (None, 1)            26          dropout_270[0][0]                
__________________________________________________________________________________________________
dense_1345 (Dense)              (None, 1)            26          dropout_270[0][0]                
__________________________________________________________________________________________________
dense_1346 (Dense)              (None, 1)            26          dropout_270[0][0]                
__________________________________________________________________________________________________
dense_1347 (Dense)              (None, 1)            26          dropout_270[0][0]                
__________________________________________________________________________________________________
dense_1348 (Dense)              (None, 1)            26          dropout_270[0][0]                
__________________________________________________________________________________________________
dense_1349 (Dense)              (None, 1)            26          dropout_270[0][0]                
__________________________________________________________________________________________________
dense_1350 (Dense)              (None, 1)            26          dropout_270[0][0]                
==================================================================================================
Total params: 460,685
Trainable params: 460,685
Non-trainable params: 0
__________________________________________________________________________________________________
None
stacking
time elapsed: 2095.620479600999


Epochs: 10
/home/dan/.local/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)

Hamming Loss:                 0.133

f1 scores 
 -----------
Agreement/disagreement:       0.022        13
Certainty:                    0.166        29
Contrariety:                  0.540       109
Hypotheticality:              0.276        48
Necessity:                    0.360        56
Prediction:                   0.605        88
Source of knowledge:          0.513        95
Tact/rudeness:                0.080        24
Uncertainty:                  0.540        83
Volition:                     0.000        13

Micro-f1 score:               0.463
Macro-f1 score:               0.310

Accuracy                      0.171
['MLP', 'Multi-task', 10, 0.31022680980327866, 0.46314832632139974, 0.17058252084216474]


Epochs: 50

Hamming Loss:                 0.125

f1 scores 
 -----------
Agreement/disagreement:       0.070        13
Certainty:                    0.363        29
Contrariety:                  0.529       109
Hypotheticality:              0.338        48
Necessity:                    0.428        56
Prediction:                   0.661        88
Source of knowledge:          0.513        95
Tact/rudeness:                0.057        24
Uncertainty:                  0.677        83
Volition:                     0.000        13

Micro-f1 score:               0.516
Macro-f1 score:               0.364

Accuracy                      0.251
['MLP', 'Multi-task', 50, 0.3635614088051932, 0.5157426181837108, 0.25088314257453725]


Epochs: 100

Hamming Loss:                 0.121

f1 scores 
 -----------
Agreement/disagreement:       0.053        13
Certainty:                    0.436        29
Contrariety:                  0.601       109
Hypotheticality:              0.438        48
Necessity:                    0.425        56
Prediction:                   0.651        88
Source of knowledge:          0.587        95
Tact/rudeness:                0.208        24
Uncertainty:                  0.659        83
Volition:                     0.094        13

Micro-f1 score:               0.555
Macro-f1 score:               0.415

Accuracy                      0.291
['MLP', 'Multi-task', 100, 0.4152482368651339, 0.55472360336442, 0.2907058075455701]


Epochs: 150

Hamming Loss:                 0.122

f1 scores 
 -----------
Agreement/disagreement:       0.083        13
Certainty:                    0.390        29
Contrariety:                  0.576       109
Hypotheticality:              0.408        48
Necessity:                    0.452        56
Prediction:                   0.672        88
Source of knowledge:          0.538        95
Tact/rudeness:                0.231        24
Uncertainty:                  0.683        83
Volition:                     0.099        13

Micro-f1 score:               0.552
Macro-f1 score:               0.413

Accuracy                      0.283
['MLP', 'Multi-task', 150, 0.41327013063283224, 0.551788634032683, 0.2830012717253073]


Epochs: 200

Hamming Loss:                 0.121

f1 scores 
 -----------
Agreement/disagreement:       0.143        13
Certainty:                    0.375        29
Contrariety:                  0.606       109
Hypotheticality:              0.442        48
Necessity:                    0.468        56
Prediction:                   0.663        88
Source of knowledge:          0.609        95
Tact/rudeness:                0.266        24
Uncertainty:                  0.723        83
Volition:                     0.294        13

Micro-f1 score:               0.573
Macro-f1 score:               0.459

Accuracy                      0.313
['MLP', 'Multi-task', 200, 0.4588693149240505, 0.5731762967491305, 0.3127225519287834]


Epochs: 250

Hamming Loss:                 0.121

f1 scores 
 -----------
Agreement/disagreement:       0.369        13
Certainty:                    0.454        29
Contrariety:                  0.572       109
Hypotheticality:              0.425        48
Necessity:                    0.521        56
Prediction:                   0.661        88
Source of knowledge:          0.621        95
Tact/rudeness:                0.283        24
Uncertainty:                  0.723        83
Volition:                     0.255        13

Micro-f1 score:               0.580
Macro-f1 score:               0.488

Accuracy                      0.320
['MLP', 'Multi-task', 250, 0.48819986285260414, 0.580238550194939, 0.31982831708350995]


Epochs: 300

Hamming Loss:                 0.115

f1 scores 
 -----------
Agreement/disagreement:       0.286        13
Certainty:                    0.476        29
Contrariety:                  0.595       109
Hypotheticality:              0.499        48
Necessity:                    0.514        56
Prediction:                   0.689        88
Source of knowledge:          0.588        95
Tact/rudeness:                0.322        24
Uncertainty:                  0.740        83
Volition:                     0.366        13

Micro-f1 score:               0.589
Macro-f1 score:               0.508

Accuracy                      0.319
['MLP', 'Multi-task', 300, 0.5075764691173754, 0.5894983901530569, 0.31925427441006077]


Epochs: 350

Hamming Loss:                 0.133

f1 scores 
 -----------
Agreement/disagreement:       0.258        13
Certainty:                    0.445        29
Contrariety:                  0.590       109
Hypotheticality:              0.506        48
Necessity:                    0.451        56
Prediction:                   0.669        88
Source of knowledge:          0.638        95
Tact/rudeness:                0.243        24
Uncertainty:                  0.652        83
Volition:                     0.422        13

Micro-f1 score:               0.579
Macro-f1 score:               0.487

Accuracy                      0.314
['MLP', 'Multi-task', 350, 0.4874277789980043, 0.5794781862588828, 0.3138935989826197]


Epochs: 400

Hamming Loss:                 0.122

f1 scores 
 -----------
Agreement/disagreement:       0.357        13
Certainty:                    0.489        29
Contrariety:                  0.588       109
Hypotheticality:              0.465        48
Necessity:                    0.491        56
Prediction:                   0.662        88
Source of knowledge:          0.607        95
Tact/rudeness:                0.310        24
Uncertainty:                  0.738        83
Volition:                     0.169        13

Micro-f1 score:               0.577
Macro-f1 score:               0.488

Accuracy                      0.307
['MLP', 'Multi-task', 400, 0.48764675513011485, 0.5774497235223844, 0.30737247421223685]
                      Epochs  F1 Macro   F1 Micro       EMR
Model    Domain                                            
LR       Multi-class      10  0.783113   0.645049  0.645049
         Multi-class      50  0.783113   0.645049  0.645049
         Multi-class     100  0.783113   0.645049  0.645049
         Multi-class     150  0.783113   0.645049  0.645049
         Multi-class     200  0.783113   0.645049  0.645049
         Multi-class     250  0.783113   0.645049  0.645049
         Multi-class     300  0.783113   0.645049  0.645049
         Multi-class     350  0.783113   0.645049  0.645049
         Multi-class     400  0.783113   0.645049  0.645049
         Multi-label      10  0.803389   0.810390  0.578462
         Multi-label      50  0.803389   0.810390  0.578462
         Multi-label     100  0.803389   0.810390  0.578462
         Multi-label     150  0.803389   0.810390  0.578462
         Multi-label     200  0.803389   0.810390  0.578462
         Multi-label     250  0.803389   0.810390  0.578462
         Multi-label     300  0.803389   0.810390  0.578462
         Multi-label     350  0.803389   0.810390  0.578462
         Multi-label     400  0.803389   0.810390  0.578462
FastText Multi-class      10  0.003500   0.103448  0.103448
         Multi-class      50  0.007678   0.109388  0.109388
         Multi-class     100  0.061966   0.248504  0.248504
         Multi-class     150  0.280518   0.422089  0.422089
         Multi-class     200  0.545575   0.552890  0.552890
         Multi-class     250  0.685948   0.621858  0.621858
         Multi-class     300  0.752243   0.640886  0.640886
         Multi-class     350  0.782069   0.650401  0.650401
         Multi-class     400  0.791522   0.654571  0.654571
         Multi-label      10  0.000000   0.000000  0.000000
         Multi-label      50  0.440572   0.635676  0.257404
         Multi-label     100  0.754527   0.786207  0.508291
...                      ...       ...        ...       ...
         Multi-task      300  0.797459   0.798397  0.543380
         Multi-task      350  0.798075   0.797815  0.544560
         Multi-task      400  0.797457   0.797875  0.543966
MLP      Multi-class      10  0.584662   0.516633  0.516633
         Multi-class      50  0.753242   0.586182  0.586182
         Multi-class     100  0.744950   0.568949  0.568949
         Multi-class     150  0.742576   0.578460  0.578460
         Multi-class     200  0.729882   0.573105  0.573105
         Multi-class     250  0.743843   0.573711  0.573711
         Multi-class     300  0.741047   0.565978  0.565978
         Multi-class     350  0.755008   0.580836  0.580836
         Multi-class     400  0.744819   0.567177  0.567177
         Multi-label      10  0.327105   0.481160  0.170060
         Multi-label      50  0.423043   0.564421  0.304969
         Multi-label     100  0.453840   0.588301  0.321059
         Multi-label     150  0.510391   0.620826  0.348380
         Multi-label     200  0.498886   0.599307  0.319894
         Multi-label     250  0.508602   0.582798  0.329352
         Multi-label     300  0.556578   0.618726  0.372156
         Multi-label     350  0.563661   0.619346  0.359095
         Multi-label     400  0.536588   0.617814  0.364996
         Multi-task       10  0.310227   0.463148  0.170583
         Multi-task       50  0.363561   0.515743  0.250883
         Multi-task      100  0.415248   0.554724  0.290706
         Multi-task      150  0.413270   0.551789  0.283001
         Multi-task      200  0.458869   0.573176  0.312723
         Multi-task      250  0.488200   0.580239  0.319828
         Multi-task      300  0.507576   0.589498  0.319254
         Multi-task      350  0.487428   0.579478  0.313894
         Multi-task      400  0.487647   0.577450  0.307372

[72 rows x 4 columns]
